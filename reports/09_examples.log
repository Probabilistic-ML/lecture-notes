Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/jupyter_cache/executors/utils.py", line 56, in single_nb_execution
    record_timing=False,
  File "/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/nbclient/client.py", line 1093, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/asyncio/base_events.py", line 587, in run_until_complete
    return future.result()
  File "/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/nbclient/client.py", line 560, in async_execute
    cell, index, execution_count=self.code_cells_executed + 1
  File "/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/nbclient/client.py", line 854, in async_execute_cell
    self._check_raise_for_error(cell, exec_reply)
  File "/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/nbclient/client.py", line 756, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import numpy as np
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel, WhiteKernel
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# load data
housing_dataset = fetch_california_housing()

# use first feature (median income) as additional label
X = housing_dataset["data"][:, 1:]
y = np.stack((housing_dataset["target"], housing_dataset["data"][:, 0]), axis=1)

# split data (50% train and 50% test)
# training: 10320 samples, test: 10320 samples
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# scale data
scalerX, scalery = StandardScaler(), StandardScaler()
X_train_ = scalerX.fit_transform(X_train)
y_train_ = scalery.fit_transform(y_train)

# use PCA for labels
pca = PCA()
y_train_ = pca.fit_transform(y_train_)

# construct GPR model

# scaled, isotropic Matern 1.5 kernel with noise
kernel = ConstantKernel() * Matern(length_scale=1.0, length_scale_bounds=(1e-03, 1e6))
kernel += WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-05, 5))

model = GaussianProcessRegressor(kernel)
model.fit(X_train_, y_train_)

# print optimized hyperparameter values
params = model.kernel_.get_params()
noise_level = params["k2"].get_params()["noise_level"]
scaling_factor = params["k1"].get_params()["k1"].get_params()["constant_value"]
length_scale = params["k1"].get_params()["k2"].get_params()["length_scale"]
print("scaling factor = {:.2f}, noise level = {:.2f}".format(scaling_factor, noise_level))
print("length scales = {:.2f}".format(length_scale)

# test model
y_pred = model.predict(scalerX.transform(X_test))
y_pred = pca.inverse_transform(y_pred)
y_pred = scalery.inverse_transform(y_pred)
y_pred = np.rint(y_pred) # labels should be integer valued

r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
print("\nr2 = {:.4f}, mse = {:.2f}, mae = {:.2f}".format(r2, mse, mae))
------------------

[0;36m  File [0;32m"/tmp/ipykernel_2764/1585871566.py"[0;36m, line [0;32m48[0m
[0;31m    y_pred = model.predict(scalerX.transform(X_test))[0m
[0m         ^[0m
[0;31mSyntaxError[0m[0;31m:[0m invalid syntax

SyntaxError: invalid syntax (1585871566.py, line 48)

