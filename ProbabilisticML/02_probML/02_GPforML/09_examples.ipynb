{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f16d555",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "In the present section, we use Gaussian process regression as well as Gaussian process classification in order to demonstrate briefly the application of scikit-learn.\n",
    "\n",
    "We use the following [toy](https://scikit-learn.org/stable/datasets/toy_dataset.html) and [real-world](https://scikit-learn.org/stable/datasets/real_world.html) datasets provided by scikit-learn:\n",
    "\n",
    "- [diabetes dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset) for single-output regression\n",
    "- [California housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) for multi-output regression\n",
    "- [breast cancer dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset) for binary classification\n",
    "- [handwritten digits dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#optical-recognition-of-handwritten-digits-dataset) for multi-class classification\n",
    "\n",
    "The scikit-learn website provides detailed information on the number of samples, the features, the labels and the specific task.\n",
    "\n",
    "Each dataset is splitted into training and test data. Afterwards, the model is constructed from the training data and finally, the model quality of measured in use of the test data and a suitable metric.\n",
    "\n",
    "## Diabetes Progression\n",
    "\n",
    "The data contains information on 442 diabetes patients:\n",
    "- 10 features are given (age, sex, BMI, average blood pressure as well as six blood serum measurements)\n",
    "- the label is a quantitative measure of disease progression one year after baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b637a62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14**2 * RBF(length_scale=[6.28, 7.5, 5.02, 7.18, 15.8, 397, 7.71, 365, 3.13, 107]) WhiteKernel(noise_level=0.469)\n",
      "r2 = 0.5238, mse = 2523.04, mae = 39.47\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel, WhiteKernel\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# load data\n",
    "diabetes_dataset = load_diabetes()\n",
    "\n",
    "X = diabetes_dataset[\"data\"]\n",
    "y = diabetes_dataset[\"target\"].reshape(-1, 1)\n",
    "\n",
    "# split data (80% train and 20% test)\n",
    "# training: 353 samples, test: 89 samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scale data\n",
    "scalerX, scalery = StandardScaler(), StandardScaler()\n",
    "X_train_ = scalerX.fit_transform(X_train)\n",
    "y_train_ = scalery.fit_transform(y_train)\n",
    "\n",
    "# construct GPR model\n",
    "\n",
    "# scaled, anisotropic RBF kernel with noise\n",
    "kernel = ConstantKernel() * RBF(length_scale= 10 * [1.0], length_scale_bounds=(1e-03, 1e6)) \n",
    "kernel += WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-05, 5))\n",
    "\n",
    "model = GaussianProcessRegressor(kernel)\n",
    "model.fit(X_train_, y_train_)\n",
    "\n",
    "# print optimized hyperparameter values\n",
    "params = model.kernel_.get_params()\n",
    "# print(params[\"k1\"], params[\"k2\"])\n",
    "\n",
    "# test model\n",
    "y_pred = model.predict(scalerX.transform(X_test))\n",
    "y_pred = scalery.inverse_transform(y_pred)\n",
    "y_pred = np.rint(y_pred) # labels should be integer valued\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"r2 = {:.4f}, mse = {:.2f}, mae = {:.2f}\".format(r2, mse, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faceb17",
   "metadata": {},
   "source": [
    "## House values and Incomes\n",
    "\n",
    "The dataset contains information on housings in 20640 areas (block groups) in California:\n",
    "- 7 features (median house age, average number of rooms per household, average number of bedrooms per household, block group population, average number of household members, block group latitude, block group longitude)\n",
    "- 2 labels (median house value, median income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4325caed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8256, 7) (12384, 7)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_646/3102657094.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianProcessRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# print optimized hyperparameter values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m# First optimize starting from theta specified in kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             optima = [(self._constrained_optimization(obj_func,\n\u001b[0m\u001b[1;32m    239\u001b[0m                                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                                                       self.kernel_.bounds))]\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_constrained_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fmin_l_bfgs_b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             opt_res = scipy.optimize.minimize(\n\u001b[0m\u001b[1;32m    504\u001b[0m                 \u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 bounds=bounds)\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                   **options)\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0miprint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[1;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[1;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     lml, grad = self.log_marginal_likelihood(\n\u001b[0m\u001b[1;32m    231\u001b[0m                         theta, eval_gradient=True, clone_kernel=False)\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0mK1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK1_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m             \u001b[0mK2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK2_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mK1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mK2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK1_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK2_gradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0mK1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK1_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m             \u001b[0mK2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK2_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m             return K1 * K2, np.dstack((K1_gradient * K2[:, :, np.newaxis],\n\u001b[1;32m    915\u001b[0m                                        K2_gradient * K1[:, :, np.newaxis]))\n",
      "\u001b[0;32m~/anaconda3/envs/AMLenv/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdists\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdists\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel, WhiteKernel\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# load data\n",
    "housing_dataset = fetch_california_housing()\n",
    "\n",
    "# use first feature (median income) as additional label\n",
    "X = housing_dataset[\"data\"][:, 1:]\n",
    "y = np.stack((housing_dataset[\"target\"], housing_dataset[\"data\"][:, 0]), axis=1)\n",
    "\n",
    "# split data (50% train and 50% test)\n",
    "# training: 10320 samples, test: 10320 samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# scale data\n",
    "scalerX, scalery = StandardScaler(), StandardScaler()\n",
    "X_train_ = scalerX.fit_transform(X_train)\n",
    "y_train_ = scalery.fit_transform(y_train)\n",
    "\n",
    "# use PCA for labels\n",
    "pca = PCA()\n",
    "y_train_ = pca.fit_transform(y_train_)\n",
    "\n",
    "# construct GPR model\n",
    "\n",
    "# scaled, isotropic Matern 1.5 kernel with noise\n",
    "kernel = ConstantKernel() * Matern(length_scale=1.0, length_scale_bounds=(1e-03, 1e6))\n",
    "kernel += WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-05, 5))\n",
    "\n",
    "model = GaussianProcessRegressor(kernel)\n",
    "model.fit(X_train_, y_train_)\n",
    "\n",
    "# print optimized hyperparameter values\n",
    "params = model.kernel_.get_params()\n",
    "# print(params[\"k1\"], params[\"k2\"])\n",
    "\n",
    "# test model\n",
    "y_pred = model.predict(scalerX.transform(X_test))\n",
    "y_pred = pca.inverse_transform(y_pred)\n",
    "y_pred = scalery.inverse_transform(y_pred)\n",
    "y_pred = np.rint(y_pred) # labels should be integer valued\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"r2 = {:.4f}, mse = {:.2f}, mae = {:.2f}\".format(r2, mse, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58502c61",
   "metadata": {},
   "source": [
    "## Breast Cancer Diagnostic Analysis\n",
    "\n",
    "The data contains information on 569 biopsy results of breast cancer examinations. The features describe characteristics of the extracted cell nuclei. Each sample is labled as benign (357 in total) or malignant (212 in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel, WhiteKernel\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "# load data\n",
    "breast_cancer_dataset = load_breast_cancer()\n",
    "\n",
    "X = breast_cancer_dataset[\"data\"]\n",
    "y = breast_cancer_dataset[\"target\"]\n",
    "\n",
    "# split data (80% train and 20% test)\n",
    "# training: 455 samples, test: 114 samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scale data\n",
    "scalerX = StandardScaler()\n",
    "X_train_ = scalerX.fit_transform(X_train)\n",
    "\n",
    "# construct GPC model\n",
    "\n",
    "# scaled, anisotropic absolute exponential kernel with noise\n",
    "kernel = ConstantKernel() * Matern(length_scale= 30 * [1.0], length_scale_bounds=(1e-03, 1e20), nu=0.5) \n",
    "kernel += WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-08, 5))\n",
    "\n",
    "model = GaussianProcessClassifier(kernel)\n",
    "model.fit(X_train_, y_train)\n",
    "\n",
    "# print optimized hyperparameter values\n",
    "params = model.kernel_.get_params()\n",
    "# print(params[\"k1\"], params[\"k2\"])\n",
    "\n",
    "# test model\n",
    "y_pred = model.predict(scalerX.transform(X_test))\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred) * 100\n",
    "f1 = f1_score(y_test, y_pred) * 100\n",
    "precision = precision_score(y_test, y_pred) * 100\n",
    "recall = recall_score(y_test, y_pred) * 100\n",
    "print(\"acc = {:.2f}, f1 = {:.2f}\".format(acc, f1)) \n",
    "print(\"precision = {:.2f}, recall = {:.2f}\".format(precision, recall))\n",
    "plot_confusion_matrix(model, scalerX.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed617b9f",
   "metadata": {},
   "source": [
    "## Handwritten Digits\n",
    "\n",
    "The dataset contains 1797 images of handwritten single-digits with 8 x 8 pixels (see image below) and are labeled by the corresponding digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c526872a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel, WhiteKernel\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load data\n",
    "digits_dataset = load_digits()\n",
    "\n",
    "X = digits_dataset[\"data\"]\n",
    "y = digits_dataset[\"target\"]\n",
    "\n",
    "# split data (80% train and 20% test)\n",
    "# training: 1437 samples, test: 360 samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "for i in range(10):\n",
    "    image = digits_dataset.images[i]\n",
    "    ax =  fig.add_subplot(5, 2, i+1)\n",
    "    ax.imshow(image)\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ba89dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108**2 * RBF(length_scale=48.3) + WhiteKernel(noise_level=3.95e-07), 28.4**2 * RBF(length_scale=12.8) + WhiteKernel(noise_level=0.00099), 247**2 * RBF(length_scale=87.9) + WhiteKernel(noise_level=0.000995), 42.7**2 * RBF(length_scale=18.1) + WhiteKernel(noise_level=0.000991), 121**2 * RBF(length_scale=49.5) + WhiteKernel(noise_level=2.11e-07), 96.3**2 * RBF(length_scale=43.6) + WhiteKernel(noise_level=0.000994), 99.1**2 * RBF(length_scale=41.7) + WhiteKernel(noise_level=0.000995), 64.6**2 * RBF(length_scale=33.3) + WhiteKernel(noise_level=0.000994), 19.9**2 * RBF(length_scale=10.2) + WhiteKernel(noise_level=1.63e-07), 43.7**2 * RBF(length_scale=21) + WhiteKernel(noise_level=6.67e-07)]\n",
      "acc = 97.78\n",
      "f1 = [100.          98.24561404 100.          97.05882353 100.\n",
      "  95.74468085  97.14285714  98.50746269  96.66666667  95.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scale data\n",
    "scalerX = StandardScaler()\n",
    "X_train_ = scalerX.fit_transform(X_train)\n",
    "\n",
    "# construct GPC model\n",
    "\n",
    "# scaled, isotropic RBF kernel with noise\n",
    "kernel = ConstantKernel() * RBF(length_scale= 1., length_scale_bounds=(1e-03, 1e3)) \n",
    "kernel += WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-07, 5))\n",
    "\n",
    "model = GaussianProcessClassifier(kernel)\n",
    "model.fit(X_train_, y_train)\n",
    "\n",
    "# print optimized hyperparameter values\n",
    "params = model.kernel_.get_params()\n",
    "print(params[\"kernels\"])\n",
    "\n",
    "# test model\n",
    "y_pred = model.predict(scalerX.transform(X_test))\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred) * 100\n",
    "f1 = f1_score(y_test, y_pred, average=None, labels=range(10)) * 100\n",
    "print(\"acc = {:.2f}\".format(acc))\n",
    "print(\"f1 = {}\".format(f1)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
