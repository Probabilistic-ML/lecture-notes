{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2567d5a",
   "metadata": {},
   "source": [
    "# Gaussian Process Classification\n",
    "\n",
    "Gaussian process are not only used for regression, but also for classification problems. Gaussian process classification uses a latent regression model to predict class probabilities. In a first step, we discuss binary classification and afterwards the setting is generalized to multiclass classification.\n",
    "\n",
    "(sec:binaryclass)=\n",
    "## Binary Classification\n",
    "\n",
    "In binary classification the data $\\mathcal{D}$ is of the form\n",
    "\n",
    "$$\\mathcal{D} = \\{ (x_i, y_i)~|~x_i \\in \\mathbb{R}^d, y_i \\in \\{-1, 1\\} \\quad \\text{for } i=1,\\dots,n \\},$$\n",
    "\n",
    "i.e., the (discrete) label has either value $-1$ or $1$ representing the two possible classes. The sample matrix $X$ and the lables $y$ are constructed as before.\n",
    "\n",
    "For a test point $x^*$, the aim is to predict the **class probabilities** of the output $y^*$, i.e., the probabilities $p(y^*=1~|~X, y, x^*)$ and $p(y^*=-1~|~X, y, x^*)$. In this way, we obtain one discrete probability distribution on $\\{-1, 1\\}$ for each $x^*$. Since \n",
    "\n",
    "$$p(y^*=-1~|~X, y, x^*) = 1 - p(y^*=1~|~X, y, x^*),$$\n",
    "\n",
    "it is sufficient to focus on $p(y^*=1~|~X, y, x^*)$. In other words, we are looking for a model which returns for a given input $x^*$ the probability that the corresponding label is $1$. For example, $x^*$ could be an image which shows either a cat or a dog. The model has to quantify the probability for dog and the complementary probability yields the probability for cat. Certainly, we desire values close to 0 or 1, since values near 0.5 imply that the model has difficulties to classify the input.\n",
    "\n",
    "It holds $\\sigma(z) \\in [0,1]$, where \n",
    "\n",
    "$$\\sigma(z) := \\frac{1}{1 + \\exp(-z)} \\quad \\text{for } z \\in \\mathbb{R}$$(deflogfct)\n",
    "\n",
    "is the **logistic response function**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc81ac06",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "x = np.linspace(-8, 8, num=100)\n",
    "plt.plot(x, expit(x), label='logistic sigmoid')\n",
    "leg = plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be66c14",
   "metadata": {},
   "source": [
    "Hence, the value of $\\sigma(z)$ can be interpreted as a probability. It is also possible to use other response functions such as the Gaussian cdf, but we will restrict to $\\sigma$.\n",
    "\n",
    "Our aim is to construct the **distribution of a latent variable** $f^*$ given the data $\\mathcal{D}$ and a test point $x^*$ (denote the pdf by $p(f^*~|~X, y, x^*)$) such that the class probability can be computed by the expectation of $p(y^*=1~|~f^*) := \\sigma(f^*)$:\n",
    "\n",
    "$$\n",
    "p(y^*=1~|~X, y, x^*) &= \\int_{\\mathbb{R}} ~ p(y^*=1~|~f^*)~p(f^*~|~X, y, x^*)~df^* \\\\\n",
    "&= \\int_{\\mathbb{R}} ~ \\sigma(f^*)~p(f^*~|~X, y, x^*)~df^*.\n",
    "$$ (classprob)\n",
    "\n",
    "Please note that $p(y^*=-1~|~f^*) = 1 - p(y^*=1~|~f^*) = 1 - \\sigma(f^*) = \\sigma(-f^*)$ due to the properties of the logistic response function. Thus, the notation $p(y^*~|~f^*) = \\sigma(y^* f^*)$ is also used. Moreover, we like to mention that $f^* < 0$ suggests that $y^* = -1$ is more likely and vice versa $f^* > 0$ implies that $y^* = 1$ is more likely.\n",
    "\n",
    "*How can we construct $p(f^*~|~X, y, x^*)$ in* {eq}`classprob` *by means of Gaussian process regression*? \n",
    "\n",
    "The answer to this question is rather complicated and technical. For the interested reader, we give the details in the subsequent part:\n",
    "\n",
    "````{admonition} Explanation.\n",
    ":class: dropdown\n",
    "We follow the explanation in sections 3.3 and 3.4 of {cite}```Rasmussen2006```.\n",
    "\n",
    "In Gaussian process regression we constructed a similar distribution $p(f^*~|~X, f, x^*)$ representing the {ref}```posterior over functions<lem:gpregr>``` in terms of conditional distributions. Hence, the approach\n",
    "\n",
    "$$p(f^*|~X, y, x^*) = \\int_{\\mathbb{R}^n} ~ p(f^*~|~X, f, x^*)~p(f~|~X, y)~df$$ (latentdistr)\n",
    "\n",
    "is useful and natural, since it reduces the problem to determine the **distribution of the latent labels** $f$ given the observations $X$ and $y$. Note that we denote the continuous labels by $f$ instead of $y$, since $y$ is used for the discrete class labels.\n",
    "\n",
    "At this point, it is already evident that **Gaussian process classification is more challenging than regression**. It is required to determine the pdf $p(f~|~X, y)$ of an unobserved variable $f$ and afterwards two integrals have to be calculated which involve the posterior distribution function of a Gaussian process regression model.\n",
    "\n",
    "*How can we compute $p(f~|~X, y)$ in* {eq}`latentdistr`? \n",
    "\n",
    "Bayes' theorem yields\n",
    "\n",
    "$$p(f ~|~X, y) = \\frac{p(y~|~X, f) ~ p(f~|~X)}{p(y~|~X)} = \\frac{p(y~|~f) ~ p(f~|~X)}{p(y~|~X)},$$ (Bayeslatentlabels)\n",
    "\n",
    "since $y$ depends by assumption only on the latent variable $f$. In principle, we have all ingredients to create our classification model. Indeed, it holds \n",
    "\n",
    "$$p(y~|~f) = \\prod_{i=1}^n p(y_i~|~f_i) = \\prod_{i=1}^n \\sigma(y_i f_i) = \\prod_{i=1}^n  \\frac{1}{1 + \\exp(-y_i f_i)}$$(factclassprob)\n",
    "\n",
    "and\n",
    "\n",
    "$$p(y~|~X) = \\int_{\\mathbb{R^n}} p(y~|~f, X) ~p(f~|~X)~ df = \\int_{\\mathbb{R^n}} p(y~|~f) ~p(f~|~X)~df,$$\n",
    "\n",
    "where $p(f~|~X)$ is the marginal likelihood of the Gaussian process. Please note that we assume that the labels $y$ are independent conditional on $f$ in order to factorize in {eq}`factclassprob`. However, the non-Gaussian likelihood $p(y~|~f)$ makes it analytically intracable to compute the integral in {eq}`latentdistr`.\n",
    "\n",
    "Markov chain Monte Carlo (MCMC) methods are useful to compute the integrals. Another approach is the **Laplace approximation** of $p(f~|~X, y)$ by a Gaussian distribution function $q(f~|~X, y)$. The idea is to replace the unknown distribution by a suitable Gaussian distribution which is easier to handle. If we assume that $p(f~|~X, y)$ would be indeed the pdf of a normal distribution, then mean and covariance would be given by\n",
    "\n",
    "$$\\hat{f} := \\underset{f}{\\text{argmax}} ~ p(f~|~X, y)$$(Laplacemean)\n",
    "\n",
    "and \n",
    "\n",
    "$$\\Sigma_{\\hat{f}} := \\Big(- \\nabla^2 \\ln \\big(p(f~|~X, y)\\big)|_{f=\\hat{f}}\\Big)^{-1},$$(Laplacecov)\n",
    "\n",
    "where $\\nabla$ and $\\nabla^2$ denote the first and second derivative, respectively. Thus, the Laplace approximation requires to find the maximum of a function depending on $f$. For this purpose, we compute the roots of the gradient. The quality of the Laplace approximation depends of course on the shape of the *real* distribution function. For simplification of the calculation, we make to following changes:\n",
    "\n",
    "- instead of $p(f~|~X, y)$ consider $p(y~|~f) ~ p(f~|~X)$ in view of {eq}`Bayeslatentlabels`,\n",
    "- apply $\\ln$ to $p(y~|~f) ~ p(f~|~X)$\n",
    "\n",
    "Thus, first $p(f~|~X, y)$ is scaled by a constant and afterwards the strictly increasing function $\\ln$ is applied. A logarithmic transformation is useful, since it turns products into sums (which are easier to differentiate) and simplifies exponential terms. These modifications have no influence on the $\\text{argmax}$. \n",
    "\n",
    "Set $\\Psi(f) := \\ln \\big(p(y~|~f) ~ p(f~|~X)\\big)$. It holds\n",
    "\n",
    "$$ \\Psi(f) &= \\ln \\big(p(y~|~f)\\big) + \\ln \\big(p(f~|~X)\\big) \\\\\n",
    "           &= \\ln \\big(p(y~|~f)\\big) - \\frac{1}{2} f^T K(X, X)^{-1} f - \\frac{1}{2} \\ln \\big(|K(X, X)|\\big) - \\frac{n}{2} \\ln  \\big(2 \\pi\\big)$$\n",
    "           \n",
    "Thus, the gradient is given by\n",
    "\n",
    "$$ \\nabla \\Psi(f) = \\nabla \\ln \\big(p(y~|~f)\\big) - K(X, X)^{-1} f $$\n",
    "\n",
    "and the Hessian by\n",
    "\n",
    "$$ \\nabla^2 \\Psi(f) &= \\nabla^2 \\ln \\big(p(y~|~f)\\big) - K(X, X)^{-1} \\\\\n",
    "                    &= -  W(f) - K(X, X)^{-1},$$\n",
    "                    \n",
    "where $W(f) := - \\nabla^2 \\ln \\big(p(y~|~f)\\big)$ is a diagonal matrix, since\n",
    "\n",
    "$$\\ln \\big(p(y~|~f)\\big) = \\ln \\big(\\prod_{i=1}^n \\sigma(y_i f_i)\\big) = \\sum_{i=1}^n \\ln \\big(\\sigma(y_i f_i)\\big)$$\n",
    "           \n",
    "$\\hat{f}$ fulfills $\\nabla \\Psi(\\hat{f}) = 0$ and hence, it holds\n",
    "\n",
    "$$ \\hat{f} = K(X, X) \\nabla \\ln \\big(p(y~|~\\hat{f})\\big)$$(eqfhat)\n",
    "\n",
    "Unfortunately, $\\hat{f}$ also appears in the right-hand side of {eq}`eqfhat` and the equation can not be solved analytically. Therefore, another approximation is necessary. Roots of $\\nabla \\Psi$ can be computed by **Newton's method** in use of $\\nabla^2 \\Psi$:\n",
    "\n",
    "- start with some initial value $f_0$\n",
    "- for $i=0, 1, \\dots$ compute iteratively\n",
    "\n",
    "  $$ f_{i+1} = f_i - \\big(\\nabla^2 \\Psi(f_i)\\big)^{-1} \\nabla \\Psi(f_i)$$\n",
    "  \n",
    "  until some stopping criterion is met\n",
    "- denote the result as $\\hat{f}$\n",
    "\n",
    "Thus, $p(f~|~X, y)$ is replaced by the density $q(f~|~X, y)$ of a $\\mathcal{N}(\\hat{f}, \\Sigma_{\\hat{f}})$-distributed random variable with \n",
    "\n",
    "$$\\Sigma_{\\hat{f}} = \\big(W(\\hat{f}) + K(X, X)^{-1}\\big)^{-1}$$\n",
    "\n",
    "Consequently, the approximation of {eq}`latentdistr` yields\n",
    "\n",
    "$$p(f^*~|~X, y, x^*) \\approx q(f^*~|~X, y, x^*) := \\int_{\\mathbb{R}^n} ~ p(f^*~|~X, f, x^*)~q(f~|~X, y)~df$$\n",
    "\n",
    "The integrand is the product of two probability distribution functions of normal distributions. Hence, $q(f^*~|~X, y, x^*)$ is the density of a univariate normal distribution with mean\n",
    "\n",
    "$$\\mathbb{E}(f^*~|~X, y, x^*) = k(x^*, X) K(X, X)^{-1} \\hat{f}$$\n",
    "\n",
    "and variance \n",
    "\n",
    "$$\\text{var}(f^*~|~X, y, x^*) = k(x^*, x^*) - K(x^*, X)\\big(W(\\hat{f})^{-1} + K(X,X)\\big)^{-1} K(X, x^*)$$\n",
    "\n",
    "This result looks very familiar. Indeed, the mean and variance equal exactly the mean prediction and variance in Gaussian process regression with data given by $X$ and $\\hat{f}$ as well as additional noise specified by $W(\\hat{f})^{-1}$.\n",
    "\n",
    "For the sake of completeness, the derivation is presented in the following section:\n",
    "\n",
    "```{admonition} Don't do it!\n",
    ":class: dropdown\n",
    "For simplification of the notation, we write $K := K(X, X)$ and $W := W(\\hat{f})$. It holds\n",
    "\n",
    "$$\\mathbb{E}(f^*~|~X, y, x^*) &= \\int_{\\mathbb{R}} f^*~p(f^*~|~X, y, x^*)~df^* \\\\\n",
    "&\\approx \\int_{\\mathbb{R}} f^*~\\int_{\\mathbb{R}^n} ~ p(f^*~|~X, f, x^*)~q(f~|~X, y)~df~df^* \\\\\n",
    "&= \\int_{\\mathbb{R}^n} \\int_{\\mathbb{R}} f^*~ p(f^*~|~X, f, x^*)~df^* ~q(f~|~X, y) ~ df \\\\\n",
    "&= \\int_{\\mathbb{R}^n} K(x^*, X) K^{-1} f ~q(f~|~X, y) ~ df \\\\\n",
    "&= K(x^*, X) K^{-1} \\int_{\\mathbb{R}^n} f ~q(f~|~X, y) ~ df \\\\\n",
    "&= k(x^*, X) K^{-1} \\hat{f}$$\n",
    "\n",
    "and variance\n",
    "\n",
    "$$\\text{var}(f^*~|~X, y, x^*) &= \\int_{\\mathbb{R}} \\big(f^* - \\mathbb{E}(f^*~|~X, y, x^*)\\big)^2~p(f^*~|~X, y, x^*)~df^* \\\\\n",
    "&\\approx \\int_{\\mathbb{R}} \\big(f^* - \\mathbb{E}(f^*~|~X, y, x^*)\\big)^2~\\int_{\\mathbb{R}^n} ~ p(f^*~|~X, f, x^*)~q(f~|~X, y)~df~df^* \\\\ \n",
    "&= \\int_{\\mathbb{R}^n} \\int_{\\mathbb{R}} \\big(f^* - \\mathbb{E}(f^*~|~X, y, x^*) \\big)^2 ~ p(f^*|~X, f, x^*) ~ df^* ~ q(f~|~X, y)~df \\\\\n",
    "&= \\int_{\\mathbb{R}^n} \\int_{\\mathbb{R}} \\big(f^* - \\mathbb{E}(f^*|~X, f, x^*) + \\mathbb{E}(f^*~|~X, f, x^*) - \\mathbb{E}(f^*~|~X, y, x^*)\\big)^2 ~ p(f^*|~X, f, x^*) ~ df^* ~ q(f~|~X, y)~df \\\\\n",
    "&= \\int_{\\mathbb{R}^n} \\int_{\\mathbb{R}} \\big(f^* - \\mathbb{E}(f^*|~X, f, x^*)\\big)^2 + \\big(\\mathbb{E}(f^*~|~X, f, x^*) - \\mathbb{E}(f^*~|~X, y, x^*)\\big)^2 ~ p(f^*|~X, f, x^*) ~ df^* ~ q(f~|~X, y)~df,$$\n",
    "\n",
    "since\n",
    "\n",
    "$$&\\int_{\\mathbb{R}^n} \\int_{\\mathbb{R}} \\big(f^* - \\mathbb{E}(f^*~|~X, f, x^*)\\big)\\big(\\mathbb{E}(f^*~|~X, f, x^*) - \\mathbb{E}(f^*~|~X, y, x^*)\\big) ~ p(f^*|~X, f, x^*) ~ df^* ~ q(f~|~X, y)~df \\\\\n",
    "&= \\int_{\\mathbb{R}^n} \\underbrace{\\int_{\\mathbb{R}} \\big(f^* - \\mathbb{E}(f^*~|~X, f, x^*)\\big) ~ p(f^*~|~X, f, x^*) ~ df^*}_{=0} ~ \\big(\\mathbb{E}(f^*~|~X, f, x^*) - \\mathbb{E}(f^*~|~X, y, x^*)\\big) ~ q(f|~X, y)~df \\\\\n",
    "&= 0$$\n",
    "\n",
    "The first summand in the integral yields the variance of the posterior Gaussian process distribution at $x^*$. Recall that $\\mathbb{E}(f^*~|~X, f, x^*) = K(x^*, X)K^{-1}f$. Therefore, it follows\n",
    "\n",
    "$$ \\text{var}(f^*~|~X, y, x^*) &= k(x^*, x^*) - K(x^*, X)K^{-1}K(X, x^*) + \\int_{\\mathbb{R}^n} \\int_{\\mathbb{R}} \\big(K(x^*, X)K^{-1}(f - \\hat{f}\\big)^2 ~ p(f^*|~X, f, x^*) ~ df^* ~ q(f~|~X, y)~df \\\\\n",
    "&= k(x^*, x^*) - K(x^*, X)K^{-1}K(X, x^*) + \\int_{\\mathbb{R}^n} \\big(K(x^*, X)K^{-1}(f - \\hat{f}\\big)^2 ~ q(f~|~X, y)~df \\\\\n",
    "&= k(x^*, x^*) - K(x^*, X)K^{-1}K(X, x^*) + K(x^*, X) K^{-1} \\big(W + K^{-1}\\big)^{-1} K^{-1} K(X, x^*) \\\\\n",
    "&= k(x^*, x^*) - K(x^*, X) \\big(K^{-1} - K^{-1} \\big(W + K^{-1}\\big)^{-1} K^{-1}\\big) K(X, x^*) \\\\\n",
    "&= k(x^*, x^*) - K(x^*, X)\\big(W^{-1} + K\\big)^{-1} K(X, x^*)$$\n",
    "\n",
    "The last equation holds, since $K^{-1} + K^{-1} \\big(W + K^{-1}\\big)^{-1} K^{-1} = \\big(W^{-1} + K \\big)^{-1}$ by\n",
    "\n",
    "$$&\\big(K^{-1} - K^{-1} \\big(W + K^{-1}\\big)\\big(W^{-1} + K \\big) \\\\\n",
    "&= K^{-1} \\big(I_n - (W + K^{-1})^{-1} K^{-1}\\big)\\big(K + W^{-1}\\big) \\\\\n",
    "&= K^{-1} \\big(W + K^{-1})^{-1} \\big) \\big(W + K^{-1} - K^{-1}\\big)\\big(K + W^{-1}\\big) \\\\\n",
    "&= K^{-1} \\big(W + K^{-1})^{-1} \\big) W \\big(K + W^{-1}\\big) \\\\\n",
    "&= (W K + I_n)^{-1}  (W K + I_n) \\\\\n",
    "&= I_n\n",
    "$$\n",
    "```\n",
    "\n",
    "In order to compute the marginal likelihood $p(y~|~X)$ the second order approximation\n",
    "\n",
    "$$\\Psi(f) \\approx \\Psi(\\hat{f}) - \\frac{1}{2} (f - \\hat{f})^T {\\Sigma_{\\hat{f}}}^{-1} (f - \\hat{f})$$\n",
    "\n",
    "is used. To emphasize the dependence on the hyperparameters $\\theta$, we use the notation $p(y~|~X, \\theta)$ instead of $p(y~|~X)$ and so forth. **Note that $\\hat{f}$ and $\\Sigma_{\\hat{f}}$ also depend on $\\theta$**. It holds\n",
    "\n",
    "$$ p(y~|~X, \\theta) = \\int_{\\mathbb{R}^n} p(y~|~f) ~p(f~|~X, \\theta) df &= \\int_{\\mathbb{R}^n} \\exp(\\Psi(f))~df \\\\\n",
    "&\\approx \\exp(\\Psi(\\hat{f})) \\int_{\\mathbb{R}^n} \\exp(-\\frac{1}{2} (f - \\hat{f})^T {\\Sigma_{\\hat{f}}}^{-1} (f - \\hat{f}))~df \\\\\n",
    "&= \\exp(\\Psi(\\hat{f})) \\sqrt{(2\\pi)^n |\\Sigma_{\\hat{f}}|}$$\n",
    "\n",
    "Thefore, the log marginal likelihood reads\n",
    "\n",
    "$$\\ln \\big(p(y~|~X, \\theta)\\big) &\\approx \\Psi(\\hat{f}) + \\frac{n}{2} \\ln \\big(2\\pi\\big) + \\frac{1}{2} \\ln\\big(|\\Sigma_{\\hat{f}}|\\big) \\\\\n",
    "&= \\ln \\big(p(y~|~\\hat{f})\\big) + \\ln \\big(p(\\hat{f}~|~X, \\theta)\\big) + \\frac{n}{2} \\ln \\big(2\\pi\\big) + \\frac{1}{2} \\ln\\big(|\\Sigma_{\\hat{f}}|\\big) \\\\\n",
    "&= \\ln \\big(p(y~|~\\hat{f})\\big) - \\frac{1}{2} \\hat{f}^T K_{\\theta}(X,X)^{-1} \\hat{f} - \\frac{1}{2} \\ln \\big(|K_{\\theta}(X,X)|\\big) + \\frac{1}{2} \\ln\\big(|\\Sigma_{\\hat{f}}|\\big) \\\\\n",
    "&= \\ln \\big(p(y~|~\\hat{f})\\big) - \\frac{1}{2} \\hat{f}^T K_{\\theta}(X,X)^{-1} \\hat{f} - \\frac{1}{2} \\ln \\big(|B(X, \\hat{f}, \\theta)|\\big),$$\n",
    "\n",
    "where $K_{\\theta}$ illustrates the dependence of $K$ on $\\theta$ and $B(X, \\hat{f}) := K_{\\theta}(X, X) {\\Sigma_{\\hat{f}}}^{-1}$. It holds\n",
    "\n",
    "$$B(X, \\hat{f}) = K_{\\theta}(X, X) \\big(W(\\hat{f}) + K_{\\theta}(X, X)^{-1}\\big) = I_n + K_{\\theta}(X, X) W(\\hat{f})$$\n",
    "\n",
    "and thus, it follows\n",
    "\n",
    "$$|B(X, \\hat{f})| = |I_n + K_{\\theta}(X, X) W(\\hat{f})| &= |W(\\hat{f})^{-\\frac{1}{2}} + K_{\\theta}(X, X) W(\\hat{f})^{\\frac{1}{2}}||W(\\hat{f})^{\\frac{1}{2}}| \\\\\n",
    "&= |W(\\hat{f})^{\\frac{1}{2}}||W(\\hat{f})^{-\\frac{1}{2}} + K_{\\theta}(X, X) W(\\hat{f})^{\\frac{1}{2}}| \\\\\n",
    "&= |I_n + W(\\hat{f})^{\\frac{1}{2}} K_{\\theta}(X,X) W(\\hat{f})^{\\frac{1}{2}}|$$\n",
    "\n",
    "The last representation is particularly useful for implementation purposes, since $I_n + W(\\hat{f})^{\\frac{1}{2}} K_{\\theta}(X,X) W(\\hat{f})^{\\frac{1}{2}}$ is a positive definite matrix.\n",
    "````\n",
    "\n",
    "In application, the computational process can be summarized as follows:\n",
    "1. Choose a Gaussian process with hyperparemeters $\\theta$ as prior for the latent labels $f$\n",
    "2. For fixed $\\theta$ set $\\Psi(f) := \\ln \\big(p(y~|~f) ~ p(f~|~X, \\theta)\\big)$\n",
    "3. Compute the root $\\hat{f}$ (depends on $\\theta$) of $\\nabla \\Psi$ in use of Newton's method\n",
    "4. Calculate the log marginal likelihood by\n",
    "   \n",
    "   $$\\ln p(y~|~X, \\theta) &\\approx \\ln \\big(p(y~|~\\hat{f})\\big) - \\frac{1}{2} \\hat{f}^T K_{\\theta}(X,X)^{-1} \\hat{f} - \\frac{1}{2} \\ln \\big(|K_{\\theta}(X,X)|\\big) + \\frac{1}{2} \\ln\\big(|\\Sigma_{\\hat{f}}|\\big)\\\\\n",
    "   &=\\ln \\big(p(y~|~\\hat{f})\\big) - \\frac{1}{2} \\hat{f}^T K_{\\theta}(X,X)^{-1} \\hat{f} - \\frac{1}{2} \\ln \\big(|I_n + W(\\hat{f})^{\\frac{1}{2}} K_{\\theta}(X,X) W(\\hat{f})^{\\frac{1}{2}}|\\big),$$\n",
    "   \n",
    "   where $W(\\hat{f}) = - \\nabla^2 \\ln \\big(p(y~|~\\hat{f})\\big)$, $\\Sigma_{\\hat{f}} = \\big(W(\\hat{f}) + K_{\\theta}(X, X)^{-1}\\big)^{-1}$ and \n",
    "   \n",
    "   $$\\ln \\big(p(y~|~\\hat{f})\\big) = - \\sum_{i=1}^n \\ln \\big(1 + \\exp(-y_i\\hat{f}_i)\\big)$$\n",
    "5. Maximize $\\ln \\big(p(y~|~X, \\theta)\\big)$ with respect to $\\theta$ (which means application of an optimization algorithm and looping steps 2.-4.)\n",
    "\n",
    "Then, the class probability for a test point $x^*$ in {eq}`classprob` is given by the one dimensional integral\n",
    "\n",
    "$$p(y^*=1~|~X, y, x^*) &= \\int_{\\mathbb{R}} ~ \\sigma(f^*)~p(f^*~|~X, y, x^*)~df^* \\\\\n",
    "&\\approx \\int_{\\mathbb{R}} ~ \\sigma(f^*)~q(f^*~|~X, y, x^*)~df^*,$$\n",
    "\n",
    "where $q(f^*~|~X, y, x^*)~df^*$ is the density of a normal distribution with mean\n",
    "\n",
    "$$\\mathbb{E}(f^*~|~X, y, x^*) = k(x^*, X) K(X, X)^{-1} \\hat{f}$$\n",
    "\n",
    "and variance \n",
    "\n",
    "$$\\text{var}(f^*~|~X, y, x^*) = k(x^*, x^*) - K(x^*, X)\\big(W(\\hat{f})^{-1} + K(X,X)\\big)^{-1} K(X, x^*)$$\n",
    "\n",
    "Thus, the assigned class probability is the expectation of $\\sigma$ with respect to the posterior distribution of the latent variable $f^*$. If we are not interested in the precise value of the probability, but only in the favored class, it is sufficient to consider the sign of $\\mathbb{E}(f^*~|~X, y, x^*)$. For negative values the predicted class is $-1$ and for positive values the predicted class is $1$. This is equivalent to computing $\\sigma(\\mathbb{E}(f^*~|~X, y, x^*))$ and to conclude that the predicted class is $-1$ for a value less than $0.5$ and the predicted class is $1$ for a value larger than $0.5$.\n",
    "\n",
    "## Multi-class Classification\n",
    "\n",
    "In binary classification the data $\\mathcal{D}$ is of the form\n",
    "\n",
    "$$\\mathcal{D} = \\{ (x_i, y_i)~|~x_i \\in \\mathbb{R}^d, y_i \\in \\{-1, 1\\} \\quad \\text{for } i=1,\\dots,n \\},$$\n",
    "\n",
    "i.e., the (discrete) label has either value $-1$ or $1$ representing the two possible classes. In the multi-class setting the data is of the form\n",
    "\n",
    "$$\\mathcal{D} = \\{ (x_i, y_i)~|~x_i \\in \\mathbb{R}^d, y_i \\in \\{C_1, \\dots, C_k \\} \\quad \\text{for } i=1,\\dots,n \\},$$\n",
    "\n",
    "where $C_1, \\dots, C_k$ represent the $k$ different classes.\n",
    "\n",
    "Similarly to the multi-output case in Gaussian process regression, several different approaches exist for multi-class classification. First of all, the Laplace approximtion discussed in {ref}```sec:binaryclass``` can be generalized to a multi-class Laplace approximation (refer to Section 3.5 in {cite}```Rasmussen2006```). Moreover, there exist general approaches to extend binary classifiers to multi-class tasks:\n",
    "\n",
    "- One-vs-Rest / One-vs-All:\n",
    "    - $k$ binary classifiers are trained by creating binary labels with the classes $C_k$ (encoded as $1$) and all remaining classes (encoded as $-1$)\n",
    "    - For a test point each classifier predicts the probability for class $C_k$ and the class with the highest probability is assigned\n",
    "- One-vs-One:\n",
    "    - A binary problem is created by considering only two distinct classes $C_k$ and $C_l$, $k \\ne l$, (each possible pair of classes) and fitting a binary classifier (results in $\\frac{k~(k-1)}{2}$ classifiers)\n",
    "    - Each model predicts a class probability and the class with most votes or alternatively, the class with the highest sum of probabilities is assigned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a368bdb2",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    ":style: plain\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
