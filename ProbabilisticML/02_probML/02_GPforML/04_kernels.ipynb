{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d661e0cc",
   "metadata": {},
   "source": [
    "# Kernel Functions\n",
    "\n",
    "## Examples of Kernels \n",
    "\n",
    "As mentioned before, the choice of the kernel (the prior distribution) determines the properties of the Gaussian process and consequently also of the regression model. In the present section, we define the most common covariance functions and visualize the corresponding sample paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d43afde",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, FFMpegFileWriter\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# animation for paths of a Gaussian process\n",
    "# kernel specifies the covariance function\n",
    "# x-values from -xbnd to xbnd\n",
    "# y-axis has values from -ybnd to ybnd\n",
    "# saves gif if string is passed to name\n",
    "def get_anim(kernel, xbnd=10., ybnd=2.5, name=None):\n",
    "    nb_steps = 500\n",
    "    delta_x = 2*xbnd / nb_steps\n",
    "    x = np.arange(-xbnd, xbnd, delta_x)\n",
    "    mean = np.zeros_like(x)\n",
    "    cov = kernel(x.reshape(-1, 1))\n",
    "\n",
    "    # First set up the figure, the axis, and the plot element we want to animate\n",
    "    fig = plt.figure(num=' ', figsize=(10, 8))\n",
    "    ax = plt.axes(xlim=(-xbnd, xbnd), ylim=(-ybnd, ybnd))\n",
    "    ax.set_xlabel('x', fontsize=13)\n",
    "    ax.set_ylabel('f(x)', fontsize=13)\n",
    "    line, = ax.plot([], [], lw=2)\n",
    "\n",
    "    # initialization function: plot the background of each frame\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        return line,\n",
    "\n",
    "    # animation function.  This is called sequentially\n",
    "    def animate(i):\n",
    "        x = np.arange(-xbnd, xbnd, delta_x)\n",
    "        samples = np.random.multivariate_normal(mean, cov)\n",
    "        line.set_data(x, samples)\n",
    "        return line,\n",
    "\n",
    "    # call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "    anim = FuncAnimation(fig, animate, init_func=init,\n",
    "                         frames=50, interval=400, blit=True) #, repeat=False)\n",
    "    if name is not None:\n",
    "        anim.save(name + '.gif', writer=FFMpegFileWriter(fps=2)) #, dpi=200)\n",
    "    return anim\n",
    "\n",
    "# common kernels:\n",
    "from sklearn.gaussian_process.kernels import DotProduct # linear kernel\n",
    "from sklearn.metrics.pairwise import polynomial_kernel # polynomial kernel\n",
    "from sklearn.gaussian_process.kernels import RBF # squared exponential kernel\n",
    "from sklearn.gaussian_process.kernels import Matern # Matern kernel\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic # rational quadratic kernel\n",
    "from sklearn.gaussian_process.kernels import ExpSineSquared # periodic kernel\n",
    "\n",
    "# # example\n",
    "# kernel = Matern(nu=1.5) \n",
    "# anim = get_anim(kernel, xbnd=4., ybnd=5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f13c0f",
   "metadata": {},
   "source": [
    "### Linear Kernel\n",
    "\n",
    "The linear kernel reads\n",
    "\n",
    "$$k(x, x^{\\prime}) = \\beta_0 + \\langle x, x^{\\prime} \\rangle \\quad \\text{for } x, x^{\\prime} \\in \\mathbb{R}^d,$$\n",
    "\n",
    "where $\\beta_0 \\ge 0$ and $\\langle x, x^{\\prime} \\rangle$ denotes the scalar product of $x$ and $x^{\\prime}$. In the subsequent animation, we used $\\beta_0 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87313e",
   "metadata": {},
   "source": [
    "<img src=\"linear.gif\" width=\"800px\" alt=\"Linear kernel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866fdaab",
   "metadata": {},
   "source": [
    "### Polynomial Kernel\n",
    "\n",
    "The polynomial kernel is constructed by exponentiation of the linear kernel, i.e.,\n",
    "\n",
    "$$k(x, x^{\\prime}) = \\big(\\beta_0 + \\langle x, x^{\\prime} \\rangle\\big)^p \\quad \\text{for } x, x^{\\prime} \\in \\mathbb{R}^d,$$\n",
    "\n",
    "where $\\beta_0 \\ge 0$ and $p \\in \\mathbb{N}$. In the subsequent animation, we used $\\beta_0 = 1$ and $p=3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe3a15",
   "metadata": {},
   "source": [
    "<img src=\"polynomial.gif\" width=\"800px\" alt=\"Polynomial kernel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90d9c50",
   "metadata": {},
   "source": [
    "### Squared Exponential Kernel\n",
    "\n",
    "The squared exponential kernel is possibly the most important kernel in kernel-based machine learning. It is also called **radial basis function (RBF) kernel**. It is defined by \n",
    "\n",
    "$$k(x, x^{\\prime}) = \\exp \\big(-\\frac{r^2}{2~l^2} \\big)$$\n",
    "\n",
    "where $r = |x - x^{\\prime}|$ for $x, x^{\\prime} \\in \\mathbb{R}^d$. $l$ is called **length scale** and is assumed to be positive. In particular, the squared exponential kernel is isotropic. In the subsequent animation, we used $l=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dcdae4",
   "metadata": {},
   "source": [
    "<img src=\"rbf.gif\" width=\"800px\" alt=\"RBF kernel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b6178",
   "metadata": {},
   "source": [
    "### Exponential Kernel\n",
    "\n",
    "The (absolute) exponential kernel is another isotropic kernel and is defined by \n",
    "\n",
    "$$k(x, x^{\\prime}) = \\exp \\big(-\\frac{r}{l} \\big)$$\n",
    "\n",
    "where $r = |x - x^{\\prime}|$ for $x, x^{\\prime} \\in \\mathbb{R}^d$ and $l$ is the length scale. In the subsequent animation, we used $l=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddf23d",
   "metadata": {},
   "source": [
    "<img src=\"exp.gif\" width=\"800px\" alt=\"Exp kernel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71029ca",
   "metadata": {},
   "source": [
    "### Mat&eacute;rn Kernel\n",
    "\n",
    "The Mat&eacute;rn kernel denotes a class of isotropic kernels which is parametrized by a parameter $\\nu > 0$. The kernel is given by\n",
    "\n",
    "$$k_{\\nu}(x, x^{\\prime}) = \\frac{2^{1 - \\nu}}{\\Gamma(\\nu)}~\\Big(\\frac{\\sqrt{2\\nu}~ r}{l}\\Big)^{\\nu} ~K_{\\nu} \\Big(\\frac{\\sqrt{2\\nu}~r}{l}\\Big),$$\n",
    "\n",
    "where $r = |x - x^{\\prime}|$ for $x, x^{\\prime} \\in \\mathbb{R}^d$, $l >0$ is the length scale, $\\Gamma$ is the gamma function and $K_{\\nu}$ is a modified Bessel function.\n",
    "\n",
    "For $\\nu = 0.5$ the Mat&eacute;rn kernel becomes the exponential kernel and for $\\nu \\rightarrow \\infty$ the Mat&eacute;rn kernel approaches the squared exponential kernel. Thus, $\\nu$ determines the roughness of the samples paths and the samples paths get smoother as $\\nu$ increases.\n",
    "\n",
    "The most interesting other cases for machine learning are $\\nu = 1.5$ and $\\nu = 2.5$. It holds\n",
    "\n",
    "$$k_{\\nu = 1.5}(x, x^{\\prime}) = \\Big( 1 + \\frac{\\sqrt{3}~r}{l} \\Big)~\\exp\\Big(\\frac{\\sqrt{3}~r}{l}\\Big)$$\n",
    "\n",
    "and \n",
    "\n",
    "$$k_{\\nu = 2.5}(x, x^{\\prime}) = \\Big( 1 + \\frac{\\sqrt{5}~r}{l} + \\frac{5~r^2}{3~l^2} \\Big)~\\exp\\Big(\\frac{\\sqrt{5}~r}{l}\\Big).$$\n",
    "\n",
    "For both cases, sample paths are animated below with $l=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e114cd6c",
   "metadata": {},
   "source": [
    "$\\nu = 1.5$:\n",
    "\n",
    "<img src=\"matern15.gif\" width=\"800px\" alt=\"Matern 1.5 kernel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c0c7a",
   "metadata": {},
   "source": [
    "$\\nu = 2.5$:\n",
    "\n",
    "<img src=\"matern25.gif\" width=\"800px\" alt=\"Matern 2.5 kernel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25f0f8",
   "metadata": {},
   "source": [
    "### Rational Quadratic Kernel\n",
    "\n",
    "The rational quadratic kernel denotes a family of isotropic kernels with parameter $\\alpha > 0$ defined by\n",
    "\n",
    "$$k_{\\alpha}(x, x^{\\prime}) = \\Big( 1 + \\frac{r^2}{2\\alpha~l^2} \\Big)^{-\\alpha}$$\n",
    "\n",
    "with $r = |x - x^{\\prime}|$ for $x, x^{\\prime} \\in \\mathbb{R}^d$ and $l > 0$. This kernel can be seen as mixture of squared exponential kernels with different length scales (see (4.20) in {cite}```Rasmussen2006```). In the subsequent animation, we used $\\alpha = l = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eecfc7c",
   "metadata": {},
   "source": [
    "<img src=\"rq.gif\" width=\"800px\" alt=\"rq kernel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea382bf1",
   "metadata": {},
   "source": [
    "### Periodic Kernel\n",
    "\n",
    "The periodic kernel is also called Exp-Sine-Squared kernel. It is given by\n",
    "\n",
    "$$k(x, x^{\\prime}) = \\exp\\Big( - \\frac{2~\\sin^2\\big(\\pi \\frac{r}{p}\\big)}{l^2}\\Big)$$\n",
    "\n",
    "with $r = |x - x^{\\prime}|$ for $x, x^{\\prime} \\in \\mathbb{R}^d$. $l$ is the length scale and $p$ the **periodicity**. To illustrate the sample paths we used $l=p=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5445d45",
   "metadata": {},
   "source": [
    "<img src=\"periodic.gif\" width=\"800px\" alt=\"Periodic kernel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a57fb",
   "metadata": {},
   "source": [
    "### Brownian Motion Kernel\n",
    "\n",
    "Since we illustrated the sample paths of Brownian motion as an example for a stochastic process, we state its covariance function. Nevertheless, this kernel is not of interest for our machine learning applications. It holds\n",
    "\n",
    "$$k(s, t) = \\text{min}(s, t)$$\n",
    "\n",
    "for $s, t \\in \\mathbb{R}_{> 0}$.\n",
    "\n",
    "(sec:combofkernels)=\n",
    "## Combination and Modification of Kernels\n",
    "\n",
    "It is possible to obtain new covariance functions from known kernels by recombination and/or modification.\n",
    "\n",
    "Let $(f_1(x))_{x \\in \\mathbb{R}^d}$ and $(f_2(x))_{x \\in \\mathbb{R}^d}$ be two independent centered Gaussian processes with kernels $k_1$ and $k_2$, respectively. Moreover, let $a : \\mathbb{R}^d \\rightarrow \\mathbb{R}_{> 0}$. Then, sums and products can be used to generate new kernels $k$ and Gaussian processes $f$ from old ones:\n",
    "\n",
    "| Gaussian process | kernel $k(x, x^{\\prime})$ |\n",
    "|:--------------------------|----------:|\n",
    "| $f_1 + f_2$ | $k_1(x, x^{\\prime})+k_2(x, x^{\\prime})$ |\n",
    "| $f_1 f_2$ | $k_1(x, x^{\\prime}) k_2(x, x^{\\prime})$ |\n",
    "| $a f_1$ | $a(x) k_1(x, x^{\\prime}) a(x^{\\prime})$ |\n",
    "\n",
    "Of course, the three approaches can be combined arbitrarily.\n",
    "\n",
    "For example, by multiplication of the periodic kernel with the squared exponential kernel the **locally periodic kernel** is constructed:\n",
    "\n",
    "$$k(x, x^{\\prime}) = \\exp\\Big( - \\frac{2~\\sin^2\\big(\\pi \\frac{r}{p}\\big)}{l^2}\\Big) \\exp \\Big(-\\frac{r^2}{2~l^2} \\Big),$$\n",
    "\n",
    "where $r = |x - x^{\\prime}|$ for $x, x^{\\prime} \\in \\mathbb{R}^d$.\n",
    "\n",
    "The sample paths are indeed locally periodic, i.e., the periodic part changes over time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "889b52e3",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "kernel1 = ExpSineSquared()\n",
    "kernel2 = RBF()\n",
    "\n",
    "def kernel(x):\n",
    "    return np.multiply(kernel1(x), kernel2(x))\n",
    "\n",
    "# anim = get_anim(kernel, xbnd=4., ybnd=5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb825be8",
   "metadata": {},
   "source": [
    "<img src=\"locperiodic.gif\" width=\"800px\" alt=\"locally periodic kernel\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ca735",
   "metadata": {},
   "source": [
    "Furthermore, **scaling of a Gaussian process** with kernel $k$ by a constant $\\sigma \\ne 0$ (i.e., choosing $a(x) = \\sigma$ in the notation above) yields the kernel $\\sigma^2 k$. This is also a common approach to modify kernel functions.\n",
    "\n",
    "Another possibility create **anisotropic versions of isotropic kernels** by modification of the euclidean distance. Recall that most of the examples stated above are indeed isotropic. The (squared) distance\n",
    "\n",
    "$$r^2 = |x - x^{\\prime}|^2 = \\sum_{i=1}^d \\big(x_i - x^{\\prime}_i\\big)^2 = \\big(x - x^{\\prime}\\big)^T \\big(x - x^{\\prime}\\big)$$\n",
    "\n",
    "for $x, x^{\\prime} \\in \\mathbb{R}^d$ can be replaced by\n",
    "\n",
    "$$r_M^2 = \\big(x - x^{\\prime}\\big)^T M \\big(x - x^{\\prime}\\big),$$\n",
    "\n",
    "where $M$ is a positive definite matrix. A very common special case is the diagonal matrix\n",
    "\n",
    "$$M = \\begin{pmatrix} l^2_1 & & 0 \\\\ & \\ddots & \\\\ 0 & & l^2_d \\end{pmatrix}$$\n",
    "\n",
    "with positive diagonal elements which results in \n",
    "\n",
    "$$r_M^2 = \\sum_{i=1}^d \\frac{\\big(x_i - x^{\\prime}_i\\big)^2}{l^2_i}$$\n",
    "\n",
    "The values $l_1, \\dots, l_d$ are treated as hyperparameters of the kernel and are used to introduce **component-wise length scales**. For example, the anisotropic RBF kernel is given by\n",
    "\n",
    "$$k(x, x^{\\prime}) = \\exp \\big(-\\frac{r_M^2}{2} \\big) = \\exp \\Big(-\\frac{1}{2}~\\sum_{i=1}^d \\frac{\\big(x_i - x^{\\prime}_i\\big)^2}{l^2_i} \\Big)$$\n",
    "\n",
    "If all length scales coincide (i.e., $l_1 = \\dots = l_d = l$), we reobtain the ordinary RBF kernel.\n",
    "\n",
    "For additional techniques for creating new covariance functions please refer to section 4.2.4 in {cite}```Rasmussen2006```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71017522",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    ":style: plain\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
