{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62c4dd9",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea51ec",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Optimization is already introduced in the context of machine learning as a way to obtain the parameters of a model that minimize the approximation error or a similar metric. In general, optimization is applied to various kinds of problems. For engineers, product and process design optimization, trajectory control. parameter identification and model validation are some of the most important use cases for deploying optimization algorithms. As such, an efficient solution of optimization problems is important and we present a probabilistic strategy in the following.\n",
    "\n",
    "### Exploration vs. Exploitation\n",
    "Various optimization algorithms exist with different advantages and disadvantages. Gradient-based methods often require less iterations compared to e.g. population based methods but they require the gradient and possibly higher order derivatives. Moreover, they may get stuck at local optima or saddle points. As such, multiple starts may be required, which increases the number of iterations.\n",
    "\n",
    "In contrast, population-based methods are often good at *exploration*, i.e. searching the global optimization space for candidate optima. In return, these methods often require more function evaluations compared to gradient-based methods. Moreover, their convergence rate to the exact optimum is often slower compared to the gradient-based methods. In other words, gradient-free methods are often better at finding the *neighbourhood* of the optimum with increasing accuracy over iterations but gradient-based methods are often more efficient at finding the exact optimum given a start point in the *convex* neighbourhood, which will be called *exploitation* from here on. Note that, these statements may not hold for all functions and all algorithms in these categories but they serve as an example of exploration and exploitation trade-off in the context of optimization. This trade-off has a large influence on the choice of the optimization algorithm.\n",
    "\n",
    "### Sample efficiency\n",
    "\n",
    "In practical applications, other properties such as the *sample efficiency* may be more important. Consider the single objective optimization problem [as defined before](https://probabilistic-ml.github.io/lecture-notes/01_fund/04_opt.html#a-formal-definition)\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{arg}\\, \\min_x f(x)\n",
    "\\end{equation}\n",
    "\n",
    "Given that two algorithms can find the optimum $x^* \\in \\mathbb{R}^d$, the one that requires a smaller number of function evaluations $n\\in \\mathbb{N}$ is considered more sample efficient. However, some algorithms may result in different solutions $x^*_1, $x^*_2 \\in \\mathbb{R}^d$ and one or both of of them may be different than the true optimum, for example $f(x^*) < f(x^*_1) < f(x^*_2)$. In this case, further domain knowledge is required to assess the sample efficiency, so that the cost of an evaluation becomes comparable to the cost of a function evaluation. \n",
    "\n",
    "Since the function evaluation may represent anything from expensive physical experiments to long running computations, the sample efficiency has a direct influence on the total costs of designing a product or a process. Remember that analysis of such expensive functions are one of the motivations behind applying machine learning to obtain surrogate functions that approximate these. Thus, a much pragmatic definition of the sample efficiency is adopted here. Given a relatively low budget of function evaluations, the algorithm that achieves the best solution is assumed to be the most sample efficient. \n",
    "\n",
    "### Surrogate-based strategies\n",
    "\n",
    "Using a surrogate model $\\tilde{f}(x) \\approx f(x)$ for the optimization such as a Gaussian process may already decrease the number of required samples. Since the evaluation of this surrogate model is assumed to be much cheaper than the original function, greedy optimization algorithms can be deployed to solve the following problem\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{arg}\\, \\min_x \\tilde{f}(x)\n",
    "\\end{equation}\n",
    "\n",
    "in the hope that $\\mathrm{arg}\\, \\min_x \\tilde{f}(x) \\approx \\mathrm{arg}\\, \\min_x f(x)$, which may not hold if the surrogate model is inaccurate. In this case, improving the accuracy of the model is required, e.g. by increasing the amount of data and thus the number of function evaluations.\n",
    "\n",
    "### Adaptive sampling\n",
    "Adaptive sampling strategies are proposed to increase the sample efficiency of the surrogate-based solutions, where a model is initialized with a small portion of the total budget. At each iteration, new data points are queried and the model is retrained to refine the model accuracy in regions, that are relevant for the solution of the optimization problem. \n",
    "\n",
    "Bayesian optimization {cite}```Mockus1994,Jones2008``` decribes a category of adaptive sampling algorithms, that use a probabilistic surrogate model and solve an *auxiliary* problem by using the so-called *acquisition functions* $a(\\cdot)$. Through the use of model uncertainty, they seek to improve the sample-efficiency of surrogate based solutions. \n",
    "\n",
    "Consider a Gaussian process $\\tilde{f} \\sim \\mathcal{GP}$ as the surrogate model. As mentioned [before](https://probabilistic-ml.github.io/lecture-notes/02_probML/02_GPforML/02_GP.html), each prediction $\\tilde{f}(x) = Y \\sim \\mathcal{N}(\\mu_Y(x), \\sigma_Y(x))$ represents a normal distribution. Thus, the surrogate-based problem from before could be rewritten as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{arg}\\, \\min_x \\mu_Y(x)\n",
    "\\end{equation}\n",
    "\n",
    "From a Bayesian optimization perspective, this acquisition function $a(x)=\\mu_Y(x)$ is called the mean acquisition. More generally, some of the most popular acquisition functions are in form $a: \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ and the Bayesian optimization problem can be denoted as \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{arg}\\, \\min_x a(\\mu_Y(x), \\sigma_Y(x))\n",
    "\\end{equation}\n",
    "\n",
    "Here, two popular acquisition functions are introduced but there are a number of alternatives and constructing useful acquisition functions is an actively researched topic (see [black-box optimization challenge](https://bbochallenge.com)). An overview of some functions can be found [here](https://arxiv.org/pdf/1807.02811.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c057f33",
   "metadata": {},
   "source": [
    "## Upper confidence bound (UCB)\n",
    "\n",
    "The first acquisition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc66fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
