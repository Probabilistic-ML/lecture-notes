{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11cd6a1d",
   "metadata": {},
   "source": [
    "(sec:impprobdistr)=\n",
    "# Important Probability Distributions\n",
    "\n",
    "An extensive collection of important probability distributions can be found on [Wikipedia](https://en.wikipedia.org/wiki/List_of_probability_distributions). In the following subsections, we will shortly review some of them.\n",
    "\n",
    "## Discrete Distributions\n",
    "\n",
    "Note that each discrete probability distribution is completely described by the finite or countable sample space $\\Omega$ and the function $p : \\Omega \\rightarrow [0, 1]$ which specifies the probability of each elementary event.\n",
    "\n",
    "### Bernoulli Distribution\n",
    "\n",
    "The Bernoulli distribution $\\text{B}(1, p)$ is the distribution of a random variable $X$ which takes only two possible values (usually encoded by $0$ and $1$). The two values can be interpreted e.g. as false/true or failure/success. Thus,\n",
    "\n",
    "$$P(X = 1) = p \\quad \\text{for some } p \\in [0, 1]$$ \n",
    "\n",
    "and \n",
    "\n",
    "$$P(X = 0) = q := 1 - p.$$\n",
    "\n",
    "For example, a coin flip can be modelled by a Bernoulli distribution. The outcome heads ($X=1$) has some probabiltity $p \\in [0, 1]$ and the outcome tails ($X=0$) has the complementary probability $q = p - 1$. In the case of a fair coin, it holds $p = 0.5$.  \n",
    "\n",
    "This distribution is of particular importance in machine learning with regard to binary classification.\n",
    "\n",
    "### Categorial Distribution\n",
    "\n",
    "The categorial distribution is also called generalized Bernoulli distribution. Instead of only two different outcomes, it describes a random variable $X$ with $k$ different categories as outcomes (usually encoded by the numbers $1, \\dots, k$). Each category $i \\in \\{1, \\dots, k\\}$ possesses its individual probability\n",
    "\n",
    "$$P(X = i) = p_i.$$\n",
    "\n",
    "Note that the distribution is completely determined by $k-1$ probabilities, since $\\sum_{i=1}^k p_i = 1$. \n",
    "\n",
    "The distribution of a random variable for a fair dice is categorial with $k=6$ and $p_i = \\frac{1}{6}$ for each $k=1,\\dots,6$. In this example, the categories (number of points) are ranked and the variable is called ordinal. Keep in mind that this kind of distribution also models cases with purely categorical observations (e.g., pictures of different pets) and in this case, $i$ is simply a representation of some category, but it makes no sense to rank the categories.  \n",
    "\n",
    "This distribution is of particular importance in machine learning with regard to multiclass classification.\n",
    "\n",
    "### Binomial Distribution\n",
    "\n",
    "The binomial distribution $\\text{B}(n, p)$ has two parameters $n \\in \\mathbb{N}$ and $p \\in [0, 1]$. It describes the number of successes of $n$ independent Bernoulli experiments with parameter $p$. Thus, a random variable $X$ with binomial distribution takes values $\\{0, \\dots, n \\}$ and \n",
    "\n",
    "$$P(X=k) = {{n}\\choose{k}} p^k (1-p)^{n-k} = \\frac{n!}{k!(n-k)!} p^k(1-p)^{n-k} \\quad \\text{for } k \\in \\{0, \\dots, n \\}.$$\n",
    "\n",
    "The binomial coefficient ${{n}\\choose{k}}$ denotes the number of possibilities of exactly $k$ successes in $n$ independent Bernoulli trials.\n",
    "\n",
    "For example, the probability of observing $0$ heads in $9$ flips of a fair coin is\n",
    "\n",
    "$$P(X=0) = \\frac{9!}{0!(9-0)!} 0.5^0~(1-0.5)^{9-0} = 0.5^9 \\approx 0.02\\%.$$\n",
    "\n",
    "(def:geom)=\n",
    "### Geometric Distribution\n",
    "\n",
    "The geometric distribution $\\text{Geom}(p)$ describes the number of independent Bernoulli trials needed to get a success. Hence, it takes values in $\\{1, 2, \\dots\\}$ and \n",
    "\n",
    "$$P(X=k) = (1-p)^{k-1} p \\quad \\text{for } k=1,2,\\dots,$$\n",
    "\n",
    "since $X=k$ means no success in the first $k-1$ Bernoulli trials (with probability $1-p$ each) and finally a success in the $k$-th trial (with probability $p$). Note that $P(X=k) \\rightarrow 0$ as $k \\rightarrow \\infty$ as long as $p \\ne 0$. For example, the probability to observe heads the first time after exactply $10$ trials by tossing a fair coin is \n",
    "\n",
    "$$P(X=10) = (1-0.5)^9 ~0.5 = 0.5^{10} \\approx 0.01\\%.$$\n",
    "\n",
    "Furthermore, in use of the third Kolmogorov axiom, it holds\n",
    "\n",
    "$$P(X >= 10) = \\sum_{k=10}^{\\infty} (1-0.5)^{k-1} ~0.5 = \\frac{0.5^{10}}{1 - 0.5} = 0.5^9 \\approx 0.02\\%.$$\n",
    "\n",
    "In other words, the probability to observe only tails in the first $9$ tosses is approximately $0.02\\%$ in correspondance with the calculation in use of the binomial distribution.\n",
    "\n",
    "### Poisson Distribution\n",
    "\n",
    "The Poisson distribution $\\text{Pois}(\\lambda)$ describes the distribution of a random variable $X$ with values in $\\{0, 1, \\dots \\}$ and is given by\n",
    "\n",
    "$$P(X=k) = \\frac{\\lambda^k e^{-k}}{k!} \\quad \\text{for } k=0,1,\\dots$$\n",
    "\n",
    "and some parameter $\\lambda > 0$. It models the number of events occuring in a fixed (time or space) interval if these events happen with a known constant mean rate and independently of each other. In fact, the expectation is $\\mathbb{E}(X) = \\lambda$ and also $\\text{Cov}(X) = \\lambda$. For example, the following scenarios can be modelled by a Poisson distribution:\n",
    "\n",
    "- radioactive decay: number of decays in a given time period of a radioactive sample\n",
    "- epidemiology: the number of cases of a disease in different cities\n",
    "- sports: the number of goals in a soccer match\n",
    "\n",
    "If $n$ is very large and $p$ is very small the Poisson distribution can be used to approximate the binomial distribtion $\\text{B}(n, p)$ due to the **Poisson limit theorem** which is also called law of rare events.  \n",
    "\n",
    "\n",
    "## Continuous Distributions\n",
    "\n",
    "A continuous distribution is essentially specified by its probability density function.\n",
    "\n",
    "(def:multnormal)= \n",
    "### Normal Distribution\n",
    "\n",
    "The **multivariate normal distribution** or **Gaussian distribution** $\\mathcal{N}(\\mu, \\Sigma)$ is the most important probability distribution with regard to the subsequent chapters. In particular, it is of special importance due to the {ref}```central limit theorem <thm:clt>```.  \n",
    "\n",
    "The multivariate normal distribution is completely charaterized by its expectation $\\mu$ and covariance matrix $\\Sigma$. The general probability distribution function is given by\n",
    "\n",
    "$$\\frac{1}{\\sqrt{(2\\pi)^d |\\Sigma|}} ~\\exp\\Big(-\\frac{1}{2}~(x- \\mu)^T \\Sigma^{-1}(x -\\mu)\\Big) \\quad \\text{for } x \\in \\mathbb{R}^d,$$\n",
    "\n",
    "where $\\mu$ is some vector in $\\mathbb{R}^d$ and $\\Sigma$ is a symmetric and positive definite (i.e., $x^T \\Sigma x > 0$ for each $x \\in \\mathbb{R}^d$) matrix. In particular, $\\Sigma^{-1}$ exists. Consequently, the univariate normal distribution ($d=1$) has the density\n",
    "\n",
    "$$\\frac{1}{\\sqrt{2\\pi \\sigma^2}} ~\\exp\\big(-\\frac{1}{2}~\\frac{(x- \\mu)^2}{\\sigma^2}\\big) \\quad \\text{for } x \\in \\mathbb{R}$$\n",
    "\n",
    "as well as $\\mu \\in \\mathbb{R}$ and $\\sigma^2 > 0$. Since\n",
    "\n",
    "$$ \\int_{\\mathbb{R}} x~\\frac{1}{\\sqrt{2\\pi \\sigma^2}} ~\\exp\\big(-\\frac{1}{2}~\\frac{(x- \\mu)^2}{\\sigma^2}\\big)~dx = \\mu$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\int_{\\mathbb{R}} (x - \\mu)^2~\\frac{1}{\\sqrt{(2\\pi)^d \\sigma^2}} ~\\exp\\big(-\\frac{1}{2}~\\frac{(x- \\mu)^2}{\\sigma^2}\\big)~dx = \\sigma^2,$$\n",
    "\n",
    "it holds $\\mathbb{E}(X) = \\mu$ and $\\text{Cov}(X) = \\sigma^2$ for a normally distributed random variable $X$. This generalizes to the multivariate case, i.e.,\n",
    "\n",
    "$$\\mathbb{E}(X) = \\mu \\quad \\text{ and } \\quad \\text{Cov}(X) = \\Sigma.$$  \n",
    "\n",
    "As mentioned before, in the case $\\mu = 0$ and $\\Sigma = I_d$ (identity matrix) we obtain the **standard normal distribution**.\n",
    "\n",
    "### Beta Distribution\n",
    "\n",
    "The Beta distribution $\\text{Beta}(\\alpha, \\beta)$ is a continuous distribution with support on the interval $[0, 1]$, i.e., the probability of events outside $[0, 1]$ is zero. Its probability density function is given by\n",
    "\n",
    "$$\\frac{x^{\\alpha -1} (1-x)^{\\beta -1}}{\\text{B}(\\alpha, \\beta)} \\mathbb{1}_{[0, 1]}(x) \\quad \\text{for } x \\in \\mathbb{R},$$\n",
    "\n",
    "where $\\text{B}(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}$ and $\\alpha, \\beta > 0$. Here, $\\Gamma$ denotes the so-called Gamma function (an extension of the factorial).\n",
    "\n",
    "### Uniform Distribution\n",
    "\n",
    "The uniform distribtion $U(a, b)$ is a continuous distribution with support $[a, b]$ for some numbers $a < b$. It describes a random variable with arbitrary outcomes between $a$ and $b$. The probability density function reads\n",
    "\n",
    "$$\\frac{1}{b - a} \\mathbb{1}_{[a, b]}(x) \\quad \\text{for } x \\in \\mathbb{R}.$$\n",
    "\n",
    "$U(0, 1)$ is called standard uniform distribution. If a random variable $X$ is $U(0, 1)$-distributed, then $X^n$ is $\\text{Beta}(\\frac{1}{n}, 1)$-distributed. In particular, $U(0, 1) = \\text{Beta}(1, 1)$.\n",
    "\n",
    "### Gamma Distribution\n",
    "\n",
    "The Gamma distribution $\\text{Gamma}(\\alpha, \\beta)$ is a continuous probability distribution with support on $(0, \\infty)$ which contains some important distributions as special cases. Its probability density function is given by\n",
    "\n",
    "$$\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}~x^{\\alpha - 1} \\exp(-\\beta x) ~ \\mathbb{1}_{(0, \\infty)}(x) \\quad \\text{for } x \\in \\mathbb{R},$$\n",
    "\n",
    "where $\\alpha, \\beta > 0$.\n",
    "\n",
    "### Exponential Distribution\n",
    "\n",
    "The exponential distribution $\\text{Exp}(\\lambda)$ is the continuous analogue of the {ref}```geometric distribution<def:geom>```. Its probability density function is given by\n",
    "\n",
    "$$\\lambda \\exp(-\\lambda x)~ \\mathbb{1}_{(0, \\infty)}(x) \\quad \\text{for } x \\in \\mathbb{R},$$\n",
    "\n",
    "where $\\lambda > 0$. It holds $\\text{Exp}(\\lambda) = \\text{Gamma}(1, \\lambda)$.\n",
    "\n",
    "For example, the exponential distribution is used to model the time between two radioactive decays, i.e., the time between two random events which occur independently and at a constant average rate.\n",
    "\n",
    "### Laplace Distribution\n",
    "\n",
    "The Laplace distribution $\\text{Laplace}(\\mu, b)$ has the probability density function \n",
    "\n",
    "$$\\frac{1}{2b}~\\exp\\Big(-\\frac{|x-\\mu|}{b}\\Big) \\quad \\text{for } x \\in \\mathbb{R},$$\n",
    "\n",
    "where $\\mu \\in \\mathbb{R}$ and $b > 0$. \n",
    "\n",
    "Note that the density is a symmetric function around $\\mu$ and for $x > \\mu$ the density equals the pdf of a $\\text{Exp}(\\frac{1}{b})$-distribution (up to translation by $\\mu$). For this reason, the Laplace distribution is also called double exponential distribution.\n",
    "\n",
    "Moreover, the Lapalce distribution is similar to the normal distribution, but the squared difference to $\\mu$ in the exponential function is replace by the absolute difference.\n",
    "\n",
    "### Cauchy Distribution\n",
    "\n",
    "The Cauchy distribution $\\text{Cauchy}(x_0, \\gamma)$ has probability density function\n",
    "\n",
    "$$\\frac{1}{\\pi \\gamma \\big(1 + (\\frac{x - x_0}{\\gamma})^2 \\big)} \\quad \\text{for } x \\in \\mathbb{R},$$\n",
    "\n",
    "where $x_0 \\in \\mathbb{R}$ and $\\gamma > 0$. $\\text{Cauchy}(0, 1)$ is also called standard Cauchy distribution and is the distribution of the ratio of two independent standard normally distributed random variables.  \n",
    "\n",
    "This distribution is well-known, since it does not have a well-defined mean and variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
