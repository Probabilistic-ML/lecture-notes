{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cafe05",
   "metadata": {},
   "source": [
    "# Motivation of Probabilistic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5030a",
   "metadata": {},
   "source": [
    "In {ref}```sec:linregr```, we have discussed a simple linear model in use of different approaches:\n",
    "\n",
    "- MLE / ordinary least squares\n",
    "- MAP with Gaussian prior / ridge regression\n",
    "- MAP with Laplace prior / LASSO\n",
    "- Bayesian linear regression\n",
    "\n",
    "The first three methods yield **point estimates** for the slope $\\beta$. It is possible to include some prior belief by using a MAP estimate, but the result is still an ordinary linear function which can be used to make predictions on unseen inputs. This way it is very hard to quantify the uncertainty of the prediction. *Is it reasonable to assume that the prediction is close to the outcome of a real experiment or is it possible only a rough guess?* This is a huge disadvantage in decision making. However, the Bayesian linear regression yields additional information. The model does not only make a prediction. Instead of a fixed value for $\\beta$, it uses a probability distribution and returns even a distribution of possible outcomes (refer to posterior distribution and posterior predictive distribution in {ref}```sec:bayesianinference```). \n",
    "\n",
    "Hence, a main advantage of Bayesian / probabilistic models is the possibility to include uncertainty into decision making. It is even possible to consider different types of uncertainty. In the example in {ref}```sec:linregr```, we already mentioned the terms **epistemic** and **aleatoric** uncertainty:\n",
    "\n",
    "- epistemic uncertainty: \n",
    "    - uncertainty due to the lack of knowledge of the real world\n",
    "    - can be reduced by more data\n",
    "- aleatoric uncertainty:\n",
    "    - inherent uncertainty of the data\n",
    "    - represents the randomness (noise) in experiments, i.e., it causes different outcomes when repeating the same experiment over and over again\n",
    "    - can not be reduced\n",
    "\n",
    "In the simple linear regression, it was assumed that the noise term (the  aleatoric uncertainty) is normally distributed with zero mean and **known** variance $\\sigma^2$. A more general setting could also include $\\sigma^2$ as a unknown parameter. In this case, the aim is to perform Bayesian inference on $\\beta$ (with Gaussian prior) and $\\sigma^2$ (with inverse gamma distributed prior) simultaneously. Consequently, the resulting Bayesian model contains both types of uncertainty. Additional to the mean prediciton, the posterior predictive distribution contains information on the epistemic uncertainty and estimates the aleaetoric uncertainty as well. Please note that frequentist inference can at least estimate aleatoric uncertainty, e.g., by the variance of samples around the prediction.\n",
    "\n",
    "A drawback of the use of probabilistic models is the **increased computational effort**. In the simple example, we needed first to apply some more mathematics and in addition to the mean of the posterior distribution it is necessary to calculate the variance. This is still an acceptable effort, but one should keep in mind that the posterior (predictive) distribution can not be computed analytically in most applications. Therefore, approximations such as MCMC and variational inference are used which include expensive computations for high dimensional and complex problems. For this reason, these types of models have just become more and more popular in recent years due to the rapid progress in computational power.\n",
    "\n",
    "These properties are highly relevant in more complex problems. After the discussion of more advanced models in the following sections, we will review some important applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
