
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>8. Overview of Further Probabilistic Models &#8212; Introduction to Probabilistic Machine Learning</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/additional.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://probabilistic-ml.github.io/lecture-notes/welcome.html/02_probML/03_overview.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9. Bayesian Optimization" href="../03_appl/01_BO.html" />
    <link rel="prev" title="7.10.3. Gaussian Processes on latent representations" href="02_GPforML/10_advanced/03_DeepGP.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Probabilistic Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../welcome.html">
   Welcome
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Preface
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_preface/01_preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_preface/02_python.html">
   Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_preface/03_notation.html">
   Notation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Fundamentals
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01_fund/01_fundprob.html">
   1. Fundamentals of Probability Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/01_fundprob/01_probabilityspaces.html">
     1.1. Probability Spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/01_fundprob/02_randomvariables.html">
     1.2. Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/01_fundprob/03_independence.html">
     1.3. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/01_fundprob/04_impprobdistr.html">
     1.4. Important Probability Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/01_fundprob/05_essthms.html">
     1.5. Essential Theorems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_fund/02_stat.html">
   2. Bayesian vs. Frequentists View
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01_fund/03_bayes.html">
   3. Bayesian Inference, MAP &amp; MLE
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/03_bayes/01_cointoss.html">
     3.1. Coin Toss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/03_bayes/02_bayesianinference.html">
     3.2. Bayesian Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/03_bayes/03_MLEandMAP.html">
     3.3. MAP and MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/03_bayes/04_linregr.html">
     3.4. Linear Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_fund/04_opt.html">
   4. Optimization Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_fund/05_MLworkflow.html">
   5. Machine Learning Workflow
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probabilistic Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_motivation.html">
   6. Motivation of Probabilistic Models
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="02_GPforML.html">
   7. Gaussian Processes for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="02_GPforML/01_kerneltrick.html">
     7.1. The Kernel Trick: Implicit embeddings from inner products
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_GPforML/02_GP.html">
     7.2. Gaussian Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_GPforML/03_GPregression.html">
     7.3. Gaussian Process Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_GPforML/04_kernels.html">
     7.4. Kernel Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_GPforML/05_hyperparamimpact.html">
     7.5. Impact of Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_GPforML/06_hyperparamselect.html">
     7.6. Selection of Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_GPforML/07_multiout.html">
     7.7. Extension to Multiple Outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_GPforML/08_GPclassification.html">
     7.8. Gaussian Process Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_GPforML/09_examples.html">
     7.9. Examples
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="02_GPforML/10_advanced.html">
     7.10. Advanced Methods
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="02_GPforML/10_advanced/01_SparseGP.html">
       7.10.1. Scalable Gaussian Processes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="02_GPforML/10_advanced/02_NonstationaryGP.html">
       7.10.2. Non-stationary Gaussian Processes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="02_GPforML/10_advanced/03_DeepGP.html">
       7.10.3. Gaussian Processes on latent representations
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   8. Overview of Further Probabilistic Models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../03_appl/01_BO.html">
   9. Bayesian Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03_appl/02_DesignUncertainty.html">
   10. Design Uncertainty Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03_appl/03_RL.html">
   11. Efficient Reinforcement Learning
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org/"><img alt="Jupyter Book" src="https://jupyterbook.org/badge.svg" width="100"></a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/02_probML/03_overview.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Probabilistic-ML/lecture-notes"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/Probabilistic-ML/lecture-notes/blob/master/ProbabilisticML/02_probML/03_overview.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naives-bayes-classification">
   8.1. Naives Bayes Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-mixture-model-for-clustering">
   8.2. Gaussian Mixture Model for Clustering
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayesian-neural-networks">
   8.3. Bayesian Neural Networks
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="overview-of-further-probabilistic-models">
<h1><span class="section-number">8. </span>Overview of Further Probabilistic Models<a class="headerlink" href="#overview-of-further-probabilistic-models" title="Permalink to this headline">¶</a></h1>
<div class="section" id="naives-bayes-classification">
<h2><span class="section-number">8.1. </span>Naives Bayes Classification<a class="headerlink" href="#naives-bayes-classification" title="Permalink to this headline">¶</a></h2>
<p>For a given class <span class="math notranslate nohighlight">\(k\)</span>, we can use Bayes’ theorem</p>
<div class="math notranslate nohighlight">
\[
\begin{align} 
p(C_l~|~x) &amp;= \frac{p(x~|~C_l) ~ p(C_l)}{p(x)}
\end{align} 
\]</div>
<p>with a <strong>naive assumption</strong> that the feature <span class="math notranslate nohighlight">\(x = (x_1, \dots, x_n)\)</span> are <strong>conditionally independent</strong>
which allows us to express the contitional propability term <span class="math notranslate nohighlight">\(p(x~|~C_l)\)</span> as a product of conditional probabilities of individual features <span class="math notranslate nohighlight">\(x_i\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\begin{align} 
p(C_l~|~x) &amp;= \frac{\prod_{i=1}^n p(x_i~|~C_l) ~ p(C_l)}{p(x)}
\end{align} 
\]</div>
<p>We can now omit <span class="math notranslate nohighlight">\(p(x)\)</span>, since it does not depend on <span class="math notranslate nohighlight">\(l\)</span>. Now we can search with a optimization algorithm to find the class which maximises the probability <span class="math notranslate nohighlight">\(p(C_l~|~x)\)</span>. We call this maximimum a posterior (MAP) decision rule.</p>
<div class="math notranslate nohighlight">
\[\hat{y} = \text{argmax}_{l=1,\dots,k} ~\prod_{i=1}^n p(x_i~|~C_l)~p(C_l)  \]</div>
<p>Limits of NBC:
-&gt;aspect covariance</p>
<p>So the independece implies zero covariance between two random variables. A non zero covariance leads to Gaussian Mixture Model.</p>
</div>
<div class="section" id="gaussian-mixture-model-for-clustering">
<h2><span class="section-number">8.2. </span>Gaussian Mixture Model for Clustering<a class="headerlink" href="#gaussian-mixture-model-for-clustering" title="Permalink to this headline">¶</a></h2>
<p>If we generalize the Naive Bayes approach to a non zero covariance matrix, we arrive at Gaussian Mixture Model (GMM) where we assume multivariate Normal distribution</p>
<div class="math notranslate nohighlight">
\[
P(X=x~|~C=j) = \mathcal{N_p}(x;\mu_j,\Sigma_j)
\]</div>
<p>with mean <span class="math notranslate nohighlight">\(\mu \in \mathbb{R}^d \)</span> and covariance matrix <span class="math notranslate nohighlight">\(\Sigma \in \mathbb{R}^{d\times d }\)</span>.</p>
<p>The marginal propability <span class="math notranslate nohighlight">\(P(X)\)</span> is a Gaussian Mixture that is weighted sum of mulitvariate Normal distributions</p>
<div class="math notranslate nohighlight">
\[
P(X=x) = \sum_{j=1}^k\pi_j\mathcal{N_p}(x;\mu_j,\Sigma_j)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\pi_j:= P(C=j)\)</span> is a mixture coeffiecent for which applies</p>
<div class="math notranslate nohighlight">
\[
\sum_{j=1}^J\pi_j=1.
\]</div>
<p>For example a gaussian Mixture would be</p>
<div class="math notranslate nohighlight">
\[
P(X=x) = \frac{1}{2}\mathcal{N_2}(\mu_0,\Sigma_0+\frac{1}{2}\mathcal{N_2}(\mu_1,\Sigma_1)
\]</div>
<p>with</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pi_{0,1}=0.5,\quad \mu_0=[0,0],\quad \mu_1=[1.5,-1.5].\quad \Sigma_{0,1}=
\left[\begin{array}{rr} 
1 &amp; 0.95  \\ 
0.95 &amp; 1  \\ 
\end{array}\right]
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>

<span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">adjusted_mutual_info_score</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;default&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_1</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">cov_1</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">],[</span><span class="mf">0.95</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean_1</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov_1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">data_cigars_1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;cluster&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span> <span class="p">})</span>

<span class="n">mean_2</span><span class="o">=</span><span class="p">[</span><span class="mf">1.5</span><span class="p">,</span><span class="o">-</span><span class="mf">1.5</span><span class="p">]</span>
<span class="n">cov_2</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">],[</span><span class="mf">0.95</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean_2</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov_2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">data_cigars_2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;cluster&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span> <span class="p">})</span>

<span class="n">data_cigars</span> <span class="o">=</span> <span class="n">data_cigars_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data_cigars_2</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_cigars</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;cluster&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$X$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$Y$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03_overview_4_0.png" src="../_images/03_overview_4_0.png" />
</div>
</div>
<p>We now gnerated two clusters which are close to each other but can clearly saperated. A K-means algorithm would not cluster these in proper way. But as we saw above, we already defined a Gaussian Mixture which would obviously fit this data perferctly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gaussian_mixture_proba</span><span class="p">(</span><span class="n">pos_for_pdf</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">pi</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">k</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">pi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">pos_for_pdf</span><span class="p">,</span> <span class="n">mu</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">cov</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> 
    <span class="k">return</span> <span class="n">s</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mean_1</span><span class="p">,</span> <span class="n">mean_2</span><span class="p">])</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cov_1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cov_2</span><span class="p">)])</span>
<span class="n">pi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
<span class="n">pos</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">;</span> <span class="n">pos</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y</span>
<span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">gaussian_mixture_proba</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">,</span> <span class="n">pi</span><span class="o">=</span><span class="n">pi</span><span class="p">),</span> <span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">Greys</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_cigars</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$Y$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$X$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03_overview_8_0.png" src="../_images/03_overview_8_0.png" />
</div>
</div>
<p>As an esay example we had assumed that we already know the GMM parameters to show that the model can fit the data. The big problem is that we need to find these parameters <span class="math notranslate nohighlight">\((\pi_j,\mu_j\Sigma_j)_{j=1,...,k}\)</span> for the gaussian mixture which fits the data best. We will begin with the inference of parameters in GMM</p>
<p>For data <span class="math notranslate nohighlight">\(D={x_i:i=1,...,n}\)</span> and parameters <span class="math notranslate nohighlight">\(\Theta\)</span> model likelihood is given by</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\Theta~|~D)= \prod_{i=1}^nP(X=x_i)=\prod_{i=1}^n\sum_{j=1}^k \pi_j\mathcal{N_p}(x;\mu_j,\Sigma_j)
\]</div>
<p>and log-likelihood is given as</p>
<div class="math notranslate nohighlight">
\[
\log \mathcal{L}(\Theta~|~D)=\sum_{i=1}^n\log\sum_{j=1}^k \pi_j\mathcal{N_p}(x;\mu_j,\Sigma_j)
\]</div>
<p>The question now is how we can infer the parameters of a GMM that best explain the data? Our first idea is to compute the likelihood of the model parameters, given a data set <span class="math notranslate nohighlight">\(D\)</span>. To maximise this likelihood, we can try to simplify the likelihood expression using our standard trick, that is we take the logarithm and maximise the log-likelihood function instead.</p>
<p>Unfortunately, in the GMM this is not as simple as in our previous applications of maximum-likelihood estimation(MLE). We are left  with a logarithm of a sum of Gaussians, for which we cannot compute the derivative in a straight-forward way.</p>
<p><strong>Expectation-Maximisation (EM)</strong></p>
<p>Let us assume we knew the “correct” cluster <span class="math notranslate nohighlight">\(C(i)\)</span> for each <span class="math notranslate nohighlight">\(x_i\in D\)</span>. We can write the likelihood of model parameters <span class="math notranslate nohighlight">\(\Theta\)</span> based on joint distribution</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\Theta~|~D)= \prod_{i=1}^nP(X=x_i,C=C(i)~|~\Theta).
\]</div>
<p>The log-likelihood of the model is</p>
<div class="math notranslate nohighlight">
\[
\log \mathcal{L}(\Theta~|~D)= \sum_{i=1}^n\log P(X=x_i,C=C(i)~|~\Theta).
\]</div>
<p>For a guess of parameters <span class="math notranslate nohighlight">\(\Theta^{(t)} = (\pi_j,\mu_j\Sigma_j)_{j=1,...,k}\)</span> the expected log-likelihood can be calculated as</p>
<div class="math notranslate nohighlight">
\[
E[\log\mathcal{L}(\Theta~|~D)]= \sum_{i=1}^n \sum_{j=1}^k P(C=j~|~X=x_i,\Theta^{(t)})\log P(X=x_i,C=j~|~\Theta).
\]</div>
<p>To find the optimal parameters of the <span class="math notranslate nohighlight">\(k d\)</span>-dimensional multivariate Normal distributions that maximise the likelihood, we can apply a general and powerful iterative approach, the so-called expectation-maximisation (EM) algorithm. It is based on the idea that, rather than maximising the model likelihood based on the marginal probability <span class="math notranslate nohighlight">\(P(X)\)</span>, we can instead use an  estimate for the conditional probability <span class="math notranslate nohighlight">\(P(C~|~X)\)</span> to compute the expected log-likelihood based on the joint distribution <span class="math notranslate nohighlight">\(P(X, C)\)</span>.</p>
<p>To better understand this, let us assume we knew the cluster <span class="math notranslate nohighlight">\(C(i)\)</span> for each observation <span class="math notranslate nohighlight">\(x_i \in D\)</span>. For each we could then calculate the likelihood and log-likelihood function of our model based on the joint distribution <span class="math notranslate nohighlight">\(P(X, C)\)</span>. Unfortunately, we lack the information to which clusters the data points belong. However, we can capture this lack of information based on the conditional probability <span class="math notranslate nohighlight">\(P(C|X)\)</span>, which we can compute for any guess of parameters <span class="math notranslate nohighlight">\(\Theta^{(t)}\)</span>.</p>
<p>For <span class="math notranslate nohighlight">\(j=1,...,k\)</span> we use guessed parameters <span class="math notranslate nohighlight">\(\Theta^{(t)}\)</span> to calculate</p>
<div class="math notranslate nohighlight">
\[
P(C=j~|~X=x_i,\Theta^{(t)})= \frac{\mathcal{N_d}(x;\mu_j,\Sigma_j)\pi_j}{\sum_{j=1}^k\mathcal{N_d}(x;\mu_j,\Sigma_j)}:=\gamma_{ij}.
\]</div>
<p>Update <span class="math notranslate nohighlight">\(\Theta^{(t)}\rightarrow \Theta^{(t+1)}\)</span> such that <span class="math notranslate nohighlight">\(\gamma_{ij}\)</span> and thus <span class="math notranslate nohighlight">\(E[\log\mathcal{L}(\Theta~|~D)]\)</span> is maximal.
With <span class="math notranslate nohighlight">\(N_j:=\sum_{i=1}^n\gamma_{ij}\)</span> expactation-maximising parameters are</p>
<div class="math notranslate nohighlight">
\[
\pi_j = \frac{N_j}{n}, \quad \mu_j = \frac{1}{N_j}\sum_{i=1}^n\gamma_{ij}x_i, \quad \Sigma_j=\frac{1}{N_j}\sum_{i=1}^n\gamma_{ij}(x_i -\mu_j)(x_i-\mu_j)^T.
\]</div>
<p>The expactation-maximisation agorithm iteratively updates  <span class="math notranslate nohighlight">\(\Theta^{(t)}\rightarrow \Theta^{(t+1)}\)</span> to find maximum-likehood parameters</p>
<p>The trick is now to compute <span class="math notranslate nohighlight">\(P(C~|~X)\)</span> based on our current guess of <span class="math notranslate nohighlight">\(\Theta^{(t)}\)</span> and then update the parameters such that <span class="math notranslate nohighlight">\(P(C~|~X)\)</span> and the expected log-likelihood is maximised. Those maximum parameters can actually be determined by taking the
derivative of the conditional probability (the constraint <span class="math notranslate nohighlight">\(\sum_{j=1}\pi_j=1\)</span> requires quadratic programming to find <span class="math notranslate nohighlight">\(\pi_j\)</span>).</p>
<p>We can now use the updated parameters to get a better estimate for the conditional probability, so we can simply repeat the procedure. In each step, we first compute the expectation for the model likelihood and then find the parameters that maximise this expectation, which is why the algorithm is called expectation-maximisation.</p>
<p>This yields an iterative algorithm, which starts from an initial guess of the model parameters and then, step-by-step, updates the model parameters to iteratively increase the model likelihood until we reach a maximum.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_cigars</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]])</span>
<span class="n">data_cigars</span><span class="p">[</span><span class="s1">&#39;cluster_predicted&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_cigars</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;cluster_predicted&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_cigars</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$X$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$Y$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;$Y$&#39;)
</pre></div>
</div>
<img alt="../_images/03_overview_16_1.png" src="../_images/03_overview_16_1.png" />
</div>
</div>
<p>To visualize these Expectiation Maximisation algorithm we show “EM clustering of Old Faithful eruption data” from Wikipedia.</p>
<p><a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm"> <left><img alt="https://upload.wikimedia.org/wikipedia/commons/6/69/EM_Clustering_of_Old_Faithful_data.gif" src="https://upload.wikimedia.org/wikipedia/commons/6/69/EM_Clustering_of_Old_Faithful_data.gif" /></left></a></p>
<p>However this approach is not limited to gaussian. A mixture model could persist of any distributon.</p>
</div>
<div class="section" id="bayesian-neural-networks">
<h2><span class="section-number">8.3. </span>Bayesian Neural Networks<a class="headerlink" href="#bayesian-neural-networks" title="Permalink to this headline">¶</a></h2>
<p>“A BNN is defined slightly differently across the literature,but a common definition is that a BNN is a stochastic artificial neural network trained using Bayesian inference.” <span id="id1">[<a class="reference internal" href="#id26">1</a>]</span>
The goal of a general artifial neural network(ANN) is to represent any funtion <span class="math notranslate nohighlight">\(y = g(x)\)</span>. The simplest function, a linear mapping, can be build by one neuron which have exactly one weight to repreduce the slope and a bias to represent the offset of the linear mapping. For a more complex or general approach we concat and stack several of these neuron together to achieve more complex functions. We also add in each neuron an activation function which can turn the neuron on or (partly) off. As example see the picture below.</p>
<p><a href="https://en.wikipedia.org/wiki/Artificial_neural_network"> <left><img alt="https://upload.wikimedia.org/wikipedia/commons/e/e4/Artificial_neural_network.svg" src="https://upload.wikimedia.org/wikipedia/commons/e/e4/Artificial_neural_network.svg" /></left></a></p>
<p>A deep neural network is defined with input layer, a output layer and at least one hidden layer in between as seen in picture above. Here we want to finde the optimal parameters <span class="math notranslate nohighlight">\(\theta  = (W,b)\)</span> where <span class="math notranslate nohighlight">\(W\)</span> is the weights and <span class="math notranslate nohighlight">\(b\)</span> are the biases of the network. The approach here is to approximate a minimal cost point estimate of the network parameters <span class="math notranslate nohighlight">\(\theta\)</span>, a single value for each parameter, using the back-propagation algorithm.</p>
<p><strong>Stochastic neural networks</strong> are a type of ANNs built by introducing stochastic components into the network. This can be done by given the network a stochastic activation or stochastics weights. This is graphically shown underneath from <span id="id2">[<a class="reference internal" href="#id26">1</a>]</span>.</p>
<p><a href="https://arxiv.org/pdf/2007.06823.pdf"> <left><a class="reference internal" href="../_images/NNintro.PNG"><img alt="NN,SNN" src="../_images/NNintro.PNG" style="width: 800px;" /></a></left></a></p>
<p>On the left we see point estimate. In the middle are stochastic activations and on the right stochastics weights.The main goal of using a stochastic neural network architecture is to get a better idea of the uncertainty associated with the underlying processes. This is achieved by comparing the predictions of several sampled model parameterizations <span class="math notranslate nohighlight">\(\theta\)</span>. When the different models match, the uncertainty is low. If they do not match, then the uncertainty is high. This process can be summarized as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\theta \sim p(\theta) \\
y=g_0(x)+ \epsilon
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\epsilon\)</span> is a random noise. And a <strong>BNN</strong> is a stochastical network which uses Baysian inference as <a class="reference external" href="http://training.To">training.To</a> design an BNN we make a choice about the network architecture. Then we need to choose a stochstic model which means a prior distribution over possible model parametrizations <span class="math notranslate nohighlight">\(p(\theta)\)</span> and a prior confindence in the predictive power of the model <span class="math notranslate nohighlight">\(P(y|x,\theta)\)</span>. With the assumption of independence between the input variables <span class="math notranslate nohighlight">\(D=(x,y)\)</span> and the model parameters <span class="math notranslate nohighlight">\(\theta\)</span> and the use of bayes theorem the posterior can be written as</p>
<div class="math notranslate nohighlight">
\[
p(\theta|x,y)= \frac{p(y|x,\theta)p(\theta)}{\int_{\theta}p(y|x,\theta')p(\theta')d\theta'}.
\]</div>
<p>To compute this, there are two broad approaches available: Markov Monto Carlo Chain (MCMC) and Variational Inference. For predictions we are interested in the marginal probility distribution <span class="math notranslate nohighlight">\(p(y|x,D)\)</span> which quantifies the uncertainty of the model prediction. Usually a model averaging is done for prediction:</p>
<div class="math notranslate nohighlight">
\[
\hat y = \frac{1}{|\Theta|}\sum_{\theta_i \in \Theta}g_{\theta_i}(x)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\Theta\)</span> is a collection of samples from <span class="math notranslate nohighlight">\(p(\theta|D)\)</span> and <span class="math notranslate nohighlight">\(\hat y\)</span> is the prediction.</p>
<p>We will now take a look on a implemtation example for BNN in <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code> with the “red wine quality” dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_train_and_test_splits</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># We prefetch with a buffer the same size as the dataset because th dataset</span>
    <span class="c1"># is very small and fits into memory.</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;wine_quality&quot;</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
        <span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">dataset_size</span><span class="p">)</span>
        <span class="o">.</span><span class="n">cache</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="c1"># We shuffle with a buffer the same size as the dataset.</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_units</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>


<span class="k">def</span> <span class="nf">run_experiment</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">):</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">),</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">RootMeanSquaredError</span><span class="p">()],</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Start training the model...&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model training finished.&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">rmse</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train RMSE: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">rmse</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluating model performance...&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">rmse</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test RMSE: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">rmse</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FEATURE_NAMES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;fixed acidity&quot;</span><span class="p">,</span>
    <span class="s2">&quot;volatile acidity&quot;</span><span class="p">,</span>
    <span class="s2">&quot;citric acid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;residual sugar&quot;</span><span class="p">,</span>
    <span class="s2">&quot;chlorides&quot;</span><span class="p">,</span>
    <span class="s2">&quot;free sulfur dioxide&quot;</span><span class="p">,</span>
    <span class="s2">&quot;total sulfur dioxide&quot;</span><span class="p">,</span>
    <span class="s2">&quot;density&quot;</span><span class="p">,</span>
    <span class="s2">&quot;pH&quot;</span><span class="p">,</span>
    <span class="s2">&quot;sulphates&quot;</span><span class="p">,</span>
    <span class="s2">&quot;alcohol&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">def</span> <span class="nf">create_model_inputs</span><span class="p">():</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">FEATURE_NAMES</span><span class="p">:</span>
        <span class="n">inputs</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">feature_name</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span>
</pre></div>
</div>
</div>
</div>
<p>Experiment 1: standard neural network
We create a standard deterministic neural network model as a baseline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_baseline_model</span><span class="p">():</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">create_model_inputs</span><span class="p">()</span>
    <span class="n">input_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">())]</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">input_values</span><span class="p">)</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">features</span><span class="p">)</span>

    <span class="c1"># Create hidden layers with deterministic weights using the Dense layer.</span>
    <span class="k">for</span> <span class="n">units</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">features</span><span class="p">)</span>
    <span class="c1"># The output is deterministic: a single point estimate.</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">features</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">dataset_size</span> <span class="o">=</span> <span class="mi">4898</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dataset_size</span> <span class="o">*</span> <span class="mf">0.85</span><span class="p">)</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">get_train_and_test_splits</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">mse_loss</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()</span>
<span class="n">baseline_model</span> <span class="o">=</span> <span class="n">create_baseline_model</span><span class="p">()</span>
<span class="n">run_experiment</span><span class="p">(</span><span class="n">baseline_model</span><span class="p">,</span> <span class="n">mse_loss</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\Users\nifri004\tensorflow_datasets\wine_quality\white\1.0.0...</span>
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dl Size...: 0 MiB [00:01, ? MiB/s]
Dl Completed...: 100%|██████████| 1/1 [00:01&lt;00:00,  1.61s/ url]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">Dataset wine_quality downloaded and prepared to C:\Users\nifri004\tensorflow_datasets\wine_quality\white\1.0.0. Subsequent calls will reuse this data.</span>
Start training the model...
Epoch 1/100
17/17 [==============================] - 2s 30ms/step - loss: 27.7581 - root_mean_squared_error: 5.2686 - val_loss: 27.2702 - val_root_mean_squared_error: 5.2221
Epoch 2/100
17/17 [==============================] - 0s 7ms/step - loss: 25.6176 - root_mean_squared_error: 5.0614 - val_loss: 25.6362 - val_root_mean_squared_error: 5.0632
Epoch 3/100
17/17 [==============================] - 0s 7ms/step - loss: 23.7927 - root_mean_squared_error: 4.8778 - val_loss: 23.8602 - val_root_mean_squared_error: 4.8847
Epoch 4/100
17/17 [==============================] - 0s 8ms/step - loss: 22.0371 - root_mean_squared_error: 4.6944 - val_loss: 22.0170 - val_root_mean_squared_error: 4.6922
Epoch 5/100
17/17 [==============================] - 0s 8ms/step - loss: 20.3301 - root_mean_squared_error: 4.5089 - val_loss: 20.1654 - val_root_mean_squared_error: 4.4906
Epoch 6/100
17/17 [==============================] - 0s 8ms/step - loss: 18.6745 - root_mean_squared_error: 4.3214 - val_loss: 18.3574 - val_root_mean_squared_error: 4.2845
Epoch 7/100
17/17 [==============================] - 0s 10ms/step - loss: 17.0812 - root_mean_squared_error: 4.1329 - val_loss: 16.6430 - val_root_mean_squared_error: 4.0796
Epoch 8/100
17/17 [==============================] - 0s 10ms/step - loss: 15.5484 - root_mean_squared_error: 3.9431 - val_loss: 15.0349 - val_root_mean_squared_error: 3.8775
Epoch 9/100
17/17 [==============================] - 0s 9ms/step - loss: 14.0806 - root_mean_squared_error: 3.7524 - val_loss: 13.4975 - val_root_mean_squared_error: 3.6739
Epoch 10/100
17/17 [==============================] - 0s 8ms/step - loss: 12.6731 - root_mean_squared_error: 3.5599 - val_loss: 12.0502 - val_root_mean_squared_error: 3.4713
Epoch 11/100
17/17 [==============================] - 0s 8ms/step - loss: 11.3346 - root_mean_squared_error: 3.3667 - val_loss: 10.6872 - val_root_mean_squared_error: 3.2691
Epoch 12/100
17/17 [==============================] - 0s 10ms/step - loss: 10.0690 - root_mean_squared_error: 3.1732 - val_loss: 9.4181 - val_root_mean_squared_error: 3.0689
Epoch 13/100
17/17 [==============================] - 0s 9ms/step - loss: 8.8843 - root_mean_squared_error: 2.9807 - val_loss: 8.2357 - val_root_mean_squared_error: 2.8698
Epoch 14/100
17/17 [==============================] - 0s 11ms/step - loss: 7.7851 - root_mean_squared_error: 2.7902 - val_loss: 7.1515 - val_root_mean_squared_error: 2.6742
Epoch 15/100
17/17 [==============================] - 0s 11ms/step - loss: 6.7735 - root_mean_squared_error: 2.6026 - val_loss: 6.1706 - val_root_mean_squared_error: 2.4841
Epoch 16/100
17/17 [==============================] - 0s 8ms/step - loss: 5.8501 - root_mean_squared_error: 2.4187 - val_loss: 5.2849 - val_root_mean_squared_error: 2.2989
Epoch 17/100
17/17 [==============================] - 0s 9ms/step - loss: 5.0139 - root_mean_squared_error: 2.2392 - val_loss: 4.4910 - val_root_mean_squared_error: 2.1192
Epoch 18/100
17/17 [==============================] - 0s 9ms/step - loss: 4.2652 - root_mean_squared_error: 2.0652 - val_loss: 3.7917 - val_root_mean_squared_error: 1.9472
Epoch 19/100
17/17 [==============================] - 0s 9ms/step - loss: 3.6021 - root_mean_squared_error: 1.8979 - val_loss: 3.1764 - val_root_mean_squared_error: 1.7822
Epoch 20/100
17/17 [==============================] - 0s 8ms/step - loss: 3.0219 - root_mean_squared_error: 1.7384 - val_loss: 2.6503 - val_root_mean_squared_error: 1.6280
Epoch 21/100
17/17 [==============================] - 0s 9ms/step - loss: 2.5208 - root_mean_squared_error: 1.5877 - val_loss: 2.2044 - val_root_mean_squared_error: 1.4847
Epoch 22/100
17/17 [==============================] - 0s 9ms/step - loss: 2.0963 - root_mean_squared_error: 1.4479 - val_loss: 1.8331 - val_root_mean_squared_error: 1.3539
Epoch 23/100
17/17 [==============================] - 0s 8ms/step - loss: 1.7439 - root_mean_squared_error: 1.3206 - val_loss: 1.5276 - val_root_mean_squared_error: 1.2360
Epoch 24/100
17/17 [==============================] - 0s 10ms/step - loss: 1.4536 - root_mean_squared_error: 1.2057 - val_loss: 1.2837 - val_root_mean_squared_error: 1.1330
Epoch 25/100
17/17 [==============================] - 0s 13ms/step - loss: 1.2243 - root_mean_squared_error: 1.1065 - val_loss: 1.0982 - val_root_mean_squared_error: 1.0480
Epoch 26/100
17/17 [==============================] - 0s 9ms/step - loss: 1.0490 - root_mean_squared_error: 1.0242 - val_loss: 0.9646 - val_root_mean_squared_error: 0.9821
Epoch 27/100
17/17 [==============================] - 0s 8ms/step - loss: 0.9248 - root_mean_squared_error: 0.9617 - val_loss: 0.8765 - val_root_mean_squared_error: 0.9362
Epoch 28/100
17/17 [==============================] - 0s 8ms/step - loss: 0.8453 - root_mean_squared_error: 0.9194 - val_loss: 0.8291 - val_root_mean_squared_error: 0.9105
Epoch 29/100
17/17 [==============================] - 0s 9ms/step - loss: 0.8024 - root_mean_squared_error: 0.8958 - val_loss: 0.8094 - val_root_mean_squared_error: 0.8997
Epoch 30/100
17/17 [==============================] - 0s 8ms/step - loss: 0.7857 - root_mean_squared_error: 0.8864 - val_loss: 0.8073 - val_root_mean_squared_error: 0.8985
Epoch 31/100
17/17 [==============================] - 0s 8ms/step - loss: 0.7816 - root_mean_squared_error: 0.8841 - val_loss: 0.8053 - val_root_mean_squared_error: 0.8974
Epoch 32/100
17/17 [==============================] - 0s 12ms/step - loss: 0.7789 - root_mean_squared_error: 0.8825 - val_loss: 0.8032 - val_root_mean_squared_error: 0.8962
Epoch 33/100
17/17 [==============================] - 0s 9ms/step - loss: 0.7766 - root_mean_squared_error: 0.8813 - val_loss: 0.8007 - val_root_mean_squared_error: 0.8948
Epoch 34/100
17/17 [==============================] - 0s 9ms/step - loss: 0.7741 - root_mean_squared_error: 0.8798 - val_loss: 0.7988 - val_root_mean_squared_error: 0.8938
Epoch 35/100
17/17 [==============================] - 0s 10ms/step - loss: 0.7717 - root_mean_squared_error: 0.8784 - val_loss: 0.7958 - val_root_mean_squared_error: 0.8921
Epoch 36/100
17/17 [==============================] - 0s 9ms/step - loss: 0.7689 - root_mean_squared_error: 0.8768 - val_loss: 0.7918 - val_root_mean_squared_error: 0.8898
Epoch 37/100
17/17 [==============================] - 0s 8ms/step - loss: 0.7660 - root_mean_squared_error: 0.8752 - val_loss: 0.7886 - val_root_mean_squared_error: 0.8880
Epoch 38/100
17/17 [==============================] - 0s 9ms/step - loss: 0.7629 - root_mean_squared_error: 0.8734 - val_loss: 0.7855 - val_root_mean_squared_error: 0.8863
Epoch 39/100
17/17 [==============================] - 0s 12ms/step - loss: 0.7608 - root_mean_squared_error: 0.8722 - val_loss: 0.7826 - val_root_mean_squared_error: 0.8846
Epoch 40/100
17/17 [==============================] - 0s 10ms/step - loss: 0.7593 - root_mean_squared_error: 0.8714 - val_loss: 0.7801 - val_root_mean_squared_error: 0.8832
Epoch 41/100
17/17 [==============================] - 0s 8ms/step - loss: 0.7571 - root_mean_squared_error: 0.8701 - val_loss: 0.7787 - val_root_mean_squared_error: 0.8824
Epoch 42/100
17/17 [==============================] - 0s 7ms/step - loss: 0.7544 - root_mean_squared_error: 0.8686 - val_loss: 0.7787 - val_root_mean_squared_error: 0.8824
Epoch 43/100
17/17 [==============================] - 0s 7ms/step - loss: 0.7513 - root_mean_squared_error: 0.8668 - val_loss: 0.7749 - val_root_mean_squared_error: 0.8803
Epoch 44/100
17/17 [==============================] - 0s 8ms/step - loss: 0.7496 - root_mean_squared_error: 0.8658 - val_loss: 0.7696 - val_root_mean_squared_error: 0.8772
Epoch 45/100
17/17 [==============================] - 0s 9ms/step - loss: 0.7459 - root_mean_squared_error: 0.8636 - val_loss: 0.7674 - val_root_mean_squared_error: 0.8760
Epoch 46/100
17/17 [==============================] - 0s 9ms/step - loss: 0.7435 - root_mean_squared_error: 0.8623 - val_loss: 0.7630 - val_root_mean_squared_error: 0.8735
Epoch 47/100
17/17 [==============================] - 0s 9ms/step - loss: 0.7415 - root_mean_squared_error: 0.8611 - val_loss: 0.7610 - val_root_mean_squared_error: 0.8724
Epoch 48/100
17/17 [==============================] - 0s 8ms/step - loss: 0.7373 - root_mean_squared_error: 0.8587 - val_loss: 0.7562 - val_root_mean_squared_error: 0.8696
Epoch 49/100
17/17 [==============================] - 0s 8ms/step - loss: 0.7334 - root_mean_squared_error: 0.8564 - val_loss: 0.7514 - val_root_mean_squared_error: 0.8668
Epoch 50/100
17/17 [==============================] - 0s 9ms/step - loss: 0.7292 - root_mean_squared_error: 0.8539 - val_loss: 0.7493 - val_root_mean_squared_error: 0.8656
Epoch 51/100
17/17 [==============================] - 0s 6ms/step - loss: 0.7252 - root_mean_squared_error: 0.8516 - val_loss: 0.7410 - val_root_mean_squared_error: 0.8608
Epoch 52/100
17/17 [==============================] - 0s 9ms/step - loss: 0.7207 - root_mean_squared_error: 0.8489 - val_loss: 0.7373 - val_root_mean_squared_error: 0.8587
Epoch 53/100
17/17 [==============================] - 0s 8ms/step - loss: 0.7154 - root_mean_squared_error: 0.8458 - val_loss: 0.7300 - val_root_mean_squared_error: 0.8544
Epoch 54/100
17/17 [==============================] - 0s 10ms/step - loss: 0.7109 - root_mean_squared_error: 0.8432 - val_loss: 0.7253 - val_root_mean_squared_error: 0.8516
Epoch 55/100
17/17 [==============================] - 0s 8ms/step - loss: 0.7070 - root_mean_squared_error: 0.8408 - val_loss: 0.7206 - val_root_mean_squared_error: 0.8489
Epoch 56/100
17/17 [==============================] - 0s 8ms/step - loss: 0.6981 - root_mean_squared_error: 0.8355 - val_loss: 0.7115 - val_root_mean_squared_error: 0.8435
Epoch 57/100
17/17 [==============================] - 0s 8ms/step - loss: 0.6940 - root_mean_squared_error: 0.8331 - val_loss: 0.7047 - val_root_mean_squared_error: 0.8394
Epoch 58/100
17/17 [==============================] - 0s 10ms/step - loss: 0.6876 - root_mean_squared_error: 0.8292 - val_loss: 0.6969 - val_root_mean_squared_error: 0.8348
Epoch 59/100
17/17 [==============================] - 0s 11ms/step - loss: 0.6814 - root_mean_squared_error: 0.8255 - val_loss: 0.6926 - val_root_mean_squared_error: 0.8322
Epoch 60/100
17/17 [==============================] - 0s 10ms/step - loss: 0.6754 - root_mean_squared_error: 0.8218 - val_loss: 0.6830 - val_root_mean_squared_error: 0.8264
Epoch 61/100
17/17 [==============================] - 0s 10ms/step - loss: 0.6681 - root_mean_squared_error: 0.8174 - val_loss: 0.6755 - val_root_mean_squared_error: 0.8219
Epoch 62/100
17/17 [==============================] - 0s 8ms/step - loss: 0.6600 - root_mean_squared_error: 0.8124 - val_loss: 0.6706 - val_root_mean_squared_error: 0.8189
Epoch 63/100
17/17 [==============================] - 0s 9ms/step - loss: 0.6523 - root_mean_squared_error: 0.8076 - val_loss: 0.6580 - val_root_mean_squared_error: 0.8112
Epoch 64/100
17/17 [==============================] - 0s 9ms/step - loss: 0.6450 - root_mean_squared_error: 0.8031 - val_loss: 0.6504 - val_root_mean_squared_error: 0.8065
Epoch 65/100
17/17 [==============================] - 0s 10ms/step - loss: 0.6378 - root_mean_squared_error: 0.7986 - val_loss: 0.6415 - val_root_mean_squared_error: 0.8010
Epoch 66/100
17/17 [==============================] - 0s 10ms/step - loss: 0.6317 - root_mean_squared_error: 0.7948 - val_loss: 0.6351 - val_root_mean_squared_error: 0.7969
Epoch 67/100
17/17 [==============================] - 0s 11ms/step - loss: 0.6244 - root_mean_squared_error: 0.7902 - val_loss: 0.6270 - val_root_mean_squared_error: 0.7918
Epoch 68/100
17/17 [==============================] - 0s 7ms/step - loss: 0.6177 - root_mean_squared_error: 0.7859 - val_loss: 0.6197 - val_root_mean_squared_error: 0.7872
Epoch 69/100
17/17 [==============================] - 0s 8ms/step - loss: 0.6121 - root_mean_squared_error: 0.7824 - val_loss: 0.6176 - val_root_mean_squared_error: 0.7859
Epoch 70/100
17/17 [==============================] - 0s 7ms/step - loss: 0.6047 - root_mean_squared_error: 0.7776 - val_loss: 0.6085 - val_root_mean_squared_error: 0.7801
Epoch 71/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5988 - root_mean_squared_error: 0.7739 - val_loss: 0.5999 - val_root_mean_squared_error: 0.7746
Epoch 72/100
17/17 [==============================] - 0s 8ms/step - loss: 0.5946 - root_mean_squared_error: 0.7711 - val_loss: 0.5954 - val_root_mean_squared_error: 0.7716
Epoch 73/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5888 - root_mean_squared_error: 0.7673 - val_loss: 0.5923 - val_root_mean_squared_error: 0.7696
Epoch 74/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5859 - root_mean_squared_error: 0.7654 - val_loss: 0.5868 - val_root_mean_squared_error: 0.7660
Epoch 75/100
17/17 [==============================] - 0s 8ms/step - loss: 0.5810 - root_mean_squared_error: 0.7622 - val_loss: 0.5813 - val_root_mean_squared_error: 0.7624
Epoch 76/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5776 - root_mean_squared_error: 0.7600 - val_loss: 0.5789 - val_root_mean_squared_error: 0.7609
Epoch 77/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5745 - root_mean_squared_error: 0.7580 - val_loss: 0.5751 - val_root_mean_squared_error: 0.7584
Epoch 78/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5731 - root_mean_squared_error: 0.7570 - val_loss: 0.5721 - val_root_mean_squared_error: 0.7564
Epoch 79/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5698 - root_mean_squared_error: 0.7549 - val_loss: 0.5712 - val_root_mean_squared_error: 0.7558
Epoch 80/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5704 - root_mean_squared_error: 0.7552 - val_loss: 0.5694 - val_root_mean_squared_error: 0.7546
Epoch 81/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5665 - root_mean_squared_error: 0.7527 - val_loss: 0.5662 - val_root_mean_squared_error: 0.7525
Epoch 82/100
17/17 [==============================] - 0s 8ms/step - loss: 0.5646 - root_mean_squared_error: 0.7514 - val_loss: 0.5651 - val_root_mean_squared_error: 0.7517
Epoch 83/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5653 - root_mean_squared_error: 0.7518 - val_loss: 0.5633 - val_root_mean_squared_error: 0.7505
Epoch 84/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5625 - root_mean_squared_error: 0.7500 - val_loss: 0.5621 - val_root_mean_squared_error: 0.7497
Epoch 85/100
17/17 [==============================] - 0s 8ms/step - loss: 0.5628 - root_mean_squared_error: 0.7502 - val_loss: 0.5625 - val_root_mean_squared_error: 0.7500
Epoch 86/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5618 - root_mean_squared_error: 0.7496 - val_loss: 0.5606 - val_root_mean_squared_error: 0.7487
Epoch 87/100
17/17 [==============================] - 0s 8ms/step - loss: 0.5602 - root_mean_squared_error: 0.7485 - val_loss: 0.5595 - val_root_mean_squared_error: 0.7480
Epoch 88/100
17/17 [==============================] - 0s 9ms/step - loss: 0.5597 - root_mean_squared_error: 0.7481 - val_loss: 0.5596 - val_root_mean_squared_error: 0.7481
Epoch 89/100
17/17 [==============================] - 0s 9ms/step - loss: 0.5574 - root_mean_squared_error: 0.7466 - val_loss: 0.5584 - val_root_mean_squared_error: 0.7472
Epoch 90/100
17/17 [==============================] - 0s 9ms/step - loss: 0.5586 - root_mean_squared_error: 0.7474 - val_loss: 0.5579 - val_root_mean_squared_error: 0.7469
Epoch 91/100
17/17 [==============================] - 0s 8ms/step - loss: 0.5612 - root_mean_squared_error: 0.7491 - val_loss: 0.5568 - val_root_mean_squared_error: 0.7462
Epoch 92/100
17/17 [==============================] - 0s 8ms/step - loss: 0.5588 - root_mean_squared_error: 0.7475 - val_loss: 0.5570 - val_root_mean_squared_error: 0.7463
Epoch 93/100
17/17 [==============================] - 0s 8ms/step - loss: 0.5591 - root_mean_squared_error: 0.7478 - val_loss: 0.5558 - val_root_mean_squared_error: 0.7455
Epoch 94/100
17/17 [==============================] - 0s 8ms/step - loss: 0.5570 - root_mean_squared_error: 0.7463 - val_loss: 0.5550 - val_root_mean_squared_error: 0.7450
Epoch 95/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5573 - root_mean_squared_error: 0.7465 - val_loss: 0.5545 - val_root_mean_squared_error: 0.7446
Epoch 96/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5561 - root_mean_squared_error: 0.7457 - val_loss: 0.5539 - val_root_mean_squared_error: 0.7443
Epoch 97/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5577 - root_mean_squared_error: 0.7468 - val_loss: 0.5550 - val_root_mean_squared_error: 0.7450
Epoch 98/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5555 - root_mean_squared_error: 0.7453 - val_loss: 0.5554 - val_root_mean_squared_error: 0.7452
Epoch 99/100
17/17 [==============================] - 0s 6ms/step - loss: 0.5550 - root_mean_squared_error: 0.7450 - val_loss: 0.5535 - val_root_mean_squared_error: 0.7440
Epoch 100/100
17/17 [==============================] - 0s 7ms/step - loss: 0.5556 - root_mean_squared_error: 0.7454 - val_loss: 0.5524 - val_root_mean_squared_error: 0.7432
Model training finished.
Train RMSE: 0.744
Evaluating model performance...
Test RMSE: 0.743
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">examples</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">unbatch</span><span class="p">()</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">sample</span><span class="p">))[</span>
    <span class="mi">0</span>
<span class="p">]</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="n">baseline_model</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">predicted</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2"> - Actual: </span><span class="si">{</span><span class="n">targets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted: 5.3 - Actual: 6.0
Predicted: 5.2 - Actual: 4.0
Predicted: 6.5 - Actual: 7.0
Predicted: 6.1 - Actual: 6.0
Predicted: 5.6 - Actual: 6.0
Predicted: 5.6 - Actual: 5.0
Predicted: 5.6 - Actual: 5.0
Predicted: 5.7 - Actual: 4.0
Predicted: 6.6 - Actual: 6.0
Predicted: 5.8 - Actual: 5.0
</pre></div>
</div>
</div>
</div>
<p>Experiment 2: Bayesian neural network (BNN)</p>
<p>The object of the Bayesian approach for modeling neural networks is to capture the epistemic uncertainty, which is uncertainty about the model fitness, due to limited training data.</p>
<p>The idea is that, instead of learning specific weight (and bias) values in the neural network, the Bayesian approach learns weight distributions - from which we can sample to produce an output for a given input - to encode weight uncertainty.</p>
<p>Thus, we need to define prior and the posterior distributions of these weights, and the training process is to learn the parameters of these distributions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the prior weight distribution as Normal of mean=0 and stddev=1.</span>
<span class="c1"># Note that, in this example, the we prior distribution is not trainable,</span>
<span class="c1"># as we fix its parameters.</span>
<span class="k">def</span> <span class="nf">prior</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">kernel_size</span> <span class="o">+</span> <span class="n">bias_size</span>
    <span class="n">prior_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">tfp</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">DistributionLambda</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span>
                    <span class="n">loc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">prior_model</span>


<span class="c1"># Define variational posterior weight distribution as multivariate Gaussian.</span>
<span class="c1"># Note that the learnable parameters for this distribution are the means,</span>
<span class="c1"># variances, and covariances.</span>
<span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">bias_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">kernel_size</span> <span class="o">+</span> <span class="n">bias_size</span>
    <span class="n">posterior_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">tfp</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">VariableLayer</span><span class="p">(</span>
                <span class="n">tfp</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="o">.</span><span class="n">params_size</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
            <span class="p">),</span>
            <span class="n">tfp</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span><span class="n">n</span><span class="p">),</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">posterior_model</span>


<span class="k">def</span> <span class="nf">create_bnn_model</span><span class="p">(</span><span class="n">train_size</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">create_model_inputs</span><span class="p">()</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">features</span><span class="p">)</span>

    <span class="c1"># Create hidden layers with weight uncertainty using the DenseVariational layer.</span>
    <span class="k">for</span> <span class="n">units</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">DenseVariational</span><span class="p">(</span>      <span class="c1">#here we used standard dense before!!!!</span>
            <span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span>
            <span class="n">make_prior_fn</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
            <span class="n">make_posterior_fn</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span>
            <span class="n">kl_weight</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="n">train_size</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
        <span class="p">)(</span><span class="n">features</span><span class="p">)</span>

    <span class="c1"># The output is deterministic: a single point estimate.</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">train_sample_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_size</span> <span class="o">*</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">small_train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">unbatch</span><span class="p">()</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">train_sample_size</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">bnn_model_small</span> <span class="o">=</span> <span class="n">create_bnn_model</span><span class="p">(</span><span class="n">train_sample_size</span><span class="p">)</span>
<span class="n">run_experiment</span><span class="p">(</span><span class="n">bnn_model_small</span><span class="p">,</span> <span class="n">mse_loss</span><span class="p">,</span> <span class="n">small_train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Start training the model...
Epoch 1/500
5/5 [==============================] - 3s 307ms/step - loss: 41.8960 - root_mean_squared_error: 6.4715 - val_loss: 37.7430 - val_root_mean_squared_error: 6.1424
Epoch 2/500
5/5 [==============================] - 0s 22ms/step - loss: 42.9566 - root_mean_squared_error: 6.5531 - val_loss: 42.6663 - val_root_mean_squared_error: 6.5308
Epoch 3/500
5/5 [==============================] - 0s 23ms/step - loss: 42.5569 - root_mean_squared_error: 6.5226 - val_loss: 38.7752 - val_root_mean_squared_error: 6.2257
Epoch 4/500
5/5 [==============================] - 0s 37ms/step - loss: 44.1559 - root_mean_squared_error: 6.6438 - val_loss: 39.7707 - val_root_mean_squared_error: 6.3053
Epoch 5/500
5/5 [==============================] - 0s 26ms/step - loss: 39.5188 - root_mean_squared_error: 6.2850 - val_loss: 38.0512 - val_root_mean_squared_error: 6.1672
Epoch 6/500
5/5 [==============================] - 0s 24ms/step - loss: 42.1392 - root_mean_squared_error: 6.4905 - val_loss: 39.0201 - val_root_mean_squared_error: 6.2457
Epoch 7/500
5/5 [==============================] - 0s 31ms/step - loss: 40.6071 - root_mean_squared_error: 6.3711 - val_loss: 37.1258 - val_root_mean_squared_error: 6.0919
Epoch 8/500
5/5 [==============================] - 0s 27ms/step - loss: 38.9696 - root_mean_squared_error: 6.2415 - val_loss: 36.7102 - val_root_mean_squared_error: 6.0577
Epoch 9/500
5/5 [==============================] - 0s 29ms/step - loss: 37.8238 - root_mean_squared_error: 6.1490 - val_loss: 36.0972 - val_root_mean_squared_error: 6.0064
Epoch 10/500
5/5 [==============================] - 0s 28ms/step - loss: 38.1464 - root_mean_squared_error: 6.1749 - val_loss: 41.1971 - val_root_mean_squared_error: 6.4174
Epoch 11/500
5/5 [==============================] - 0s 22ms/step - loss: 37.2697 - root_mean_squared_error: 6.1039 - val_loss: 33.0387 - val_root_mean_squared_error: 5.7464
Epoch 12/500
5/5 [==============================] - 0s 23ms/step - loss: 34.8673 - root_mean_squared_error: 5.9037 - val_loss: 31.8805 - val_root_mean_squared_error: 5.6450
Epoch 13/500
5/5 [==============================] - 0s 29ms/step - loss: 36.6436 - root_mean_squared_error: 6.0520 - val_loss: 36.7797 - val_root_mean_squared_error: 6.0634
Epoch 14/500
5/5 [==============================] - 0s 21ms/step - loss: 32.5886 - root_mean_squared_error: 5.7076 - val_loss: 33.7065 - val_root_mean_squared_error: 5.8042
Epoch 15/500
5/5 [==============================] - 0s 25ms/step - loss: 36.6762 - root_mean_squared_error: 6.0550 - val_loss: 40.0020 - val_root_mean_squared_error: 6.3235
Epoch 16/500
5/5 [==============================] - 0s 30ms/step - loss: 32.4641 - root_mean_squared_error: 5.6964 - val_loss: 33.3292 - val_root_mean_squared_error: 5.7719
Epoch 17/500
5/5 [==============================] - 0s 29ms/step - loss: 33.0606 - root_mean_squared_error: 5.7484 - val_loss: 36.9495 - val_root_mean_squared_error: 6.0772
Epoch 18/500
5/5 [==============================] - 0s 29ms/step - loss: 33.2116 - root_mean_squared_error: 5.7617 - val_loss: 32.6186 - val_root_mean_squared_error: 5.7100
Epoch 19/500
5/5 [==============================] - 0s 38ms/step - loss: 34.1212 - root_mean_squared_error: 5.8401 - val_loss: 33.5280 - val_root_mean_squared_error: 5.7887
Epoch 20/500
5/5 [==============================] - 0s 33ms/step - loss: 34.1342 - root_mean_squared_error: 5.8412 - val_loss: 30.0999 - val_root_mean_squared_error: 5.4847
Epoch 21/500
5/5 [==============================] - 0s 28ms/step - loss: 30.6321 - root_mean_squared_error: 5.5332 - val_loss: 30.9087 - val_root_mean_squared_error: 5.5585
Epoch 22/500
5/5 [==============================] - 0s 28ms/step - loss: 34.2411 - root_mean_squared_error: 5.8501 - val_loss: 28.5376 - val_root_mean_squared_error: 5.3405
Epoch 23/500
5/5 [==============================] - 0s 25ms/step - loss: 30.8859 - root_mean_squared_error: 5.5562 - val_loss: 30.8049 - val_root_mean_squared_error: 5.5492
Epoch 24/500
5/5 [==============================] - 0s 25ms/step - loss: 32.1379 - root_mean_squared_error: 5.6679 - val_loss: 32.8641 - val_root_mean_squared_error: 5.7315
Epoch 25/500
5/5 [==============================] - 0s 28ms/step - loss: 32.2433 - root_mean_squared_error: 5.6771 - val_loss: 29.3034 - val_root_mean_squared_error: 5.4120
Epoch 26/500
5/5 [==============================] - 0s 26ms/step - loss: 29.9341 - root_mean_squared_error: 5.4695 - val_loss: 30.7441 - val_root_mean_squared_error: 5.5431
Epoch 27/500
5/5 [==============================] - 0s 23ms/step - loss: 27.5713 - root_mean_squared_error: 5.2493 - val_loss: 27.4673 - val_root_mean_squared_error: 5.2398
Epoch 28/500
5/5 [==============================] - 0s 21ms/step - loss: 30.3363 - root_mean_squared_error: 5.5066 - val_loss: 29.1369 - val_root_mean_squared_error: 5.3964
Epoch 29/500
5/5 [==============================] - 0s 26ms/step - loss: 27.1876 - root_mean_squared_error: 5.2129 - val_loss: 27.2407 - val_root_mean_squared_error: 5.2181
Epoch 30/500
5/5 [==============================] - 0s 30ms/step - loss: 25.5005 - root_mean_squared_error: 5.0482 - val_loss: 28.5054 - val_root_mean_squared_error: 5.3376
Epoch 31/500
5/5 [==============================] - 0s 24ms/step - loss: 28.4023 - root_mean_squared_error: 5.3284 - val_loss: 28.6729 - val_root_mean_squared_error: 5.3527
Epoch 32/500
5/5 [==============================] - 0s 28ms/step - loss: 25.2671 - root_mean_squared_error: 5.0251 - val_loss: 28.2112 - val_root_mean_squared_error: 5.3102
Epoch 33/500
5/5 [==============================] - 0s 24ms/step - loss: 25.7341 - root_mean_squared_error: 5.0715 - val_loss: 25.9815 - val_root_mean_squared_error: 5.0955
Epoch 34/500
5/5 [==============================] - 0s 32ms/step - loss: 30.3119 - root_mean_squared_error: 5.5043 - val_loss: 27.7610 - val_root_mean_squared_error: 5.2674
Epoch 35/500
5/5 [==============================] - 0s 34ms/step - loss: 27.7525 - root_mean_squared_error: 5.2665 - val_loss: 25.4829 - val_root_mean_squared_error: 5.0464
Epoch 36/500
5/5 [==============================] - 0s 32ms/step - loss: 28.1550 - root_mean_squared_error: 5.3046 - val_loss: 24.8593 - val_root_mean_squared_error: 4.9843
Epoch 37/500
5/5 [==============================] - 0s 25ms/step - loss: 29.0918 - root_mean_squared_error: 5.3922 - val_loss: 24.0684 - val_root_mean_squared_error: 4.9043
Epoch 38/500
5/5 [==============================] - 0s 37ms/step - loss: 26.3402 - root_mean_squared_error: 5.1304 - val_loss: 22.6475 - val_root_mean_squared_error: 4.7570
Epoch 39/500
5/5 [==============================] - 0s 31ms/step - loss: 26.1184 - root_mean_squared_error: 5.1091 - val_loss: 23.0717 - val_root_mean_squared_error: 4.8013
Epoch 40/500
5/5 [==============================] - 0s 36ms/step - loss: 25.1137 - root_mean_squared_error: 5.0098 - val_loss: 25.5079 - val_root_mean_squared_error: 5.0487
Epoch 41/500
5/5 [==============================] - 0s 33ms/step - loss: 22.6185 - root_mean_squared_error: 4.7540 - val_loss: 23.9750 - val_root_mean_squared_error: 4.8945
Epoch 42/500
5/5 [==============================] - 0s 31ms/step - loss: 23.7124 - root_mean_squared_error: 4.8676 - val_loss: 24.5122 - val_root_mean_squared_error: 4.9495
Epoch 43/500
5/5 [==============================] - 0s 38ms/step - loss: 26.0754 - root_mean_squared_error: 5.1047 - val_loss: 22.1784 - val_root_mean_squared_error: 4.7080
Epoch 44/500
5/5 [==============================] - 0s 36ms/step - loss: 24.7279 - root_mean_squared_error: 4.9710 - val_loss: 24.7303 - val_root_mean_squared_error: 4.9714
Epoch 45/500
5/5 [==============================] - 0s 36ms/step - loss: 22.0760 - root_mean_squared_error: 4.6971 - val_loss: 19.6541 - val_root_mean_squared_error: 4.4312
Epoch 46/500
5/5 [==============================] - 0s 33ms/step - loss: 21.6946 - root_mean_squared_error: 4.6559 - val_loss: 21.8173 - val_root_mean_squared_error: 4.6690
Epoch 47/500
5/5 [==============================] - 0s 25ms/step - loss: 22.3794 - root_mean_squared_error: 4.7287 - val_loss: 19.3479 - val_root_mean_squared_error: 4.3963
Epoch 48/500
5/5 [==============================] - 0s 26ms/step - loss: 20.5224 - root_mean_squared_error: 4.5283 - val_loss: 20.4989 - val_root_mean_squared_error: 4.5258
Epoch 49/500
5/5 [==============================] - 0s 30ms/step - loss: 20.4286 - root_mean_squared_error: 4.5180 - val_loss: 20.0685 - val_root_mean_squared_error: 4.4779
Epoch 50/500
5/5 [==============================] - 0s 23ms/step - loss: 20.6925 - root_mean_squared_error: 4.5470 - val_loss: 20.7848 - val_root_mean_squared_error: 4.5574
Epoch 51/500
5/5 [==============================] - 0s 25ms/step - loss: 20.8698 - root_mean_squared_error: 4.5666 - val_loss: 19.6087 - val_root_mean_squared_error: 4.4262
Epoch 52/500
5/5 [==============================] - 0s 23ms/step - loss: 19.7779 - root_mean_squared_error: 4.4451 - val_loss: 19.9948 - val_root_mean_squared_error: 4.4694
Epoch 53/500
5/5 [==============================] - 0s 26ms/step - loss: 21.0086 - root_mean_squared_error: 4.5814 - val_loss: 17.4055 - val_root_mean_squared_error: 4.1694
Epoch 54/500
5/5 [==============================] - 0s 27ms/step - loss: 19.6119 - root_mean_squared_error: 4.4270 - val_loss: 19.5068 - val_root_mean_squared_error: 4.4145
Epoch 55/500
5/5 [==============================] - 0s 27ms/step - loss: 18.9914 - root_mean_squared_error: 4.3558 - val_loss: 16.4296 - val_root_mean_squared_error: 4.0509
Epoch 56/500
5/5 [==============================] - 0s 24ms/step - loss: 20.5924 - root_mean_squared_error: 4.5360 - val_loss: 18.2879 - val_root_mean_squared_error: 4.2741
Epoch 57/500
5/5 [==============================] - 0s 26ms/step - loss: 20.1605 - root_mean_squared_error: 4.4884 - val_loss: 19.1173 - val_root_mean_squared_error: 4.3699
Epoch 58/500
5/5 [==============================] - 0s 23ms/step - loss: 18.9884 - root_mean_squared_error: 4.3555 - val_loss: 18.8738 - val_root_mean_squared_error: 4.3423
Epoch 59/500
5/5 [==============================] - 0s 30ms/step - loss: 19.0376 - root_mean_squared_error: 4.3611 - val_loss: 17.5035 - val_root_mean_squared_error: 4.1816
Epoch 60/500
5/5 [==============================] - 0s 25ms/step - loss: 18.0498 - root_mean_squared_error: 4.2461 - val_loss: 16.7246 - val_root_mean_squared_error: 4.0872
Epoch 61/500
5/5 [==============================] - 0s 25ms/step - loss: 21.6891 - root_mean_squared_error: 4.6554 - val_loss: 15.4841 - val_root_mean_squared_error: 3.9327
Epoch 62/500
5/5 [==============================] - 0s 26ms/step - loss: 16.6926 - root_mean_squared_error: 4.0830 - val_loss: 16.5371 - val_root_mean_squared_error: 4.0645
Epoch 63/500
5/5 [==============================] - 0s 32ms/step - loss: 17.6895 - root_mean_squared_error: 4.2037 - val_loss: 16.8826 - val_root_mean_squared_error: 4.1071
Epoch 64/500
5/5 [==============================] - 0s 36ms/step - loss: 16.0993 - root_mean_squared_error: 4.0099 - val_loss: 19.3593 - val_root_mean_squared_error: 4.3980
Epoch 65/500
5/5 [==============================] - 0s 30ms/step - loss: 17.6647 - root_mean_squared_error: 4.2006 - val_loss: 16.1357 - val_root_mean_squared_error: 4.0145
Epoch 66/500
5/5 [==============================] - 0s 26ms/step - loss: 18.5947 - root_mean_squared_error: 4.3100 - val_loss: 16.8077 - val_root_mean_squared_error: 4.0975
Epoch 67/500
5/5 [==============================] - 0s 25ms/step - loss: 19.8645 - root_mean_squared_error: 4.4550 - val_loss: 13.6370 - val_root_mean_squared_error: 3.6897
Epoch 68/500
5/5 [==============================] - 0s 32ms/step - loss: 16.2845 - root_mean_squared_error: 4.0334 - val_loss: 14.7555 - val_root_mean_squared_error: 3.8389
Epoch 69/500
5/5 [==============================] - 0s 28ms/step - loss: 15.9749 - root_mean_squared_error: 3.9948 - val_loss: 14.0110 - val_root_mean_squared_error: 3.7406
Epoch 70/500
5/5 [==============================] - 0s 24ms/step - loss: 14.4695 - root_mean_squared_error: 3.8010 - val_loss: 16.2488 - val_root_mean_squared_error: 4.0285
Epoch 71/500
5/5 [==============================] - 0s 26ms/step - loss: 14.1415 - root_mean_squared_error: 3.7580 - val_loss: 12.3631 - val_root_mean_squared_error: 3.5133
Epoch 72/500
5/5 [==============================] - 0s 26ms/step - loss: 14.8945 - root_mean_squared_error: 3.8568 - val_loss: 17.3601 - val_root_mean_squared_error: 4.1641
Epoch 73/500
5/5 [==============================] - 0s 27ms/step - loss: 16.3741 - root_mean_squared_error: 4.0441 - val_loss: 15.3360 - val_root_mean_squared_error: 3.9135
Epoch 74/500
5/5 [==============================] - 0s 24ms/step - loss: 15.2803 - root_mean_squared_error: 3.9065 - val_loss: 12.9241 - val_root_mean_squared_error: 3.5914
Epoch 75/500
5/5 [==============================] - 0s 24ms/step - loss: 15.6193 - root_mean_squared_error: 3.9503 - val_loss: 12.0401 - val_root_mean_squared_error: 3.4671
Epoch 76/500
5/5 [==============================] - 0s 27ms/step - loss: 13.6226 - root_mean_squared_error: 3.6882 - val_loss: 13.3253 - val_root_mean_squared_error: 3.6475
Epoch 77/500
5/5 [==============================] - 0s 25ms/step - loss: 13.8991 - root_mean_squared_error: 3.7255 - val_loss: 11.7576 - val_root_mean_squared_error: 3.4255
Epoch 78/500
5/5 [==============================] - 0s 28ms/step - loss: 14.3158 - root_mean_squared_error: 3.7812 - val_loss: 12.0422 - val_root_mean_squared_error: 3.4673
Epoch 79/500
5/5 [==============================] - 0s 25ms/step - loss: 13.1227 - root_mean_squared_error: 3.6195 - val_loss: 13.5996 - val_root_mean_squared_error: 3.6848
Epoch 80/500
5/5 [==============================] - 0s 26ms/step - loss: 13.7350 - root_mean_squared_error: 3.7033 - val_loss: 11.3440 - val_root_mean_squared_error: 3.3647
Epoch 81/500
5/5 [==============================] - 0s 26ms/step - loss: 11.1869 - root_mean_squared_error: 3.3416 - val_loss: 12.8200 - val_root_mean_squared_error: 3.5774
Epoch 82/500
5/5 [==============================] - 0s 30ms/step - loss: 13.9960 - root_mean_squared_error: 3.7386 - val_loss: 11.2725 - val_root_mean_squared_error: 3.3539
Epoch 83/500
5/5 [==============================] - 0s 25ms/step - loss: 11.6899 - root_mean_squared_error: 3.4158 - val_loss: 11.8654 - val_root_mean_squared_error: 3.4417
Epoch 84/500
5/5 [==============================] - 0s 25ms/step - loss: 10.9830 - root_mean_squared_error: 3.3107 - val_loss: 10.8604 - val_root_mean_squared_error: 3.2930
Epoch 85/500
5/5 [==============================] - 0s 23ms/step - loss: 10.7903 - root_mean_squared_error: 3.2814 - val_loss: 10.5236 - val_root_mean_squared_error: 3.2412
Epoch 86/500
5/5 [==============================] - 0s 20ms/step - loss: 10.7029 - root_mean_squared_error: 3.2680 - val_loss: 11.8177 - val_root_mean_squared_error: 3.4349
Epoch 87/500
5/5 [==============================] - 0s 26ms/step - loss: 10.4220 - root_mean_squared_error: 3.2249 - val_loss: 10.7263 - val_root_mean_squared_error: 3.2721
Epoch 88/500
5/5 [==============================] - 0s 26ms/step - loss: 10.4455 - root_mean_squared_error: 3.2284 - val_loss: 9.3560 - val_root_mean_squared_error: 3.0555
Epoch 89/500
5/5 [==============================] - 0s 27ms/step - loss: 11.1182 - root_mean_squared_error: 3.3311 - val_loss: 13.4120 - val_root_mean_squared_error: 3.6596
Epoch 90/500
5/5 [==============================] - 0s 25ms/step - loss: 10.9463 - root_mean_squared_error: 3.3050 - val_loss: 8.6891 - val_root_mean_squared_error: 2.9439
Epoch 91/500
5/5 [==============================] - 0s 23ms/step - loss: 10.2789 - root_mean_squared_error: 3.2027 - val_loss: 11.2785 - val_root_mean_squared_error: 3.3552
Epoch 92/500
5/5 [==============================] - 0s 25ms/step - loss: 9.4996 - root_mean_squared_error: 3.0786 - val_loss: 9.0136 - val_root_mean_squared_error: 2.9990
Epoch 93/500
5/5 [==============================] - 0s 27ms/step - loss: 9.9366 - root_mean_squared_error: 3.1490 - val_loss: 7.8954 - val_root_mean_squared_error: 2.8052
Epoch 94/500
5/5 [==============================] - 0s 22ms/step - loss: 9.3631 - root_mean_squared_error: 3.0562 - val_loss: 9.5074 - val_root_mean_squared_error: 3.0799
Epoch 95/500
5/5 [==============================] - 0s 24ms/step - loss: 9.0355 - root_mean_squared_error: 3.0024 - val_loss: 9.4845 - val_root_mean_squared_error: 3.0761
Epoch 96/500
5/5 [==============================] - 0s 25ms/step - loss: 10.7864 - root_mean_squared_error: 3.2808 - val_loss: 7.7323 - val_root_mean_squared_error: 2.7772
Epoch 97/500
5/5 [==============================] - 0s 35ms/step - loss: 9.0423 - root_mean_squared_error: 3.0037 - val_loss: 8.2724 - val_root_mean_squared_error: 2.8711
Epoch 98/500
5/5 [==============================] - 0s 26ms/step - loss: 8.4912 - root_mean_squared_error: 2.9099 - val_loss: 8.0414 - val_root_mean_squared_error: 2.8316
Epoch 99/500
5/5 [==============================] - 0s 27ms/step - loss: 8.9329 - root_mean_squared_error: 2.9852 - val_loss: 8.8410 - val_root_mean_squared_error: 2.9698
Epoch 100/500
5/5 [==============================] - 0s 27ms/step - loss: 8.8534 - root_mean_squared_error: 2.9716 - val_loss: 7.4439 - val_root_mean_squared_error: 2.7234
Epoch 101/500
5/5 [==============================] - 0s 26ms/step - loss: 7.7301 - root_mean_squared_error: 2.7758 - val_loss: 8.2681 - val_root_mean_squared_error: 2.8718
Epoch 102/500
5/5 [==============================] - 0s 27ms/step - loss: 7.3516 - root_mean_squared_error: 2.7069 - val_loss: 9.0107 - val_root_mean_squared_error: 2.9985
Epoch 103/500
5/5 [==============================] - 0s 27ms/step - loss: 7.2886 - root_mean_squared_error: 2.6944 - val_loss: 7.3746 - val_root_mean_squared_error: 2.7111
Epoch 104/500
5/5 [==============================] - 0s 25ms/step - loss: 7.3709 - root_mean_squared_error: 2.7100 - val_loss: 6.5770 - val_root_mean_squared_error: 2.5595
Epoch 105/500
5/5 [==============================] - 0s 25ms/step - loss: 7.2256 - root_mean_squared_error: 2.6836 - val_loss: 7.0589 - val_root_mean_squared_error: 2.6518
Epoch 106/500
5/5 [==============================] - 0s 25ms/step - loss: 7.4130 - root_mean_squared_error: 2.7185 - val_loss: 7.1798 - val_root_mean_squared_error: 2.6757
Epoch 107/500
5/5 [==============================] - 0s 25ms/step - loss: 8.0299 - root_mean_squared_error: 2.8299 - val_loss: 7.0327 - val_root_mean_squared_error: 2.6477
Epoch 108/500
5/5 [==============================] - 0s 25ms/step - loss: 6.7641 - root_mean_squared_error: 2.5956 - val_loss: 6.6384 - val_root_mean_squared_error: 2.5725
Epoch 109/500
5/5 [==============================] - 0s 28ms/step - loss: 6.8029 - root_mean_squared_error: 2.6036 - val_loss: 7.3856 - val_root_mean_squared_error: 2.7131
Epoch 110/500
5/5 [==============================] - 0s 25ms/step - loss: 7.6467 - root_mean_squared_error: 2.7609 - val_loss: 5.7932 - val_root_mean_squared_error: 2.4018
Epoch 111/500
5/5 [==============================] - 0s 31ms/step - loss: 7.4322 - root_mean_squared_error: 2.7223 - val_loss: 6.9290 - val_root_mean_squared_error: 2.6279
Epoch 112/500
5/5 [==============================] - 0s 22ms/step - loss: 6.2000 - root_mean_squared_error: 2.4847 - val_loss: 5.7479 - val_root_mean_squared_error: 2.3919
Epoch 113/500
5/5 [==============================] - 0s 25ms/step - loss: 5.7221 - root_mean_squared_error: 2.3870 - val_loss: 5.1635 - val_root_mean_squared_error: 2.2663
Epoch 114/500
5/5 [==============================] - 0s 25ms/step - loss: 6.3445 - root_mean_squared_error: 2.5142 - val_loss: 6.5261 - val_root_mean_squared_error: 2.5494
Epoch 115/500
5/5 [==============================] - 0s 25ms/step - loss: 6.1456 - root_mean_squared_error: 2.4749 - val_loss: 6.6433 - val_root_mean_squared_error: 2.5730
Epoch 116/500
5/5 [==============================] - 0s 25ms/step - loss: 6.5729 - root_mean_squared_error: 2.5589 - val_loss: 5.8217 - val_root_mean_squared_error: 2.4078
Epoch 117/500
5/5 [==============================] - 0s 27ms/step - loss: 6.4301 - root_mean_squared_error: 2.5307 - val_loss: 5.6605 - val_root_mean_squared_error: 2.3733
Epoch 118/500
5/5 [==============================] - 0s 26ms/step - loss: 5.6831 - root_mean_squared_error: 2.3787 - val_loss: 4.7668 - val_root_mean_squared_error: 2.1781
Epoch 119/500
5/5 [==============================] - 0s 27ms/step - loss: 4.6247 - root_mean_squared_error: 2.1444 - val_loss: 4.8025 - val_root_mean_squared_error: 2.1849
Epoch 120/500
5/5 [==============================] - 0s 23ms/step - loss: 5.5651 - root_mean_squared_error: 2.3530 - val_loss: 5.6251 - val_root_mean_squared_error: 2.3668
Epoch 121/500
5/5 [==============================] - 0s 20ms/step - loss: 5.2512 - root_mean_squared_error: 2.2866 - val_loss: 4.4353 - val_root_mean_squared_error: 2.0993
Epoch 122/500
5/5 [==============================] - 0s 27ms/step - loss: 4.7081 - root_mean_squared_error: 2.1643 - val_loss: 5.1793 - val_root_mean_squared_error: 2.2711
Epoch 123/500
5/5 [==============================] - 0s 26ms/step - loss: 4.6812 - root_mean_squared_error: 2.1576 - val_loss: 4.4785 - val_root_mean_squared_error: 2.1103
Epoch 124/500
5/5 [==============================] - 0s 23ms/step - loss: 4.6770 - root_mean_squared_error: 2.1569 - val_loss: 4.4884 - val_root_mean_squared_error: 2.1126
Epoch 125/500
5/5 [==============================] - 0s 24ms/step - loss: 4.8331 - root_mean_squared_error: 2.1925 - val_loss: 4.1949 - val_root_mean_squared_error: 2.0420
Epoch 126/500
5/5 [==============================] - 0s 25ms/step - loss: 4.6555 - root_mean_squared_error: 2.1505 - val_loss: 4.0274 - val_root_mean_squared_error: 1.9996
Epoch 127/500
5/5 [==============================] - 0s 28ms/step - loss: 4.5130 - root_mean_squared_error: 2.1175 - val_loss: 4.1686 - val_root_mean_squared_error: 2.0352
Epoch 128/500
5/5 [==============================] - 0s 26ms/step - loss: 4.0792 - root_mean_squared_error: 2.0134 - val_loss: 4.1273 - val_root_mean_squared_error: 2.0251
Epoch 129/500
5/5 [==============================] - 0s 22ms/step - loss: 4.2101 - root_mean_squared_error: 2.0452 - val_loss: 3.6289 - val_root_mean_squared_error: 1.8982
Epoch 130/500
5/5 [==============================] - 0s 33ms/step - loss: 4.2489 - root_mean_squared_error: 2.0554 - val_loss: 4.1004 - val_root_mean_squared_error: 2.0177
Epoch 131/500
5/5 [==============================] - 0s 32ms/step - loss: 4.1646 - root_mean_squared_error: 2.0343 - val_loss: 3.7072 - val_root_mean_squared_error: 1.9196
Epoch 132/500
5/5 [==============================] - 0s 26ms/step - loss: 4.0263 - root_mean_squared_error: 1.9997 - val_loss: 3.5000 - val_root_mean_squared_error: 1.8635
Epoch 133/500
5/5 [==============================] - 0s 23ms/step - loss: 3.5402 - root_mean_squared_error: 1.8751 - val_loss: 3.2223 - val_root_mean_squared_error: 1.7879
Epoch 134/500
5/5 [==============================] - 0s 29ms/step - loss: 3.3993 - root_mean_squared_error: 1.8359 - val_loss: 3.5311 - val_root_mean_squared_error: 1.8729
Epoch 135/500
5/5 [==============================] - 0s 25ms/step - loss: 3.7395 - root_mean_squared_error: 1.9266 - val_loss: 3.1540 - val_root_mean_squared_error: 1.7668
Epoch 136/500
5/5 [==============================] - 0s 29ms/step - loss: 3.1562 - root_mean_squared_error: 1.7691 - val_loss: 3.6222 - val_root_mean_squared_error: 1.8971
Epoch 137/500
5/5 [==============================] - 0s 26ms/step - loss: 2.8342 - root_mean_squared_error: 1.6747 - val_loss: 2.9984 - val_root_mean_squared_error: 1.7225
Epoch 138/500
5/5 [==============================] - 0s 26ms/step - loss: 3.3761 - root_mean_squared_error: 1.8297 - val_loss: 2.8082 - val_root_mean_squared_error: 1.6677
Epoch 139/500
5/5 [==============================] - 0s 26ms/step - loss: 3.2455 - root_mean_squared_error: 1.7939 - val_loss: 2.8067 - val_root_mean_squared_error: 1.6670
Epoch 140/500
5/5 [==============================] - 0s 27ms/step - loss: 3.0549 - root_mean_squared_error: 1.7395 - val_loss: 3.9877 - val_root_mean_squared_error: 1.9918
Epoch 141/500
5/5 [==============================] - 0s 26ms/step - loss: 2.8513 - root_mean_squared_error: 1.6804 - val_loss: 2.3937 - val_root_mean_squared_error: 1.5378
Epoch 142/500
5/5 [==============================] - 0s 27ms/step - loss: 2.6709 - root_mean_squared_error: 1.6263 - val_loss: 2.8158 - val_root_mean_squared_error: 1.6702
Epoch 143/500
5/5 [==============================] - 0s 26ms/step - loss: 2.5179 - root_mean_squared_error: 1.5761 - val_loss: 2.4951 - val_root_mean_squared_error: 1.5708
Epoch 144/500
5/5 [==============================] - 0s 30ms/step - loss: 2.7614 - root_mean_squared_error: 1.6527 - val_loss: 2.1972 - val_root_mean_squared_error: 1.4715
Epoch 145/500
5/5 [==============================] - 0s 31ms/step - loss: 2.3431 - root_mean_squared_error: 1.5213 - val_loss: 2.5285 - val_root_mean_squared_error: 1.5812
Epoch 146/500
5/5 [==============================] - 0s 23ms/step - loss: 2.4259 - root_mean_squared_error: 1.5471 - val_loss: 1.8916 - val_root_mean_squared_error: 1.3644
Epoch 147/500
5/5 [==============================] - 0s 27ms/step - loss: 2.1538 - root_mean_squared_error: 1.4581 - val_loss: 2.1095 - val_root_mean_squared_error: 1.4424
Epoch 148/500
5/5 [==============================] - 0s 25ms/step - loss: 2.1637 - root_mean_squared_error: 1.4611 - val_loss: 2.1546 - val_root_mean_squared_error: 1.4576
Epoch 149/500
5/5 [==============================] - 0s 23ms/step - loss: 2.1251 - root_mean_squared_error: 1.4472 - val_loss: 2.2113 - val_root_mean_squared_error: 1.4785
Epoch 150/500
5/5 [==============================] - 0s 33ms/step - loss: 1.8385 - root_mean_squared_error: 1.3450 - val_loss: 1.9112 - val_root_mean_squared_error: 1.3718
Epoch 151/500
5/5 [==============================] - 0s 24ms/step - loss: 2.0558 - root_mean_squared_error: 1.4241 - val_loss: 2.0686 - val_root_mean_squared_error: 1.4305
Epoch 152/500
5/5 [==============================] - 0s 27ms/step - loss: 1.9393 - root_mean_squared_error: 1.3830 - val_loss: 1.9634 - val_root_mean_squared_error: 1.3919
Epoch 153/500
5/5 [==============================] - 0s 34ms/step - loss: 1.9980 - root_mean_squared_error: 1.4040 - val_loss: 1.7111 - val_root_mean_squared_error: 1.2969
Epoch 154/500
5/5 [==============================] - 0s 26ms/step - loss: 1.9696 - root_mean_squared_error: 1.3926 - val_loss: 1.7166 - val_root_mean_squared_error: 1.2995
Epoch 155/500
5/5 [==============================] - 0s 22ms/step - loss: 1.5838 - root_mean_squared_error: 1.2488 - val_loss: 1.5189 - val_root_mean_squared_error: 1.2192
Epoch 156/500
5/5 [==============================] - 0s 27ms/step - loss: 1.6248 - root_mean_squared_error: 1.2623 - val_loss: 1.5042 - val_root_mean_squared_error: 1.2155
Epoch 157/500
5/5 [==============================] - 0s 25ms/step - loss: 1.5614 - root_mean_squared_error: 1.2372 - val_loss: 1.3821 - val_root_mean_squared_error: 1.1637
Epoch 158/500
5/5 [==============================] - 0s 29ms/step - loss: 1.6528 - root_mean_squared_error: 1.2745 - val_loss: 1.4358 - val_root_mean_squared_error: 1.1866
Epoch 159/500
5/5 [==============================] - 0s 25ms/step - loss: 1.4824 - root_mean_squared_error: 1.2038 - val_loss: 1.5740 - val_root_mean_squared_error: 1.2424
Epoch 160/500
5/5 [==============================] - 0s 29ms/step - loss: 1.3153 - root_mean_squared_error: 1.1339 - val_loss: 1.3938 - val_root_mean_squared_error: 1.1692
Epoch 161/500
5/5 [==============================] - 0s 25ms/step - loss: 1.2946 - root_mean_squared_error: 1.1243 - val_loss: 1.1358 - val_root_mean_squared_error: 1.0494
Epoch 162/500
5/5 [==============================] - 0s 22ms/step - loss: 1.4789 - root_mean_squared_error: 1.2040 - val_loss: 1.2021 - val_root_mean_squared_error: 1.0848
Epoch 163/500
5/5 [==============================] - 0s 28ms/step - loss: 1.1454 - root_mean_squared_error: 1.0548 - val_loss: 1.3148 - val_root_mean_squared_error: 1.1336
Epoch 164/500
5/5 [==============================] - 0s 31ms/step - loss: 1.2306 - root_mean_squared_error: 1.0942 - val_loss: 1.1658 - val_root_mean_squared_error: 1.0637
Epoch 165/500
5/5 [==============================] - 0s 32ms/step - loss: 1.0675 - root_mean_squared_error: 1.0186 - val_loss: 1.1689 - val_root_mean_squared_error: 1.0645
Epoch 166/500
5/5 [==============================] - 0s 26ms/step - loss: 1.1797 - root_mean_squared_error: 1.0714 - val_loss: 1.1111 - val_root_mean_squared_error: 1.0388
Epoch 167/500
5/5 [==============================] - 0s 25ms/step - loss: 1.1455 - root_mean_squared_error: 1.0561 - val_loss: 1.1871 - val_root_mean_squared_error: 1.0767
Epoch 168/500
5/5 [==============================] - 0s 25ms/step - loss: 1.0625 - root_mean_squared_error: 1.0164 - val_loss: 1.0921 - val_root_mean_squared_error: 1.0297
Epoch 169/500
5/5 [==============================] - 0s 28ms/step - loss: 1.0790 - root_mean_squared_error: 1.0231 - val_loss: 1.0137 - val_root_mean_squared_error: 0.9902
Epoch 170/500
5/5 [==============================] - 0s 34ms/step - loss: 1.0568 - root_mean_squared_error: 1.0102 - val_loss: 0.9797 - val_root_mean_squared_error: 0.9742
Epoch 171/500
5/5 [==============================] - 0s 23ms/step - loss: 0.9958 - root_mean_squared_error: 0.9825 - val_loss: 0.9802 - val_root_mean_squared_error: 0.9740
Epoch 172/500
5/5 [==============================] - 0s 26ms/step - loss: 0.9677 - root_mean_squared_error: 0.9671 - val_loss: 0.9569 - val_root_mean_squared_error: 0.9627
Epoch 173/500
5/5 [==============================] - 0s 26ms/step - loss: 1.0373 - root_mean_squared_error: 1.0047 - val_loss: 1.0133 - val_root_mean_squared_error: 0.9894
Epoch 174/500
5/5 [==============================] - 0s 21ms/step - loss: 1.0253 - root_mean_squared_error: 0.9989 - val_loss: 0.8616 - val_root_mean_squared_error: 0.9096
Epoch 175/500
5/5 [==============================] - 0s 34ms/step - loss: 0.9563 - root_mean_squared_error: 0.9616 - val_loss: 0.9157 - val_root_mean_squared_error: 0.9413
Epoch 176/500
5/5 [==============================] - 0s 28ms/step - loss: 0.9054 - root_mean_squared_error: 0.9338 - val_loss: 0.8325 - val_root_mean_squared_error: 0.8934
Epoch 177/500
5/5 [==============================] - 0s 36ms/step - loss: 0.8593 - root_mean_squared_error: 0.9097 - val_loss: 0.8139 - val_root_mean_squared_error: 0.8820
Epoch 178/500
5/5 [==============================] - 0s 28ms/step - loss: 0.8372 - root_mean_squared_error: 0.8972 - val_loss: 0.8150 - val_root_mean_squared_error: 0.8840
Epoch 179/500
5/5 [==============================] - 0s 27ms/step - loss: 0.8549 - root_mean_squared_error: 0.9073 - val_loss: 0.8409 - val_root_mean_squared_error: 0.8998
Epoch 180/500
5/5 [==============================] - 0s 30ms/step - loss: 0.7943 - root_mean_squared_error: 0.8727 - val_loss: 0.8278 - val_root_mean_squared_error: 0.8915
Epoch 181/500
5/5 [==============================] - 0s 27ms/step - loss: 0.8167 - root_mean_squared_error: 0.8861 - val_loss: 0.8009 - val_root_mean_squared_error: 0.8760
Epoch 182/500
5/5 [==============================] - 0s 29ms/step - loss: 0.8905 - root_mean_squared_error: 0.9250 - val_loss: 0.8469 - val_root_mean_squared_error: 0.9012
Epoch 183/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7999 - root_mean_squared_error: 0.8741 - val_loss: 0.8378 - val_root_mean_squared_error: 0.8992
Epoch 184/500
5/5 [==============================] - 0s 21ms/step - loss: 0.7940 - root_mean_squared_error: 0.8724 - val_loss: 0.8317 - val_root_mean_squared_error: 0.8923
Epoch 185/500
5/5 [==============================] - 0s 22ms/step - loss: 0.8158 - root_mean_squared_error: 0.8859 - val_loss: 0.8373 - val_root_mean_squared_error: 0.8985
Epoch 186/500
5/5 [==============================] - 0s 28ms/step - loss: 0.8432 - root_mean_squared_error: 0.9006 - val_loss: 0.8377 - val_root_mean_squared_error: 0.8965
Epoch 187/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7356 - root_mean_squared_error: 0.8387 - val_loss: 0.8531 - val_root_mean_squared_error: 0.9065
Epoch 188/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7973 - root_mean_squared_error: 0.8741 - val_loss: 0.8234 - val_root_mean_squared_error: 0.8863
Epoch 189/500
5/5 [==============================] - 0s 30ms/step - loss: 0.7930 - root_mean_squared_error: 0.8725 - val_loss: 0.8415 - val_root_mean_squared_error: 0.8986
Epoch 190/500
5/5 [==============================] - 0s 31ms/step - loss: 0.7828 - root_mean_squared_error: 0.8657 - val_loss: 0.8262 - val_root_mean_squared_error: 0.8917
Epoch 191/500
5/5 [==============================] - 0s 23ms/step - loss: 0.8014 - root_mean_squared_error: 0.8781 - val_loss: 0.8047 - val_root_mean_squared_error: 0.8769
Epoch 192/500
5/5 [==============================] - 0s 28ms/step - loss: 0.7973 - root_mean_squared_error: 0.8764 - val_loss: 0.8059 - val_root_mean_squared_error: 0.8791
Epoch 193/500
5/5 [==============================] - 0s 39ms/step - loss: 0.8175 - root_mean_squared_error: 0.8876 - val_loss: 0.7651 - val_root_mean_squared_error: 0.8562
Epoch 194/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7970 - root_mean_squared_error: 0.8741 - val_loss: 0.7777 - val_root_mean_squared_error: 0.8633
Epoch 195/500
5/5 [==============================] - 0s 31ms/step - loss: 0.8306 - root_mean_squared_error: 0.8930 - val_loss: 0.8448 - val_root_mean_squared_error: 0.9019
Epoch 196/500
5/5 [==============================] - 0s 28ms/step - loss: 0.7860 - root_mean_squared_error: 0.8683 - val_loss: 0.8051 - val_root_mean_squared_error: 0.8774
Epoch 197/500
5/5 [==============================] - 0s 24ms/step - loss: 0.8302 - root_mean_squared_error: 0.8957 - val_loss: 0.8229 - val_root_mean_squared_error: 0.8899
Epoch 198/500
5/5 [==============================] - 0s 23ms/step - loss: 0.8170 - root_mean_squared_error: 0.8855 - val_loss: 0.8098 - val_root_mean_squared_error: 0.8827
Epoch 199/500
5/5 [==============================] - 0s 30ms/step - loss: 0.8138 - root_mean_squared_error: 0.8842 - val_loss: 0.8570 - val_root_mean_squared_error: 0.9062
Epoch 200/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7918 - root_mean_squared_error: 0.8716 - val_loss: 0.7867 - val_root_mean_squared_error: 0.8707
Epoch 201/500
5/5 [==============================] - 0s 23ms/step - loss: 0.8053 - root_mean_squared_error: 0.8815 - val_loss: 0.7856 - val_root_mean_squared_error: 0.8675
Epoch 202/500
5/5 [==============================] - 0s 27ms/step - loss: 0.8463 - root_mean_squared_error: 0.9023 - val_loss: 0.8114 - val_root_mean_squared_error: 0.8834
Epoch 203/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7833 - root_mean_squared_error: 0.8671 - val_loss: 0.7601 - val_root_mean_squared_error: 0.8532
Epoch 204/500
5/5 [==============================] - 0s 22ms/step - loss: 0.8109 - root_mean_squared_error: 0.8832 - val_loss: 0.8228 - val_root_mean_squared_error: 0.8907
Epoch 205/500
5/5 [==============================] - 0s 21ms/step - loss: 0.7760 - root_mean_squared_error: 0.8644 - val_loss: 0.7956 - val_root_mean_squared_error: 0.8745
Epoch 206/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7713 - root_mean_squared_error: 0.8623 - val_loss: 0.8217 - val_root_mean_squared_error: 0.8894
Epoch 207/500
5/5 [==============================] - 0s 26ms/step - loss: 0.8069 - root_mean_squared_error: 0.8809 - val_loss: 0.7965 - val_root_mean_squared_error: 0.8759
Epoch 208/500
5/5 [==============================] - 0s 23ms/step - loss: 0.8124 - root_mean_squared_error: 0.8817 - val_loss: 0.7961 - val_root_mean_squared_error: 0.8733
Epoch 209/500
5/5 [==============================] - 0s 23ms/step - loss: 0.8389 - root_mean_squared_error: 0.8996 - val_loss: 0.7914 - val_root_mean_squared_error: 0.8750
Epoch 210/500
5/5 [==============================] - 0s 26ms/step - loss: 0.8045 - root_mean_squared_error: 0.8772 - val_loss: 0.8036 - val_root_mean_squared_error: 0.8783
Epoch 211/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7933 - root_mean_squared_error: 0.8738 - val_loss: 0.8097 - val_root_mean_squared_error: 0.8828
Epoch 212/500
5/5 [==============================] - 0s 25ms/step - loss: 0.8199 - root_mean_squared_error: 0.8908 - val_loss: 0.8429 - val_root_mean_squared_error: 0.9017
Epoch 213/500
5/5 [==============================] - 0s 25ms/step - loss: 0.8222 - root_mean_squared_error: 0.8902 - val_loss: 0.8020 - val_root_mean_squared_error: 0.8814
Epoch 214/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7380 - root_mean_squared_error: 0.8439 - val_loss: 0.7745 - val_root_mean_squared_error: 0.8632
Epoch 215/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7488 - root_mean_squared_error: 0.8465 - val_loss: 0.8084 - val_root_mean_squared_error: 0.8832
Epoch 216/500
5/5 [==============================] - 0s 33ms/step - loss: 0.7591 - root_mean_squared_error: 0.8542 - val_loss: 0.8019 - val_root_mean_squared_error: 0.8796
Epoch 217/500
5/5 [==============================] - 0s 32ms/step - loss: 0.7245 - root_mean_squared_error: 0.8346 - val_loss: 0.7914 - val_root_mean_squared_error: 0.8732
Epoch 218/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7550 - root_mean_squared_error: 0.8514 - val_loss: 0.8202 - val_root_mean_squared_error: 0.8860
Epoch 219/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7478 - root_mean_squared_error: 0.8467 - val_loss: 0.8037 - val_root_mean_squared_error: 0.8798
Epoch 220/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7451 - root_mean_squared_error: 0.8461 - val_loss: 0.8156 - val_root_mean_squared_error: 0.8841
Epoch 221/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7714 - root_mean_squared_error: 0.8599 - val_loss: 0.7881 - val_root_mean_squared_error: 0.8687
Epoch 222/500
5/5 [==============================] - 0s 26ms/step - loss: 0.8195 - root_mean_squared_error: 0.8884 - val_loss: 0.7675 - val_root_mean_squared_error: 0.8581
Epoch 223/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7437 - root_mean_squared_error: 0.8438 - val_loss: 0.7849 - val_root_mean_squared_error: 0.8691
Epoch 224/500
5/5 [==============================] - 0s 19ms/step - loss: 0.7493 - root_mean_squared_error: 0.8482 - val_loss: 0.7914 - val_root_mean_squared_error: 0.8735
Epoch 225/500
5/5 [==============================] - 0s 30ms/step - loss: 0.6806 - root_mean_squared_error: 0.8076 - val_loss: 0.7875 - val_root_mean_squared_error: 0.8686
Epoch 226/500
5/5 [==============================] - 0s 32ms/step - loss: 0.7668 - root_mean_squared_error: 0.8592 - val_loss: 0.7849 - val_root_mean_squared_error: 0.8690
Epoch 227/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7459 - root_mean_squared_error: 0.8454 - val_loss: 0.8161 - val_root_mean_squared_error: 0.8866
Epoch 228/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7951 - root_mean_squared_error: 0.8743 - val_loss: 0.7768 - val_root_mean_squared_error: 0.8640
Epoch 229/500
5/5 [==============================] - 0s 25ms/step - loss: 0.8032 - root_mean_squared_error: 0.8796 - val_loss: 0.7719 - val_root_mean_squared_error: 0.8607
Epoch 230/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7413 - root_mean_squared_error: 0.8464 - val_loss: 0.7987 - val_root_mean_squared_error: 0.8763
Epoch 231/500
5/5 [==============================] - 0s 23ms/step - loss: 0.8078 - root_mean_squared_error: 0.8814 - val_loss: 0.7694 - val_root_mean_squared_error: 0.8610
Epoch 232/500
5/5 [==============================] - 0s 20ms/step - loss: 0.7410 - root_mean_squared_error: 0.8422 - val_loss: 0.7827 - val_root_mean_squared_error: 0.8682
Epoch 233/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7736 - root_mean_squared_error: 0.8617 - val_loss: 0.7603 - val_root_mean_squared_error: 0.8522
Epoch 234/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7463 - root_mean_squared_error: 0.8481 - val_loss: 0.7893 - val_root_mean_squared_error: 0.8706
Epoch 235/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7663 - root_mean_squared_error: 0.8585 - val_loss: 0.7472 - val_root_mean_squared_error: 0.8444
Epoch 236/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7483 - root_mean_squared_error: 0.8479 - val_loss: 0.7707 - val_root_mean_squared_error: 0.8597
Epoch 237/500
5/5 [==============================] - 0s 28ms/step - loss: 0.7768 - root_mean_squared_error: 0.8638 - val_loss: 0.7496 - val_root_mean_squared_error: 0.8503
Epoch 238/500
5/5 [==============================] - 0s 29ms/step - loss: 0.8027 - root_mean_squared_error: 0.8790 - val_loss: 0.7824 - val_root_mean_squared_error: 0.8645
Epoch 239/500
5/5 [==============================] - 0s 34ms/step - loss: 0.7563 - root_mean_squared_error: 0.8522 - val_loss: 0.8117 - val_root_mean_squared_error: 0.8843
Epoch 240/500
5/5 [==============================] - 0s 32ms/step - loss: 0.7705 - root_mean_squared_error: 0.8591 - val_loss: 0.8118 - val_root_mean_squared_error: 0.8850
Epoch 241/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7586 - root_mean_squared_error: 0.8566 - val_loss: 0.7339 - val_root_mean_squared_error: 0.8388
Epoch 242/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7931 - root_mean_squared_error: 0.8745 - val_loss: 0.7557 - val_root_mean_squared_error: 0.8537
Epoch 243/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7443 - root_mean_squared_error: 0.8453 - val_loss: 0.7582 - val_root_mean_squared_error: 0.8557
Epoch 244/500
5/5 [==============================] - 0s 31ms/step - loss: 0.7583 - root_mean_squared_error: 0.8529 - val_loss: 0.7421 - val_root_mean_squared_error: 0.8454
Epoch 245/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7817 - root_mean_squared_error: 0.8653 - val_loss: 0.7772 - val_root_mean_squared_error: 0.8656
Epoch 246/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7552 - root_mean_squared_error: 0.8513 - val_loss: 0.7824 - val_root_mean_squared_error: 0.8663
Epoch 247/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7185 - root_mean_squared_error: 0.8297 - val_loss: 0.7540 - val_root_mean_squared_error: 0.8510
Epoch 248/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7556 - root_mean_squared_error: 0.8492 - val_loss: 0.7449 - val_root_mean_squared_error: 0.8454
Epoch 249/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7620 - root_mean_squared_error: 0.8543 - val_loss: 0.7695 - val_root_mean_squared_error: 0.8596
Epoch 250/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7251 - root_mean_squared_error: 0.8338 - val_loss: 0.7347 - val_root_mean_squared_error: 0.8383
Epoch 251/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7174 - root_mean_squared_error: 0.8295 - val_loss: 0.7553 - val_root_mean_squared_error: 0.8493
Epoch 252/500
5/5 [==============================] - 0s 30ms/step - loss: 0.7717 - root_mean_squared_error: 0.8622 - val_loss: 0.7592 - val_root_mean_squared_error: 0.8539
Epoch 253/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7369 - root_mean_squared_error: 0.8414 - val_loss: 0.7689 - val_root_mean_squared_error: 0.8585
Epoch 254/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7067 - root_mean_squared_error: 0.8244 - val_loss: 0.7219 - val_root_mean_squared_error: 0.8290
Epoch 255/500
5/5 [==============================] - 0s 27ms/step - loss: 0.8126 - root_mean_squared_error: 0.8857 - val_loss: 0.7669 - val_root_mean_squared_error: 0.8577
Epoch 256/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7525 - root_mean_squared_error: 0.8516 - val_loss: 0.7459 - val_root_mean_squared_error: 0.8469
Epoch 257/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7937 - root_mean_squared_error: 0.8748 - val_loss: 0.8144 - val_root_mean_squared_error: 0.8861
Epoch 258/500
5/5 [==============================] - 0s 31ms/step - loss: 0.7446 - root_mean_squared_error: 0.8440 - val_loss: 0.7588 - val_root_mean_squared_error: 0.8533
Epoch 259/500
5/5 [==============================] - 0s 28ms/step - loss: 0.7812 - root_mean_squared_error: 0.8667 - val_loss: 0.7559 - val_root_mean_squared_error: 0.8530
Epoch 260/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6859 - root_mean_squared_error: 0.8121 - val_loss: 0.7240 - val_root_mean_squared_error: 0.8307
Epoch 261/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7373 - root_mean_squared_error: 0.8418 - val_loss: 0.7405 - val_root_mean_squared_error: 0.8428
Epoch 262/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7720 - root_mean_squared_error: 0.8612 - val_loss: 0.7949 - val_root_mean_squared_error: 0.8761
Epoch 263/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7464 - root_mean_squared_error: 0.8464 - val_loss: 0.7316 - val_root_mean_squared_error: 0.8381
Epoch 264/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7128 - root_mean_squared_error: 0.8256 - val_loss: 0.6999 - val_root_mean_squared_error: 0.8188
Epoch 265/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7190 - root_mean_squared_error: 0.8288 - val_loss: 0.7083 - val_root_mean_squared_error: 0.8226
Epoch 266/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7574 - root_mean_squared_error: 0.8534 - val_loss: 0.7905 - val_root_mean_squared_error: 0.8720
Epoch 267/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7564 - root_mean_squared_error: 0.8534 - val_loss: 0.7341 - val_root_mean_squared_error: 0.8391
Epoch 268/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7369 - root_mean_squared_error: 0.8414 - val_loss: 0.7171 - val_root_mean_squared_error: 0.8307
Epoch 269/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7808 - root_mean_squared_error: 0.8663 - val_loss: 0.7030 - val_root_mean_squared_error: 0.8184
Epoch 270/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7248 - root_mean_squared_error: 0.8356 - val_loss: 0.7691 - val_root_mean_squared_error: 0.8597
Epoch 271/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7879 - root_mean_squared_error: 0.8715 - val_loss: 0.6943 - val_root_mean_squared_error: 0.8150
Epoch 272/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7056 - root_mean_squared_error: 0.8218 - val_loss: 0.7233 - val_root_mean_squared_error: 0.8319
Epoch 273/500
5/5 [==============================] - 0s 21ms/step - loss: 0.7291 - root_mean_squared_error: 0.8375 - val_loss: 0.7130 - val_root_mean_squared_error: 0.8240
Epoch 274/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7284 - root_mean_squared_error: 0.8380 - val_loss: 0.7421 - val_root_mean_squared_error: 0.8439
Epoch 275/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7684 - root_mean_squared_error: 0.8616 - val_loss: 0.7653 - val_root_mean_squared_error: 0.8600
Epoch 276/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6878 - root_mean_squared_error: 0.8113 - val_loss: 0.7821 - val_root_mean_squared_error: 0.8678
Epoch 277/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7141 - root_mean_squared_error: 0.8289 - val_loss: 0.7199 - val_root_mean_squared_error: 0.8286
Epoch 278/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7454 - root_mean_squared_error: 0.8467 - val_loss: 0.6999 - val_root_mean_squared_error: 0.8191
Epoch 279/500
5/5 [==============================] - 0s 28ms/step - loss: 0.7133 - root_mean_squared_error: 0.8276 - val_loss: 0.7525 - val_root_mean_squared_error: 0.8502
Epoch 280/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7848 - root_mean_squared_error: 0.8707 - val_loss: 0.7914 - val_root_mean_squared_error: 0.8744
Epoch 281/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7039 - root_mean_squared_error: 0.8202 - val_loss: 0.7137 - val_root_mean_squared_error: 0.8276
Epoch 282/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7462 - root_mean_squared_error: 0.8458 - val_loss: 0.7549 - val_root_mean_squared_error: 0.8529
Epoch 283/500
5/5 [==============================] - 0s 20ms/step - loss: 0.7456 - root_mean_squared_error: 0.8458 - val_loss: 0.7215 - val_root_mean_squared_error: 0.8307
Epoch 284/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7651 - root_mean_squared_error: 0.8566 - val_loss: 0.7159 - val_root_mean_squared_error: 0.8297
Epoch 285/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7101 - root_mean_squared_error: 0.8237 - val_loss: 0.7234 - val_root_mean_squared_error: 0.8342
Epoch 286/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7140 - root_mean_squared_error: 0.8271 - val_loss: 0.6973 - val_root_mean_squared_error: 0.8186
Epoch 287/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7360 - root_mean_squared_error: 0.8396 - val_loss: 0.7406 - val_root_mean_squared_error: 0.8423
Epoch 288/500
5/5 [==============================] - 0s 32ms/step - loss: 0.7664 - root_mean_squared_error: 0.8586 - val_loss: 0.7018 - val_root_mean_squared_error: 0.8179
Epoch 289/500
5/5 [==============================] - 0s 19ms/step - loss: 0.7723 - root_mean_squared_error: 0.8622 - val_loss: 0.7463 - val_root_mean_squared_error: 0.8469
Epoch 290/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7424 - root_mean_squared_error: 0.8438 - val_loss: 0.7500 - val_root_mean_squared_error: 0.8485
Epoch 291/500
5/5 [==============================] - 0s 28ms/step - loss: 0.7492 - root_mean_squared_error: 0.8484 - val_loss: 0.7287 - val_root_mean_squared_error: 0.8367
Epoch 292/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7017 - root_mean_squared_error: 0.8216 - val_loss: 0.7081 - val_root_mean_squared_error: 0.8209
Epoch 293/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7031 - root_mean_squared_error: 0.8210 - val_loss: 0.6985 - val_root_mean_squared_error: 0.8195
Epoch 294/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7511 - root_mean_squared_error: 0.8480 - val_loss: 0.7441 - val_root_mean_squared_error: 0.8461
Epoch 295/500
5/5 [==============================] - 0s 21ms/step - loss: 0.6742 - root_mean_squared_error: 0.8029 - val_loss: 0.7558 - val_root_mean_squared_error: 0.8516
Epoch 296/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7109 - root_mean_squared_error: 0.8275 - val_loss: 0.7490 - val_root_mean_squared_error: 0.8497
Epoch 297/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7360 - root_mean_squared_error: 0.8420 - val_loss: 0.8057 - val_root_mean_squared_error: 0.8815
Epoch 298/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7399 - root_mean_squared_error: 0.8434 - val_loss: 0.7033 - val_root_mean_squared_error: 0.8198
Epoch 299/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7317 - root_mean_squared_error: 0.8385 - val_loss: 0.7436 - val_root_mean_squared_error: 0.8457
Epoch 300/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7597 - root_mean_squared_error: 0.8540 - val_loss: 0.7059 - val_root_mean_squared_error: 0.8231
Epoch 301/500
5/5 [==============================] - 0s 34ms/step - loss: 0.7186 - root_mean_squared_error: 0.8305 - val_loss: 0.7575 - val_root_mean_squared_error: 0.8517
Epoch 302/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7263 - root_mean_squared_error: 0.8371 - val_loss: 0.7538 - val_root_mean_squared_error: 0.8522
Epoch 303/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6524 - root_mean_squared_error: 0.7878 - val_loss: 0.7127 - val_root_mean_squared_error: 0.8281
Epoch 304/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7167 - root_mean_squared_error: 0.8280 - val_loss: 0.7203 - val_root_mean_squared_error: 0.8295
Epoch 305/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7221 - root_mean_squared_error: 0.8329 - val_loss: 0.7037 - val_root_mean_squared_error: 0.8190
Epoch 306/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6728 - root_mean_squared_error: 0.8023 - val_loss: 0.7845 - val_root_mean_squared_error: 0.8713
Epoch 307/500
5/5 [==============================] - 0s 31ms/step - loss: 0.6916 - root_mean_squared_error: 0.8142 - val_loss: 0.6959 - val_root_mean_squared_error: 0.8158
Epoch 308/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7239 - root_mean_squared_error: 0.8336 - val_loss: 0.7282 - val_root_mean_squared_error: 0.8397
Epoch 309/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7478 - root_mean_squared_error: 0.8495 - val_loss: 0.7817 - val_root_mean_squared_error: 0.8686
Epoch 310/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6706 - root_mean_squared_error: 0.8017 - val_loss: 0.7330 - val_root_mean_squared_error: 0.8383
Epoch 311/500
5/5 [==============================] - 0s 31ms/step - loss: 0.6897 - root_mean_squared_error: 0.8137 - val_loss: 0.7481 - val_root_mean_squared_error: 0.8495
Epoch 312/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6801 - root_mean_squared_error: 0.8088 - val_loss: 0.7618 - val_root_mean_squared_error: 0.8558
Epoch 313/500
5/5 [==============================] - 0s 21ms/step - loss: 0.6810 - root_mean_squared_error: 0.8079 - val_loss: 0.7566 - val_root_mean_squared_error: 0.8546
Epoch 314/500
5/5 [==============================] - 0s 28ms/step - loss: 0.6643 - root_mean_squared_error: 0.7974 - val_loss: 0.7488 - val_root_mean_squared_error: 0.8485
Epoch 315/500
5/5 [==============================] - 0s 28ms/step - loss: 0.6548 - root_mean_squared_error: 0.7895 - val_loss: 0.7751 - val_root_mean_squared_error: 0.8643
Epoch 316/500
5/5 [==============================] - 0s 28ms/step - loss: 0.6713 - root_mean_squared_error: 0.8032 - val_loss: 0.7421 - val_root_mean_squared_error: 0.8441
Epoch 317/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7397 - root_mean_squared_error: 0.8426 - val_loss: 0.7603 - val_root_mean_squared_error: 0.8537
Epoch 318/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7837 - root_mean_squared_error: 0.8695 - val_loss: 0.7411 - val_root_mean_squared_error: 0.8441
Epoch 319/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7166 - root_mean_squared_error: 0.8300 - val_loss: 0.7186 - val_root_mean_squared_error: 0.8303
Epoch 320/500
5/5 [==============================] - 0s 34ms/step - loss: 0.6763 - root_mean_squared_error: 0.8031 - val_loss: 0.7040 - val_root_mean_squared_error: 0.8211
Epoch 321/500
5/5 [==============================] - 0s 34ms/step - loss: 0.6754 - root_mean_squared_error: 0.8039 - val_loss: 0.7055 - val_root_mean_squared_error: 0.8229
Epoch 322/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7049 - root_mean_squared_error: 0.8196 - val_loss: 0.7296 - val_root_mean_squared_error: 0.8377
Epoch 323/500
5/5 [==============================] - 0s 21ms/step - loss: 0.7071 - root_mean_squared_error: 0.8231 - val_loss: 0.7034 - val_root_mean_squared_error: 0.8214
Epoch 324/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7280 - root_mean_squared_error: 0.8382 - val_loss: 0.7466 - val_root_mean_squared_error: 0.8487
Epoch 325/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6843 - root_mean_squared_error: 0.8094 - val_loss: 0.7061 - val_root_mean_squared_error: 0.8236
Epoch 326/500
5/5 [==============================] - 0s 31ms/step - loss: 0.7096 - root_mean_squared_error: 0.8273 - val_loss: 0.6882 - val_root_mean_squared_error: 0.8110
Epoch 327/500
5/5 [==============================] - 0s 29ms/step - loss: 0.6793 - root_mean_squared_error: 0.8073 - val_loss: 0.7071 - val_root_mean_squared_error: 0.8215
Epoch 328/500
5/5 [==============================] - 0s 31ms/step - loss: 0.7300 - root_mean_squared_error: 0.8373 - val_loss: 0.7330 - val_root_mean_squared_error: 0.8384
Epoch 329/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6856 - root_mean_squared_error: 0.8114 - val_loss: 0.7302 - val_root_mean_squared_error: 0.8359
Epoch 330/500
5/5 [==============================] - 0s 20ms/step - loss: 0.6895 - root_mean_squared_error: 0.8132 - val_loss: 0.7051 - val_root_mean_squared_error: 0.8202
Epoch 331/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7366 - root_mean_squared_error: 0.8395 - val_loss: 0.6993 - val_root_mean_squared_error: 0.8167
Epoch 332/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7107 - root_mean_squared_error: 0.8263 - val_loss: 0.6585 - val_root_mean_squared_error: 0.7941
Epoch 333/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6971 - root_mean_squared_error: 0.8172 - val_loss: 0.6891 - val_root_mean_squared_error: 0.8118
Epoch 334/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7011 - root_mean_squared_error: 0.8199 - val_loss: 0.6736 - val_root_mean_squared_error: 0.8026
Epoch 335/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7328 - root_mean_squared_error: 0.8406 - val_loss: 0.6817 - val_root_mean_squared_error: 0.8088
Epoch 336/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6662 - root_mean_squared_error: 0.7978 - val_loss: 0.7121 - val_root_mean_squared_error: 0.8256
Epoch 337/500
5/5 [==============================] - 0s 20ms/step - loss: 0.6920 - root_mean_squared_error: 0.8143 - val_loss: 0.6808 - val_root_mean_squared_error: 0.8087
Epoch 338/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7025 - root_mean_squared_error: 0.8237 - val_loss: 0.7091 - val_root_mean_squared_error: 0.8249
Epoch 339/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6955 - root_mean_squared_error: 0.8168 - val_loss: 0.6800 - val_root_mean_squared_error: 0.8070
Epoch 340/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7503 - root_mean_squared_error: 0.8503 - val_loss: 0.7430 - val_root_mean_squared_error: 0.8454
Epoch 341/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6634 - root_mean_squared_error: 0.7953 - val_loss: 0.6672 - val_root_mean_squared_error: 0.8002
Epoch 342/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6909 - root_mean_squared_error: 0.8129 - val_loss: 0.7209 - val_root_mean_squared_error: 0.8327
Epoch 343/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6557 - root_mean_squared_error: 0.7917 - val_loss: 0.6588 - val_root_mean_squared_error: 0.7947
Epoch 344/500
5/5 [==============================] - 0s 20ms/step - loss: 0.6758 - root_mean_squared_error: 0.8045 - val_loss: 0.6848 - val_root_mean_squared_error: 0.8091
Epoch 345/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6803 - root_mean_squared_error: 0.8076 - val_loss: 0.7146 - val_root_mean_squared_error: 0.8275
Epoch 346/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6997 - root_mean_squared_error: 0.8182 - val_loss: 0.6947 - val_root_mean_squared_error: 0.8164
Epoch 347/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6875 - root_mean_squared_error: 0.8143 - val_loss: 0.6760 - val_root_mean_squared_error: 0.8019
Epoch 348/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6350 - root_mean_squared_error: 0.7772 - val_loss: 0.7278 - val_root_mean_squared_error: 0.8375
Epoch 349/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6631 - root_mean_squared_error: 0.7974 - val_loss: 0.7177 - val_root_mean_squared_error: 0.8321
Epoch 350/500
5/5 [==============================] - 0s 21ms/step - loss: 0.6558 - root_mean_squared_error: 0.7925 - val_loss: 0.6433 - val_root_mean_squared_error: 0.7834
Epoch 351/500
5/5 [==============================] - 0s 33ms/step - loss: 0.6844 - root_mean_squared_error: 0.8094 - val_loss: 0.6984 - val_root_mean_squared_error: 0.8152
Epoch 352/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7268 - root_mean_squared_error: 0.8339 - val_loss: 0.6726 - val_root_mean_squared_error: 0.8006
Epoch 353/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6619 - root_mean_squared_error: 0.7939 - val_loss: 0.6720 - val_root_mean_squared_error: 0.8030
Epoch 354/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6869 - root_mean_squared_error: 0.8090 - val_loss: 0.7145 - val_root_mean_squared_error: 0.8256
Epoch 355/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6404 - root_mean_squared_error: 0.7816 - val_loss: 0.6814 - val_root_mean_squared_error: 0.8062
Epoch 356/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6913 - root_mean_squared_error: 0.8143 - val_loss: 0.7008 - val_root_mean_squared_error: 0.8192
Epoch 357/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6944 - root_mean_squared_error: 0.8159 - val_loss: 0.6988 - val_root_mean_squared_error: 0.8197
Epoch 358/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6812 - root_mean_squared_error: 0.8076 - val_loss: 0.6673 - val_root_mean_squared_error: 0.8004
Epoch 359/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6765 - root_mean_squared_error: 0.8049 - val_loss: 0.7180 - val_root_mean_squared_error: 0.8318
Epoch 360/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7105 - root_mean_squared_error: 0.8245 - val_loss: 0.7048 - val_root_mean_squared_error: 0.8249
Epoch 361/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6969 - root_mean_squared_error: 0.8168 - val_loss: 0.6592 - val_root_mean_squared_error: 0.7958
Epoch 362/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7152 - root_mean_squared_error: 0.8283 - val_loss: 0.6755 - val_root_mean_squared_error: 0.8055
Epoch 363/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6693 - root_mean_squared_error: 0.7994 - val_loss: 0.6763 - val_root_mean_squared_error: 0.8076
Epoch 364/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7281 - root_mean_squared_error: 0.8379 - val_loss: 0.6598 - val_root_mean_squared_error: 0.7948
Epoch 365/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6842 - root_mean_squared_error: 0.8081 - val_loss: 0.6871 - val_root_mean_squared_error: 0.8093
Epoch 366/500
5/5 [==============================] - 0s 20ms/step - loss: 0.6919 - root_mean_squared_error: 0.8147 - val_loss: 0.6784 - val_root_mean_squared_error: 0.8045
Epoch 367/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7072 - root_mean_squared_error: 0.8219 - val_loss: 0.6713 - val_root_mean_squared_error: 0.8002
Epoch 368/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6952 - root_mean_squared_error: 0.8165 - val_loss: 0.6921 - val_root_mean_squared_error: 0.8139
Epoch 369/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6654 - root_mean_squared_error: 0.7974 - val_loss: 0.7000 - val_root_mean_squared_error: 0.8207
Epoch 370/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6727 - root_mean_squared_error: 0.8028 - val_loss: 0.6564 - val_root_mean_squared_error: 0.7901
Epoch 371/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7204 - root_mean_squared_error: 0.8319 - val_loss: 0.6681 - val_root_mean_squared_error: 0.7950
Epoch 372/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7157 - root_mean_squared_error: 0.8280 - val_loss: 0.6532 - val_root_mean_squared_error: 0.7880
Epoch 373/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6961 - root_mean_squared_error: 0.8178 - val_loss: 0.6710 - val_root_mean_squared_error: 0.7988
Epoch 374/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6899 - root_mean_squared_error: 0.8147 - val_loss: 0.6739 - val_root_mean_squared_error: 0.8025
Epoch 375/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6702 - root_mean_squared_error: 0.8003 - val_loss: 0.7214 - val_root_mean_squared_error: 0.8304
Epoch 376/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6834 - root_mean_squared_error: 0.8105 - val_loss: 0.6762 - val_root_mean_squared_error: 0.8041
Epoch 377/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6687 - root_mean_squared_error: 0.7990 - val_loss: 0.7072 - val_root_mean_squared_error: 0.8244
Epoch 378/500
5/5 [==============================] - 0s 32ms/step - loss: 0.6372 - root_mean_squared_error: 0.7796 - val_loss: 0.6850 - val_root_mean_squared_error: 0.8074
Epoch 379/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6891 - root_mean_squared_error: 0.8122 - val_loss: 0.6513 - val_root_mean_squared_error: 0.7889
Epoch 380/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6950 - root_mean_squared_error: 0.8148 - val_loss: 0.6605 - val_root_mean_squared_error: 0.7959
Epoch 381/500
5/5 [==============================] - 0s 21ms/step - loss: 0.7193 - root_mean_squared_error: 0.8330 - val_loss: 0.6809 - val_root_mean_squared_error: 0.8050
Epoch 382/500
5/5 [==============================] - 0s 28ms/step - loss: 0.6659 - root_mean_squared_error: 0.7954 - val_loss: 0.6759 - val_root_mean_squared_error: 0.8054
Epoch 383/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6390 - root_mean_squared_error: 0.7805 - val_loss: 0.6821 - val_root_mean_squared_error: 0.8078
Epoch 384/500
5/5 [==============================] - 0s 21ms/step - loss: 0.6924 - root_mean_squared_error: 0.8150 - val_loss: 0.6700 - val_root_mean_squared_error: 0.8019
Epoch 385/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6564 - root_mean_squared_error: 0.7897 - val_loss: 0.6585 - val_root_mean_squared_error: 0.7930
Epoch 386/500
5/5 [==============================] - 0s 21ms/step - loss: 0.7351 - root_mean_squared_error: 0.8392 - val_loss: 0.6965 - val_root_mean_squared_error: 0.8162
Epoch 387/500
5/5 [==============================] - 0s 20ms/step - loss: 0.6779 - root_mean_squared_error: 0.8073 - val_loss: 0.6781 - val_root_mean_squared_error: 0.8053
Epoch 388/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7048 - root_mean_squared_error: 0.8237 - val_loss: 0.6726 - val_root_mean_squared_error: 0.8012
Epoch 389/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6583 - root_mean_squared_error: 0.7944 - val_loss: 0.6548 - val_root_mean_squared_error: 0.7911
Epoch 390/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7661 - root_mean_squared_error: 0.8580 - val_loss: 0.7159 - val_root_mean_squared_error: 0.8267
Epoch 391/500
5/5 [==============================] - 0s 21ms/step - loss: 0.6003 - root_mean_squared_error: 0.7536 - val_loss: 0.6651 - val_root_mean_squared_error: 0.7993
Epoch 392/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7008 - root_mean_squared_error: 0.8195 - val_loss: 0.6778 - val_root_mean_squared_error: 0.8054
Epoch 393/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6790 - root_mean_squared_error: 0.8060 - val_loss: 0.6445 - val_root_mean_squared_error: 0.7818
Epoch 394/500
5/5 [==============================] - 0s 30ms/step - loss: 0.6926 - root_mean_squared_error: 0.8146 - val_loss: 0.7003 - val_root_mean_squared_error: 0.8218
Epoch 395/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6962 - root_mean_squared_error: 0.8150 - val_loss: 0.7089 - val_root_mean_squared_error: 0.8239
Epoch 396/500
5/5 [==============================] - 0s 21ms/step - loss: 0.6568 - root_mean_squared_error: 0.7936 - val_loss: 0.6611 - val_root_mean_squared_error: 0.7929
Epoch 397/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6857 - root_mean_squared_error: 0.8083 - val_loss: 0.6761 - val_root_mean_squared_error: 0.8065
Epoch 398/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7426 - root_mean_squared_error: 0.8439 - val_loss: 0.7037 - val_root_mean_squared_error: 0.8225
Epoch 399/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6888 - root_mean_squared_error: 0.8127 - val_loss: 0.7160 - val_root_mean_squared_error: 0.8277
Epoch 400/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6737 - root_mean_squared_error: 0.8041 - val_loss: 0.6595 - val_root_mean_squared_error: 0.7950
Epoch 401/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6773 - root_mean_squared_error: 0.8034 - val_loss: 0.6582 - val_root_mean_squared_error: 0.7941
Epoch 402/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7608 - root_mean_squared_error: 0.8572 - val_loss: 0.6646 - val_root_mean_squared_error: 0.7971
Epoch 403/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7115 - root_mean_squared_error: 0.8254 - val_loss: 0.6580 - val_root_mean_squared_error: 0.7950
Epoch 404/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6345 - root_mean_squared_error: 0.7779 - val_loss: 0.6725 - val_root_mean_squared_error: 0.8022
Epoch 405/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6502 - root_mean_squared_error: 0.7876 - val_loss: 0.7300 - val_root_mean_squared_error: 0.8363
Epoch 406/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6306 - root_mean_squared_error: 0.7757 - val_loss: 0.7698 - val_root_mean_squared_error: 0.8611
Epoch 407/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7494 - root_mean_squared_error: 0.8487 - val_loss: 0.6653 - val_root_mean_squared_error: 0.7954
Epoch 408/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6685 - root_mean_squared_error: 0.8004 - val_loss: 0.6712 - val_root_mean_squared_error: 0.7983
Epoch 409/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6229 - root_mean_squared_error: 0.7711 - val_loss: 0.6552 - val_root_mean_squared_error: 0.7920
Epoch 410/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6350 - root_mean_squared_error: 0.7785 - val_loss: 0.6482 - val_root_mean_squared_error: 0.7879
Epoch 411/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6904 - root_mean_squared_error: 0.8135 - val_loss: 0.6672 - val_root_mean_squared_error: 0.7976
Epoch 412/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6548 - root_mean_squared_error: 0.7915 - val_loss: 0.6504 - val_root_mean_squared_error: 0.7871
Epoch 413/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6813 - root_mean_squared_error: 0.8066 - val_loss: 0.6828 - val_root_mean_squared_error: 0.8077
Epoch 414/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7024 - root_mean_squared_error: 0.8197 - val_loss: 0.6455 - val_root_mean_squared_error: 0.7847
Epoch 415/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6708 - root_mean_squared_error: 0.8023 - val_loss: 0.6473 - val_root_mean_squared_error: 0.7872
Epoch 416/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6958 - root_mean_squared_error: 0.8151 - val_loss: 0.6666 - val_root_mean_squared_error: 0.7985
Epoch 417/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6785 - root_mean_squared_error: 0.8068 - val_loss: 0.6630 - val_root_mean_squared_error: 0.7956
Epoch 418/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6193 - root_mean_squared_error: 0.7681 - val_loss: 0.6801 - val_root_mean_squared_error: 0.8059
Epoch 419/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6624 - root_mean_squared_error: 0.7958 - val_loss: 0.6658 - val_root_mean_squared_error: 0.7981
Epoch 420/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6167 - root_mean_squared_error: 0.7659 - val_loss: 0.6526 - val_root_mean_squared_error: 0.7855
Epoch 421/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7018 - root_mean_squared_error: 0.8203 - val_loss: 0.7025 - val_root_mean_squared_error: 0.8230
Epoch 422/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6878 - root_mean_squared_error: 0.8111 - val_loss: 0.6621 - val_root_mean_squared_error: 0.7960
Epoch 423/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6611 - root_mean_squared_error: 0.7936 - val_loss: 0.6418 - val_root_mean_squared_error: 0.7802
Epoch 424/500
5/5 [==============================] - 0s 21ms/step - loss: 0.6957 - root_mean_squared_error: 0.8178 - val_loss: 0.6632 - val_root_mean_squared_error: 0.7970
Epoch 425/500
5/5 [==============================] - 0s 23ms/step - loss: 0.7146 - root_mean_squared_error: 0.8294 - val_loss: 0.6749 - val_root_mean_squared_error: 0.8016
Epoch 426/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7159 - root_mean_squared_error: 0.8286 - val_loss: 0.6657 - val_root_mean_squared_error: 0.7967
Epoch 427/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6828 - root_mean_squared_error: 0.8084 - val_loss: 0.6983 - val_root_mean_squared_error: 0.8200
Epoch 428/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6561 - root_mean_squared_error: 0.7921 - val_loss: 0.6824 - val_root_mean_squared_error: 0.8067
Epoch 429/500
5/5 [==============================] - 0s 28ms/step - loss: 0.7249 - root_mean_squared_error: 0.8357 - val_loss: 0.6606 - val_root_mean_squared_error: 0.7955
Epoch 430/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7088 - root_mean_squared_error: 0.8243 - val_loss: 0.6562 - val_root_mean_squared_error: 0.7908
Epoch 431/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6535 - root_mean_squared_error: 0.7891 - val_loss: 0.6765 - val_root_mean_squared_error: 0.8041
Epoch 432/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6527 - root_mean_squared_error: 0.7885 - val_loss: 0.6471 - val_root_mean_squared_error: 0.7871
Epoch 433/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6689 - root_mean_squared_error: 0.8003 - val_loss: 0.7102 - val_root_mean_squared_error: 0.8246
Epoch 434/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6718 - root_mean_squared_error: 0.8019 - val_loss: 0.6677 - val_root_mean_squared_error: 0.7967
Epoch 435/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7288 - root_mean_squared_error: 0.8359 - val_loss: 0.6336 - val_root_mean_squared_error: 0.7755
Epoch 436/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6777 - root_mean_squared_error: 0.8051 - val_loss: 0.6616 - val_root_mean_squared_error: 0.7943
Epoch 437/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6481 - root_mean_squared_error: 0.7872 - val_loss: 0.6603 - val_root_mean_squared_error: 0.7930
Epoch 438/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6716 - root_mean_squared_error: 0.8021 - val_loss: 0.6460 - val_root_mean_squared_error: 0.7832
Epoch 439/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7170 - root_mean_squared_error: 0.8306 - val_loss: 0.6658 - val_root_mean_squared_error: 0.7952
Epoch 440/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6244 - root_mean_squared_error: 0.7690 - val_loss: 0.6708 - val_root_mean_squared_error: 0.8001
Epoch 441/500
5/5 [==============================] - 0s 21ms/step - loss: 0.6624 - root_mean_squared_error: 0.7958 - val_loss: 0.6662 - val_root_mean_squared_error: 0.7990
Epoch 442/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6910 - root_mean_squared_error: 0.8140 - val_loss: 0.6651 - val_root_mean_squared_error: 0.7960
Epoch 443/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6355 - root_mean_squared_error: 0.7807 - val_loss: 0.6514 - val_root_mean_squared_error: 0.7856
Epoch 444/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6915 - root_mean_squared_error: 0.8147 - val_loss: 0.6765 - val_root_mean_squared_error: 0.8038
Epoch 445/500
5/5 [==============================] - 0s 31ms/step - loss: 0.7486 - root_mean_squared_error: 0.8490 - val_loss: 0.6649 - val_root_mean_squared_error: 0.7959
Epoch 446/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6702 - root_mean_squared_error: 0.7997 - val_loss: 0.6883 - val_root_mean_squared_error: 0.8126
Epoch 447/500
5/5 [==============================] - 0s 30ms/step - loss: 0.6506 - root_mean_squared_error: 0.7882 - val_loss: 0.7326 - val_root_mean_squared_error: 0.8381
Epoch 448/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6626 - root_mean_squared_error: 0.7970 - val_loss: 0.6638 - val_root_mean_squared_error: 0.7939
Epoch 449/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6904 - root_mean_squared_error: 0.8127 - val_loss: 0.6804 - val_root_mean_squared_error: 0.8061
Epoch 450/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6510 - root_mean_squared_error: 0.7891 - val_loss: 0.6561 - val_root_mean_squared_error: 0.7908
Epoch 451/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6352 - root_mean_squared_error: 0.7763 - val_loss: 0.6819 - val_root_mean_squared_error: 0.8065
Epoch 452/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6848 - root_mean_squared_error: 0.8093 - val_loss: 0.6436 - val_root_mean_squared_error: 0.7829
Epoch 453/500
5/5 [==============================] - 0s 26ms/step - loss: 0.7680 - root_mean_squared_error: 0.8598 - val_loss: 0.6335 - val_root_mean_squared_error: 0.7769
Epoch 454/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6836 - root_mean_squared_error: 0.8093 - val_loss: 0.6540 - val_root_mean_squared_error: 0.7891
Epoch 455/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6953 - root_mean_squared_error: 0.8152 - val_loss: 0.6510 - val_root_mean_squared_error: 0.7902
Epoch 456/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6269 - root_mean_squared_error: 0.7745 - val_loss: 0.6444 - val_root_mean_squared_error: 0.7849
Epoch 457/500
5/5 [==============================] - 0s 29ms/step - loss: 0.6121 - root_mean_squared_error: 0.7605 - val_loss: 0.7022 - val_root_mean_squared_error: 0.8207
Epoch 458/500
5/5 [==============================] - 0s 32ms/step - loss: 0.5533 - root_mean_squared_error: 0.7216 - val_loss: 0.6657 - val_root_mean_squared_error: 0.7961
Epoch 459/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6766 - root_mean_squared_error: 0.8045 - val_loss: 0.6595 - val_root_mean_squared_error: 0.7922
Epoch 460/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6805 - root_mean_squared_error: 0.8071 - val_loss: 0.6554 - val_root_mean_squared_error: 0.7886
Epoch 461/500
5/5 [==============================] - 0s 31ms/step - loss: 0.6653 - root_mean_squared_error: 0.7982 - val_loss: 0.6298 - val_root_mean_squared_error: 0.7770
Epoch 462/500
5/5 [==============================] - 0s 28ms/step - loss: 0.6765 - root_mean_squared_error: 0.8034 - val_loss: 0.6701 - val_root_mean_squared_error: 0.7986
Epoch 463/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6762 - root_mean_squared_error: 0.8026 - val_loss: 0.6651 - val_root_mean_squared_error: 0.7973
Epoch 464/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6632 - root_mean_squared_error: 0.7942 - val_loss: 0.6609 - val_root_mean_squared_error: 0.7946
Epoch 465/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6909 - root_mean_squared_error: 0.8140 - val_loss: 0.6453 - val_root_mean_squared_error: 0.7832
Epoch 466/500
5/5 [==============================] - 0s 25ms/step - loss: 0.7278 - root_mean_squared_error: 0.8361 - val_loss: 0.6627 - val_root_mean_squared_error: 0.7949
Epoch 467/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6466 - root_mean_squared_error: 0.7843 - val_loss: 0.6565 - val_root_mean_squared_error: 0.7904
Epoch 468/500
5/5 [==============================] - 0s 32ms/step - loss: 0.6577 - root_mean_squared_error: 0.7924 - val_loss: 0.6410 - val_root_mean_squared_error: 0.7848
Epoch 469/500
5/5 [==============================] - 0s 22ms/step - loss: 0.7099 - root_mean_squared_error: 0.8246 - val_loss: 0.6684 - val_root_mean_squared_error: 0.7989
Epoch 470/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7300 - root_mean_squared_error: 0.8366 - val_loss: 0.7747 - val_root_mean_squared_error: 0.8645
Epoch 471/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6275 - root_mean_squared_error: 0.7719 - val_loss: 0.6694 - val_root_mean_squared_error: 0.7994
Epoch 472/500
5/5 [==============================] - 0s 23ms/step - loss: 0.6841 - root_mean_squared_error: 0.8108 - val_loss: 0.6547 - val_root_mean_squared_error: 0.7916
Epoch 473/500
5/5 [==============================] - 0s 24ms/step - loss: 0.7108 - root_mean_squared_error: 0.8267 - val_loss: 0.6940 - val_root_mean_squared_error: 0.8135
Epoch 474/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6627 - root_mean_squared_error: 0.7954 - val_loss: 0.6591 - val_root_mean_squared_error: 0.7945
Epoch 475/500
5/5 [==============================] - 0s 31ms/step - loss: 0.6496 - root_mean_squared_error: 0.7848 - val_loss: 0.6436 - val_root_mean_squared_error: 0.7843
Epoch 476/500
5/5 [==============================] - 0s 33ms/step - loss: 0.6738 - root_mean_squared_error: 0.8016 - val_loss: 0.6472 - val_root_mean_squared_error: 0.7824
Epoch 477/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6781 - root_mean_squared_error: 0.8060 - val_loss: 0.6922 - val_root_mean_squared_error: 0.8140
Epoch 478/500
5/5 [==============================] - 0s 34ms/step - loss: 0.6634 - root_mean_squared_error: 0.7958 - val_loss: 0.6477 - val_root_mean_squared_error: 0.7861
Epoch 479/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6181 - root_mean_squared_error: 0.7663 - val_loss: 0.7015 - val_root_mean_squared_error: 0.8178
Epoch 480/500
5/5 [==============================] - 0s 25ms/step - loss: 0.6387 - root_mean_squared_error: 0.7797 - val_loss: 0.6642 - val_root_mean_squared_error: 0.7960
Epoch 481/500
5/5 [==============================] - 0s 28ms/step - loss: 0.6731 - root_mean_squared_error: 0.8006 - val_loss: 0.6465 - val_root_mean_squared_error: 0.7866
Epoch 482/500
5/5 [==============================] - 0s 24ms/step - loss: 0.6953 - root_mean_squared_error: 0.8167 - val_loss: 0.6810 - val_root_mean_squared_error: 0.8085
Epoch 483/500
5/5 [==============================] - 0s 28ms/step - loss: 0.6973 - root_mean_squared_error: 0.8171 - val_loss: 0.6803 - val_root_mean_squared_error: 0.8062
Epoch 484/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6599 - root_mean_squared_error: 0.7926 - val_loss: 0.6491 - val_root_mean_squared_error: 0.7886
Epoch 485/500
5/5 [==============================] - 0s 36ms/step - loss: 0.6066 - root_mean_squared_error: 0.7589 - val_loss: 0.6704 - val_root_mean_squared_error: 0.8003
Epoch 486/500
5/5 [==============================] - 0s 27ms/step - loss: 0.6607 - root_mean_squared_error: 0.7945 - val_loss: 0.6868 - val_root_mean_squared_error: 0.8084
Epoch 487/500
5/5 [==============================] - 0s 27ms/step - loss: 0.7091 - root_mean_squared_error: 0.8241 - val_loss: 0.6499 - val_root_mean_squared_error: 0.7880
Epoch 488/500
5/5 [==============================] - 0s 29ms/step - loss: 0.6423 - root_mean_squared_error: 0.7832 - val_loss: 0.6354 - val_root_mean_squared_error: 0.7782
Epoch 489/500
5/5 [==============================] - 0s 33ms/step - loss: 0.6583 - root_mean_squared_error: 0.7931 - val_loss: 0.7145 - val_root_mean_squared_error: 0.8276
Epoch 490/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6543 - root_mean_squared_error: 0.7897 - val_loss: 0.6359 - val_root_mean_squared_error: 0.7789
Epoch 491/500
5/5 [==============================] - 0s 26ms/step - loss: 0.6942 - root_mean_squared_error: 0.8142 - val_loss: 0.6527 - val_root_mean_squared_error: 0.7860
Epoch 492/500
5/5 [==============================] - 0s 40ms/step - loss: 0.6750 - root_mean_squared_error: 0.8031 - val_loss: 0.6723 - val_root_mean_squared_error: 0.7996
Epoch 493/500
5/5 [==============================] - 0s 29ms/step - loss: 0.7202 - root_mean_squared_error: 0.8308 - val_loss: 0.6554 - val_root_mean_squared_error: 0.7918
Epoch 494/500
5/5 [==============================] - 0s 29ms/step - loss: 0.6516 - root_mean_squared_error: 0.7882 - val_loss: 0.6395 - val_root_mean_squared_error: 0.7806
Epoch 495/500
5/5 [==============================] - 0s 22ms/step - loss: 0.6662 - root_mean_squared_error: 0.7986 - val_loss: 0.6434 - val_root_mean_squared_error: 0.7848
Epoch 496/500
5/5 [==============================] - 0s 21ms/step - loss: 0.6491 - root_mean_squared_error: 0.7869 - val_loss: 0.6209 - val_root_mean_squared_error: 0.7689
Epoch 497/500
5/5 [==============================] - 0s 28ms/step - loss: 0.6237 - root_mean_squared_error: 0.7703 - val_loss: 0.6361 - val_root_mean_squared_error: 0.7785
Epoch 498/500
5/5 [==============================] - 0s 21ms/step - loss: 0.7349 - root_mean_squared_error: 0.8405 - val_loss: 0.6620 - val_root_mean_squared_error: 0.7930
Epoch 499/500
5/5 [==============================] - 0s 20ms/step - loss: 0.6763 - root_mean_squared_error: 0.8045 - val_loss: 0.6649 - val_root_mean_squared_error: 0.7963
Epoch 500/500
5/5 [==============================] - 0s 29ms/step - loss: 0.6496 - root_mean_squared_error: 0.7882 - val_loss: 0.6849 - val_root_mean_squared_error: 0.8107
Model training finished.
Train RMSE: 0.766
Evaluating model performance...
Test RMSE: 0.796
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_predictions</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="n">predicted</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">prediction_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">prediction_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">prediction_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">prediction_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Predictions mean: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">prediction_mean</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;min: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">prediction_min</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;max: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">prediction_max</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;range: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">prediction_range</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2"> - &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Actual: </span><span class="si">{</span><span class="n">targets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>


<span class="n">compute_predictions</span><span class="p">(</span><span class="n">bnn_model_small</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predictions mean: 5.3, min: 4.56, max: 5.88, range: 1.32 - Actual: 6.0
Predictions mean: 5.3, min: 4.01, max: 6.14, range: 2.13 - Actual: 4.0
Predictions mean: 6.26, min: 5.92, max: 6.5, range: 0.58 - Actual: 7.0
Predictions mean: 6.13, min: 5.73, max: 6.42, range: 0.69 - Actual: 6.0
Predictions mean: 5.49, min: 4.55, max: 6.04, range: 1.49 - Actual: 6.0
Predictions mean: 5.45, min: 4.51, max: 6.14, range: 1.63 - Actual: 5.0
Predictions mean: 5.88, min: 4.9, max: 6.29, range: 1.4 - Actual: 5.0
Predictions mean: 5.87, min: 5.1, max: 6.33, range: 1.24 - Actual: 4.0
Predictions mean: 6.35, min: 6.07, max: 6.52, range: 0.45 - Actual: 6.0
Predictions mean: 5.92, min: 5.38, max: 6.37, range: 1.0 - Actual: 5.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Full model</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">bnn_model_full</span> <span class="o">=</span> <span class="n">create_bnn_model</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span>
<span class="n">run_experiment</span><span class="p">(</span><span class="n">bnn_model_full</span><span class="p">,</span> <span class="n">mse_loss</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">)</span>

<span class="n">compute_predictions</span><span class="p">(</span><span class="n">bnn_model_full</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Start training the model...
Epoch 1/500
17/17 [==============================] - 3s 60ms/step - loss: 26.1045 - root_mean_squared_error: 5.1088 - val_loss: 24.1278 - val_root_mean_squared_error: 4.9116
Epoch 2/500
17/17 [==============================] - 0s 7ms/step - loss: 27.3876 - root_mean_squared_error: 5.2329 - val_loss: 22.7275 - val_root_mean_squared_error: 4.7670
Epoch 3/500
17/17 [==============================] - 0s 8ms/step - loss: 23.4801 - root_mean_squared_error: 4.8451 - val_loss: 22.3047 - val_root_mean_squared_error: 4.7223
Epoch 4/500
17/17 [==============================] - 0s 8ms/step - loss: 23.8513 - root_mean_squared_error: 4.8834 - val_loss: 21.1810 - val_root_mean_squared_error: 4.6018
Epoch 5/500
17/17 [==============================] - 0s 9ms/step - loss: 21.4764 - root_mean_squared_error: 4.6338 - val_loss: 22.7071 - val_root_mean_squared_error: 4.7646
Epoch 6/500
17/17 [==============================] - 0s 8ms/step - loss: 19.9827 - root_mean_squared_error: 4.4697 - val_loss: 20.3251 - val_root_mean_squared_error: 4.5079
Epoch 7/500
17/17 [==============================] - 0s 10ms/step - loss: 20.4355 - root_mean_squared_error: 4.5200 - val_loss: 21.1732 - val_root_mean_squared_error: 4.6009
Epoch 8/500
17/17 [==============================] - 0s 9ms/step - loss: 18.9875 - root_mean_squared_error: 4.3570 - val_loss: 17.2415 - val_root_mean_squared_error: 4.1517
Epoch 9/500
17/17 [==============================] - 0s 8ms/step - loss: 16.0802 - root_mean_squared_error: 4.0094 - val_loss: 14.5200 - val_root_mean_squared_error: 3.8098
Epoch 10/500
17/17 [==============================] - 0s 9ms/step - loss: 16.2383 - root_mean_squared_error: 4.0291 - val_loss: 13.7531 - val_root_mean_squared_error: 3.7078
Epoch 11/500
17/17 [==============================] - 0s 8ms/step - loss: 15.2897 - root_mean_squared_error: 3.9095 - val_loss: 16.0619 - val_root_mean_squared_error: 4.0071
Epoch 12/500
17/17 [==============================] - 0s 8ms/step - loss: 14.1970 - root_mean_squared_error: 3.7672 - val_loss: 10.3076 - val_root_mean_squared_error: 3.2096
Epoch 13/500
17/17 [==============================] - 0s 8ms/step - loss: 12.4938 - root_mean_squared_error: 3.5340 - val_loss: 12.7618 - val_root_mean_squared_error: 3.5717
Epoch 14/500
17/17 [==============================] - 0s 8ms/step - loss: 12.0126 - root_mean_squared_error: 3.4651 - val_loss: 10.1075 - val_root_mean_squared_error: 3.1785
Epoch 15/500
17/17 [==============================] - 0s 9ms/step - loss: 11.0005 - root_mean_squared_error: 3.3159 - val_loss: 12.6586 - val_root_mean_squared_error: 3.5571
Epoch 16/500
17/17 [==============================] - 0s 9ms/step - loss: 11.4587 - root_mean_squared_error: 3.3844 - val_loss: 12.8889 - val_root_mean_squared_error: 3.5894
Epoch 17/500
17/17 [==============================] - 0s 9ms/step - loss: 10.0531 - root_mean_squared_error: 3.1698 - val_loss: 7.8337 - val_root_mean_squared_error: 2.7977
Epoch 18/500
17/17 [==============================] - 0s 9ms/step - loss: 9.0964 - root_mean_squared_error: 3.0151 - val_loss: 7.9257 - val_root_mean_squared_error: 2.8143
Epoch 19/500
17/17 [==============================] - 0s 9ms/step - loss: 8.5176 - root_mean_squared_error: 2.9175 - val_loss: 8.0432 - val_root_mean_squared_error: 2.8351
Epoch 20/500
17/17 [==============================] - 0s 9ms/step - loss: 6.6643 - root_mean_squared_error: 2.5805 - val_loss: 5.4092 - val_root_mean_squared_error: 2.3244
Epoch 21/500
17/17 [==============================] - 0s 9ms/step - loss: 6.9157 - root_mean_squared_error: 2.6287 - val_loss: 5.0567 - val_root_mean_squared_error: 2.2473
Epoch 22/500
17/17 [==============================] - 0s 9ms/step - loss: 5.9227 - root_mean_squared_error: 2.4325 - val_loss: 4.3234 - val_root_mean_squared_error: 2.0778
Epoch 23/500
17/17 [==============================] - 0s 9ms/step - loss: 5.0921 - root_mean_squared_error: 2.2552 - val_loss: 3.6612 - val_root_mean_squared_error: 1.9119
Epoch 24/500
17/17 [==============================] - 0s 13ms/step - loss: 4.3245 - root_mean_squared_error: 2.0781 - val_loss: 3.5749 - val_root_mean_squared_error: 1.8890
Epoch 25/500
17/17 [==============================] - 0s 8ms/step - loss: 4.1621 - root_mean_squared_error: 2.0386 - val_loss: 3.6738 - val_root_mean_squared_error: 1.9148
Epoch 26/500
17/17 [==============================] - 0s 9ms/step - loss: 3.3965 - root_mean_squared_error: 1.8413 - val_loss: 3.8403 - val_root_mean_squared_error: 1.9582
Epoch 27/500
17/17 [==============================] - 0s 9ms/step - loss: 3.3147 - root_mean_squared_error: 1.8188 - val_loss: 2.8135 - val_root_mean_squared_error: 1.6754
Epoch 28/500
17/17 [==============================] - 0s 9ms/step - loss: 2.7146 - root_mean_squared_error: 1.6457 - val_loss: 1.9901 - val_root_mean_squared_error: 1.4082
Epoch 29/500
17/17 [==============================] - 0s 9ms/step - loss: 2.6555 - root_mean_squared_error: 1.6276 - val_loss: 2.1845 - val_root_mean_squared_error: 1.4756
Epoch 30/500
17/17 [==============================] - 0s 9ms/step - loss: 2.1331 - root_mean_squared_error: 1.4582 - val_loss: 1.2866 - val_root_mean_squared_error: 1.1304
Epoch 31/500
17/17 [==============================] - 0s 9ms/step - loss: 1.6829 - root_mean_squared_error: 1.2945 - val_loss: 1.2367 - val_root_mean_squared_error: 1.1088
Epoch 32/500
17/17 [==============================] - 0s 9ms/step - loss: 1.4219 - root_mean_squared_error: 1.1894 - val_loss: 1.5527 - val_root_mean_squared_error: 1.2436
Epoch 33/500
17/17 [==============================] - 0s 11ms/step - loss: 1.2929 - root_mean_squared_error: 1.1339 - val_loss: 1.3156 - val_root_mean_squared_error: 1.1438
Epoch 34/500
17/17 [==============================] - 0s 11ms/step - loss: 1.2858 - root_mean_squared_error: 1.1308 - val_loss: 1.0681 - val_root_mean_squared_error: 1.0301
Epoch 35/500
17/17 [==============================] - 0s 10ms/step - loss: 0.9756 - root_mean_squared_error: 0.9839 - val_loss: 0.9370 - val_root_mean_squared_error: 0.9633
Epoch 36/500
17/17 [==============================] - 0s 9ms/step - loss: 0.9062 - root_mean_squared_error: 0.9481 - val_loss: 0.7948 - val_root_mean_squared_error: 0.8870
Epoch 37/500
17/17 [==============================] - 0s 9ms/step - loss: 0.9105 - root_mean_squared_error: 0.9505 - val_loss: 0.8982 - val_root_mean_squared_error: 0.9444
Epoch 38/500
17/17 [==============================] - 0s 9ms/step - loss: 1.0041 - root_mean_squared_error: 0.9985 - val_loss: 0.8483 - val_root_mean_squared_error: 0.9164
Epoch 39/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7854 - root_mean_squared_error: 0.8818 - val_loss: 0.8715 - val_root_mean_squared_error: 0.9298
Epoch 40/500
17/17 [==============================] - 0s 9ms/step - loss: 0.8049 - root_mean_squared_error: 0.8929 - val_loss: 0.9253 - val_root_mean_squared_error: 0.9587
Epoch 41/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7756 - root_mean_squared_error: 0.8763 - val_loss: 0.7418 - val_root_mean_squared_error: 0.8566
Epoch 42/500
17/17 [==============================] - 0s 9ms/step - loss: 0.8062 - root_mean_squared_error: 0.8938 - val_loss: 0.7800 - val_root_mean_squared_error: 0.8786
Epoch 43/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7621 - root_mean_squared_error: 0.8682 - val_loss: 0.7174 - val_root_mean_squared_error: 0.8421
Epoch 44/500
17/17 [==============================] - 0s 11ms/step - loss: 0.7885 - root_mean_squared_error: 0.8830 - val_loss: 0.7450 - val_root_mean_squared_error: 0.8581
Epoch 45/500
17/17 [==============================] - 0s 10ms/step - loss: 0.7848 - root_mean_squared_error: 0.8814 - val_loss: 0.7725 - val_root_mean_squared_error: 0.8743
Epoch 46/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7859 - root_mean_squared_error: 0.8818 - val_loss: 0.7312 - val_root_mean_squared_error: 0.8502
Epoch 47/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7695 - root_mean_squared_error: 0.8727 - val_loss: 0.7551 - val_root_mean_squared_error: 0.8646
Epoch 48/500
17/17 [==============================] - 0s 12ms/step - loss: 0.7787 - root_mean_squared_error: 0.8779 - val_loss: 0.7764 - val_root_mean_squared_error: 0.8765
Epoch 49/500
17/17 [==============================] - 0s 12ms/step - loss: 0.7715 - root_mean_squared_error: 0.8738 - val_loss: 0.8435 - val_root_mean_squared_error: 0.9147
Epoch 50/500
17/17 [==============================] - 0s 13ms/step - loss: 0.7482 - root_mean_squared_error: 0.8601 - val_loss: 0.7519 - val_root_mean_squared_error: 0.8627
Epoch 51/500
17/17 [==============================] - 0s 11ms/step - loss: 0.7463 - root_mean_squared_error: 0.8591 - val_loss: 0.8042 - val_root_mean_squared_error: 0.8932
Epoch 52/500
17/17 [==============================] - 0s 12ms/step - loss: 0.7856 - root_mean_squared_error: 0.8816 - val_loss: 0.7450 - val_root_mean_squared_error: 0.8588
Epoch 53/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7603 - root_mean_squared_error: 0.8672 - val_loss: 0.7603 - val_root_mean_squared_error: 0.8671
Epoch 54/500
17/17 [==============================] - 0s 10ms/step - loss: 0.7379 - root_mean_squared_error: 0.8539 - val_loss: 0.7098 - val_root_mean_squared_error: 0.8379
Epoch 55/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7485 - root_mean_squared_error: 0.8604 - val_loss: 0.7674 - val_root_mean_squared_error: 0.8709
Epoch 56/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7455 - root_mean_squared_error: 0.8583 - val_loss: 0.7063 - val_root_mean_squared_error: 0.8354
Epoch 57/500
17/17 [==============================] - 0s 14ms/step - loss: 0.7334 - root_mean_squared_error: 0.8513 - val_loss: 0.7119 - val_root_mean_squared_error: 0.8384
Epoch 58/500
17/17 [==============================] - 0s 12ms/step - loss: 0.7406 - root_mean_squared_error: 0.8557 - val_loss: 0.7365 - val_root_mean_squared_error: 0.8527
Epoch 59/500
17/17 [==============================] - 0s 10ms/step - loss: 0.7428 - root_mean_squared_error: 0.8566 - val_loss: 0.7496 - val_root_mean_squared_error: 0.8609
Epoch 60/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7251 - root_mean_squared_error: 0.8461 - val_loss: 0.7620 - val_root_mean_squared_error: 0.8687
Epoch 61/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7191 - root_mean_squared_error: 0.8425 - val_loss: 0.7354 - val_root_mean_squared_error: 0.8529
Epoch 62/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7275 - root_mean_squared_error: 0.8476 - val_loss: 0.6941 - val_root_mean_squared_error: 0.8275
Epoch 63/500
17/17 [==============================] - 0s 10ms/step - loss: 0.7260 - root_mean_squared_error: 0.8468 - val_loss: 0.7881 - val_root_mean_squared_error: 0.8826
Epoch 64/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7362 - root_mean_squared_error: 0.8526 - val_loss: 0.7055 - val_root_mean_squared_error: 0.8349
Epoch 65/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7107 - root_mean_squared_error: 0.8377 - val_loss: 0.6827 - val_root_mean_squared_error: 0.8205
Epoch 66/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7178 - root_mean_squared_error: 0.8419 - val_loss: 0.6658 - val_root_mean_squared_error: 0.8100
Epoch 67/500
17/17 [==============================] - 0s 11ms/step - loss: 0.7248 - root_mean_squared_error: 0.8460 - val_loss: 0.7125 - val_root_mean_squared_error: 0.8392
Epoch 68/500
17/17 [==============================] - 0s 11ms/step - loss: 0.7050 - root_mean_squared_error: 0.8342 - val_loss: 0.6697 - val_root_mean_squared_error: 0.8123
Epoch 69/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7109 - root_mean_squared_error: 0.8377 - val_loss: 0.7523 - val_root_mean_squared_error: 0.8623
Epoch 70/500
17/17 [==============================] - 0s 11ms/step - loss: 0.7020 - root_mean_squared_error: 0.8323 - val_loss: 0.6562 - val_root_mean_squared_error: 0.8045
Epoch 71/500
17/17 [==============================] - 0s 11ms/step - loss: 0.7346 - root_mean_squared_error: 0.8518 - val_loss: 0.7049 - val_root_mean_squared_error: 0.8332
Epoch 72/500
17/17 [==============================] - 0s 8ms/step - loss: 0.7052 - root_mean_squared_error: 0.8342 - val_loss: 0.7858 - val_root_mean_squared_error: 0.8812
Epoch 73/500
17/17 [==============================] - 0s 9ms/step - loss: 0.7179 - root_mean_squared_error: 0.8420 - val_loss: 0.7264 - val_root_mean_squared_error: 0.8476
Epoch 74/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6909 - root_mean_squared_error: 0.8253 - val_loss: 0.7201 - val_root_mean_squared_error: 0.8426
Epoch 75/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6810 - root_mean_squared_error: 0.8199 - val_loss: 0.6840 - val_root_mean_squared_error: 0.8210
Epoch 76/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6872 - root_mean_squared_error: 0.8234 - val_loss: 0.7006 - val_root_mean_squared_error: 0.8309
Epoch 77/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6796 - root_mean_squared_error: 0.8186 - val_loss: 0.6862 - val_root_mean_squared_error: 0.8221
Epoch 78/500
17/17 [==============================] - 0s 11ms/step - loss: 0.6852 - root_mean_squared_error: 0.8222 - val_loss: 0.6787 - val_root_mean_squared_error: 0.8176
Epoch 79/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6933 - root_mean_squared_error: 0.8270 - val_loss: 0.7175 - val_root_mean_squared_error: 0.8411
Epoch 80/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6751 - root_mean_squared_error: 0.8156 - val_loss: 0.6665 - val_root_mean_squared_error: 0.8111
Epoch 81/500
17/17 [==============================] - 0s 12ms/step - loss: 0.6956 - root_mean_squared_error: 0.8280 - val_loss: 0.7011 - val_root_mean_squared_error: 0.8318
Epoch 82/500
17/17 [==============================] - 0s 12ms/step - loss: 0.6940 - root_mean_squared_error: 0.8273 - val_loss: 0.7209 - val_root_mean_squared_error: 0.8435
Epoch 83/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6948 - root_mean_squared_error: 0.8277 - val_loss: 0.6605 - val_root_mean_squared_error: 0.8066
Epoch 84/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6922 - root_mean_squared_error: 0.8262 - val_loss: 0.6833 - val_root_mean_squared_error: 0.8216
Epoch 85/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6628 - root_mean_squared_error: 0.8080 - val_loss: 0.7402 - val_root_mean_squared_error: 0.8548
Epoch 86/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6762 - root_mean_squared_error: 0.8165 - val_loss: 0.6697 - val_root_mean_squared_error: 0.8124
Epoch 87/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6980 - root_mean_squared_error: 0.8297 - val_loss: 0.6617 - val_root_mean_squared_error: 0.8074
Epoch 88/500
17/17 [==============================] - 0s 5ms/step - loss: 0.7043 - root_mean_squared_error: 0.8333 - val_loss: 0.6514 - val_root_mean_squared_error: 0.8010
Epoch 89/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6952 - root_mean_squared_error: 0.8280 - val_loss: 0.6824 - val_root_mean_squared_error: 0.8201
Epoch 90/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6823 - root_mean_squared_error: 0.8206 - val_loss: 0.6490 - val_root_mean_squared_error: 0.7987
Epoch 91/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6692 - root_mean_squared_error: 0.8121 - val_loss: 0.6428 - val_root_mean_squared_error: 0.7957
Epoch 92/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6701 - root_mean_squared_error: 0.8123 - val_loss: 0.6801 - val_root_mean_squared_error: 0.8188
Epoch 93/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6626 - root_mean_squared_error: 0.8077 - val_loss: 0.6405 - val_root_mean_squared_error: 0.7935
Epoch 94/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6663 - root_mean_squared_error: 0.8100 - val_loss: 0.6978 - val_root_mean_squared_error: 0.8297
Epoch 95/500
17/17 [==============================] - 0s 12ms/step - loss: 0.6708 - root_mean_squared_error: 0.8126 - val_loss: 0.6397 - val_root_mean_squared_error: 0.7936
Epoch 96/500
17/17 [==============================] - 0s 13ms/step - loss: 0.6567 - root_mean_squared_error: 0.8039 - val_loss: 0.6628 - val_root_mean_squared_error: 0.8080
Epoch 97/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6532 - root_mean_squared_error: 0.8016 - val_loss: 0.6762 - val_root_mean_squared_error: 0.8166
Epoch 98/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6880 - root_mean_squared_error: 0.8239 - val_loss: 0.6471 - val_root_mean_squared_error: 0.7978
Epoch 99/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6586 - root_mean_squared_error: 0.8054 - val_loss: 0.7161 - val_root_mean_squared_error: 0.8403
Epoch 100/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6837 - root_mean_squared_error: 0.8206 - val_loss: 0.6824 - val_root_mean_squared_error: 0.8197
Epoch 101/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6460 - root_mean_squared_error: 0.7975 - val_loss: 0.6335 - val_root_mean_squared_error: 0.7891
Epoch 102/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6692 - root_mean_squared_error: 0.8120 - val_loss: 0.6274 - val_root_mean_squared_error: 0.7851
Epoch 103/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6552 - root_mean_squared_error: 0.8031 - val_loss: 0.6381 - val_root_mean_squared_error: 0.7923
Epoch 104/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6607 - root_mean_squared_error: 0.8070 - val_loss: 0.6889 - val_root_mean_squared_error: 0.8246
Epoch 105/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6567 - root_mean_squared_error: 0.8040 - val_loss: 0.6833 - val_root_mean_squared_error: 0.8201
Epoch 106/500
17/17 [==============================] - 0s 11ms/step - loss: 0.6481 - root_mean_squared_error: 0.7984 - val_loss: 0.6702 - val_root_mean_squared_error: 0.8116
Epoch 107/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6780 - root_mean_squared_error: 0.8171 - val_loss: 0.6297 - val_root_mean_squared_error: 0.7876
Epoch 108/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6553 - root_mean_squared_error: 0.8028 - val_loss: 0.6755 - val_root_mean_squared_error: 0.8155
Epoch 109/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6372 - root_mean_squared_error: 0.7914 - val_loss: 0.6349 - val_root_mean_squared_error: 0.7904
Epoch 110/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6427 - root_mean_squared_error: 0.7950 - val_loss: 0.6856 - val_root_mean_squared_error: 0.8215
Epoch 111/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6614 - root_mean_squared_error: 0.8070 - val_loss: 0.6391 - val_root_mean_squared_error: 0.7933
Epoch 112/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6614 - root_mean_squared_error: 0.8072 - val_loss: 0.6548 - val_root_mean_squared_error: 0.8029
Epoch 113/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6481 - root_mean_squared_error: 0.7978 - val_loss: 0.6758 - val_root_mean_squared_error: 0.8156
Epoch 114/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6536 - root_mean_squared_error: 0.8021 - val_loss: 0.6419 - val_root_mean_squared_error: 0.7952
Epoch 115/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6489 - root_mean_squared_error: 0.7988 - val_loss: 0.6677 - val_root_mean_squared_error: 0.8103
Epoch 116/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6637 - root_mean_squared_error: 0.8080 - val_loss: 0.6369 - val_root_mean_squared_error: 0.7910
Epoch 117/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6396 - root_mean_squared_error: 0.7932 - val_loss: 0.6447 - val_root_mean_squared_error: 0.7965
Epoch 118/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6419 - root_mean_squared_error: 0.7940 - val_loss: 0.6371 - val_root_mean_squared_error: 0.7923
Epoch 119/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6356 - root_mean_squared_error: 0.7904 - val_loss: 0.6366 - val_root_mean_squared_error: 0.7907
Epoch 120/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6624 - root_mean_squared_error: 0.8075 - val_loss: 0.6843 - val_root_mean_squared_error: 0.8204
Epoch 121/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6537 - root_mean_squared_error: 0.8018 - val_loss: 0.6709 - val_root_mean_squared_error: 0.8120
Epoch 122/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6464 - root_mean_squared_error: 0.7974 - val_loss: 0.6320 - val_root_mean_squared_error: 0.7883
Epoch 123/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6378 - root_mean_squared_error: 0.7921 - val_loss: 0.6207 - val_root_mean_squared_error: 0.7801
Epoch 124/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6438 - root_mean_squared_error: 0.7954 - val_loss: 0.6608 - val_root_mean_squared_error: 0.8069
Epoch 125/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6344 - root_mean_squared_error: 0.7899 - val_loss: 0.6445 - val_root_mean_squared_error: 0.7958
Epoch 126/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6453 - root_mean_squared_error: 0.7968 - val_loss: 0.6118 - val_root_mean_squared_error: 0.7756
Epoch 127/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6493 - root_mean_squared_error: 0.7987 - val_loss: 0.6130 - val_root_mean_squared_error: 0.7760
Epoch 128/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6344 - root_mean_squared_error: 0.7897 - val_loss: 0.6102 - val_root_mean_squared_error: 0.7735
Epoch 129/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6559 - root_mean_squared_error: 0.8030 - val_loss: 0.6365 - val_root_mean_squared_error: 0.7913
Epoch 130/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6423 - root_mean_squared_error: 0.7947 - val_loss: 0.6412 - val_root_mean_squared_error: 0.7942
Epoch 131/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6524 - root_mean_squared_error: 0.8013 - val_loss: 0.6457 - val_root_mean_squared_error: 0.7970
Epoch 132/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6504 - root_mean_squared_error: 0.7997 - val_loss: 0.6323 - val_root_mean_squared_error: 0.7884
Epoch 133/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6428 - root_mean_squared_error: 0.7953 - val_loss: 0.6564 - val_root_mean_squared_error: 0.8040
Epoch 134/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6426 - root_mean_squared_error: 0.7948 - val_loss: 0.6253 - val_root_mean_squared_error: 0.7837
Epoch 135/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6470 - root_mean_squared_error: 0.7976 - val_loss: 0.6278 - val_root_mean_squared_error: 0.7842
Epoch 136/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6561 - root_mean_squared_error: 0.8028 - val_loss: 0.6305 - val_root_mean_squared_error: 0.7871
Epoch 137/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6351 - root_mean_squared_error: 0.7900 - val_loss: 0.6504 - val_root_mean_squared_error: 0.8000
Epoch 138/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6462 - root_mean_squared_error: 0.7966 - val_loss: 0.6132 - val_root_mean_squared_error: 0.7757
Epoch 139/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6320 - root_mean_squared_error: 0.7879 - val_loss: 0.6299 - val_root_mean_squared_error: 0.7867
Epoch 140/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6392 - root_mean_squared_error: 0.7924 - val_loss: 0.6171 - val_root_mean_squared_error: 0.7774
Epoch 141/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6358 - root_mean_squared_error: 0.7903 - val_loss: 0.6404 - val_root_mean_squared_error: 0.7934
Epoch 142/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6334 - root_mean_squared_error: 0.7887 - val_loss: 0.6147 - val_root_mean_squared_error: 0.7768
Epoch 143/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6310 - root_mean_squared_error: 0.7874 - val_loss: 0.6229 - val_root_mean_squared_error: 0.7825
Epoch 144/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6185 - root_mean_squared_error: 0.7791 - val_loss: 0.6397 - val_root_mean_squared_error: 0.7930
Epoch 145/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6072 - root_mean_squared_error: 0.7716 - val_loss: 0.6812 - val_root_mean_squared_error: 0.8182
Epoch 146/500
17/17 [==============================] - 0s 4ms/step - loss: 0.6382 - root_mean_squared_error: 0.7922 - val_loss: 0.6512 - val_root_mean_squared_error: 0.8001
Epoch 147/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6380 - root_mean_squared_error: 0.7919 - val_loss: 0.6231 - val_root_mean_squared_error: 0.7834
Epoch 148/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6400 - root_mean_squared_error: 0.7928 - val_loss: 0.6528 - val_root_mean_squared_error: 0.8009
Epoch 149/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6354 - root_mean_squared_error: 0.7902 - val_loss: 0.6462 - val_root_mean_squared_error: 0.7979
Epoch 150/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6385 - root_mean_squared_error: 0.7920 - val_loss: 0.6338 - val_root_mean_squared_error: 0.7891
Epoch 151/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6180 - root_mean_squared_error: 0.7788 - val_loss: 0.6311 - val_root_mean_squared_error: 0.7872
Epoch 152/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6365 - root_mean_squared_error: 0.7908 - val_loss: 0.6188 - val_root_mean_squared_error: 0.7785
Epoch 153/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6158 - root_mean_squared_error: 0.7772 - val_loss: 0.6222 - val_root_mean_squared_error: 0.7812
Epoch 154/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6279 - root_mean_squared_error: 0.7850 - val_loss: 0.6563 - val_root_mean_squared_error: 0.8033
Epoch 155/500
17/17 [==============================] - 0s 4ms/step - loss: 0.6471 - root_mean_squared_error: 0.7976 - val_loss: 0.6399 - val_root_mean_squared_error: 0.7928
Epoch 156/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6322 - root_mean_squared_error: 0.7881 - val_loss: 0.6322 - val_root_mean_squared_error: 0.7879
Epoch 157/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6296 - root_mean_squared_error: 0.7859 - val_loss: 0.6052 - val_root_mean_squared_error: 0.7699
Epoch 158/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6335 - root_mean_squared_error: 0.7889 - val_loss: 0.6308 - val_root_mean_squared_error: 0.7870
Epoch 159/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6207 - root_mean_squared_error: 0.7804 - val_loss: 0.6275 - val_root_mean_squared_error: 0.7840
Epoch 160/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6214 - root_mean_squared_error: 0.7812 - val_loss: 0.6900 - val_root_mean_squared_error: 0.8245
Epoch 161/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6300 - root_mean_squared_error: 0.7865 - val_loss: 0.6655 - val_root_mean_squared_error: 0.8093
Epoch 162/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6310 - root_mean_squared_error: 0.7872 - val_loss: 0.6224 - val_root_mean_squared_error: 0.7815
Epoch 163/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6129 - root_mean_squared_error: 0.7755 - val_loss: 0.6159 - val_root_mean_squared_error: 0.7768
Epoch 164/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6341 - root_mean_squared_error: 0.7891 - val_loss: 0.5941 - val_root_mean_squared_error: 0.7632
Epoch 165/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6500 - root_mean_squared_error: 0.7991 - val_loss: 0.6550 - val_root_mean_squared_error: 0.8027
Epoch 166/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6311 - root_mean_squared_error: 0.7874 - val_loss: 0.6070 - val_root_mean_squared_error: 0.7714
Epoch 167/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6428 - root_mean_squared_error: 0.7946 - val_loss: 0.6349 - val_root_mean_squared_error: 0.7896
Epoch 168/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6237 - root_mean_squared_error: 0.7826 - val_loss: 0.6084 - val_root_mean_squared_error: 0.7723
Epoch 169/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6214 - root_mean_squared_error: 0.7808 - val_loss: 0.6416 - val_root_mean_squared_error: 0.7938
Epoch 170/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6256 - root_mean_squared_error: 0.7841 - val_loss: 0.6982 - val_root_mean_squared_error: 0.8289
Epoch 171/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6223 - root_mean_squared_error: 0.7817 - val_loss: 0.6283 - val_root_mean_squared_error: 0.7858
Epoch 172/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6289 - root_mean_squared_error: 0.7858 - val_loss: 0.6356 - val_root_mean_squared_error: 0.7903
Epoch 173/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6284 - root_mean_squared_error: 0.7857 - val_loss: 0.6435 - val_root_mean_squared_error: 0.7953
Epoch 174/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6196 - root_mean_squared_error: 0.7798 - val_loss: 0.6025 - val_root_mean_squared_error: 0.7694
Epoch 175/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6269 - root_mean_squared_error: 0.7849 - val_loss: 0.6034 - val_root_mean_squared_error: 0.7699
Epoch 176/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6199 - root_mean_squared_error: 0.7802 - val_loss: 0.6293 - val_root_mean_squared_error: 0.7863
Epoch 177/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6417 - root_mean_squared_error: 0.7939 - val_loss: 0.6002 - val_root_mean_squared_error: 0.7666
Epoch 178/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6340 - root_mean_squared_error: 0.7891 - val_loss: 0.6071 - val_root_mean_squared_error: 0.7725
Epoch 179/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6308 - root_mean_squared_error: 0.7869 - val_loss: 0.6098 - val_root_mean_squared_error: 0.7733
Epoch 180/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6260 - root_mean_squared_error: 0.7835 - val_loss: 0.6199 - val_root_mean_squared_error: 0.7799
Epoch 181/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6184 - root_mean_squared_error: 0.7793 - val_loss: 0.6101 - val_root_mean_squared_error: 0.7733
Epoch 182/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6362 - root_mean_squared_error: 0.7905 - val_loss: 0.6278 - val_root_mean_squared_error: 0.7846
Epoch 183/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6372 - root_mean_squared_error: 0.7909 - val_loss: 0.6122 - val_root_mean_squared_error: 0.7757
Epoch 184/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6298 - root_mean_squared_error: 0.7866 - val_loss: 0.6193 - val_root_mean_squared_error: 0.7793
Epoch 185/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6300 - root_mean_squared_error: 0.7868 - val_loss: 0.6066 - val_root_mean_squared_error: 0.7718
Epoch 186/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6204 - root_mean_squared_error: 0.7801 - val_loss: 0.6468 - val_root_mean_squared_error: 0.7966
Epoch 187/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6151 - root_mean_squared_error: 0.7767 - val_loss: 0.6170 - val_root_mean_squared_error: 0.7787
Epoch 188/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6393 - root_mean_squared_error: 0.7922 - val_loss: 0.6184 - val_root_mean_squared_error: 0.7790
Epoch 189/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6209 - root_mean_squared_error: 0.7810 - val_loss: 0.6155 - val_root_mean_squared_error: 0.7767
Epoch 190/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6343 - root_mean_squared_error: 0.7889 - val_loss: 0.6154 - val_root_mean_squared_error: 0.7767
Epoch 191/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6216 - root_mean_squared_error: 0.7810 - val_loss: 0.6532 - val_root_mean_squared_error: 0.8006
Epoch 192/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6190 - root_mean_squared_error: 0.7791 - val_loss: 0.6098 - val_root_mean_squared_error: 0.7727
Epoch 193/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6186 - root_mean_squared_error: 0.7791 - val_loss: 0.6045 - val_root_mean_squared_error: 0.7697
Epoch 194/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6213 - root_mean_squared_error: 0.7810 - val_loss: 0.6147 - val_root_mean_squared_error: 0.7764
Epoch 195/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6216 - root_mean_squared_error: 0.7812 - val_loss: 0.6135 - val_root_mean_squared_error: 0.7755
Epoch 196/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6256 - root_mean_squared_error: 0.7833 - val_loss: 0.6487 - val_root_mean_squared_error: 0.7978
Epoch 197/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6299 - root_mean_squared_error: 0.7864 - val_loss: 0.6322 - val_root_mean_squared_error: 0.7874
Epoch 198/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6222 - root_mean_squared_error: 0.7811 - val_loss: 0.6215 - val_root_mean_squared_error: 0.7807
Epoch 199/500
17/17 [==============================] - 0s 4ms/step - loss: 0.6126 - root_mean_squared_error: 0.7752 - val_loss: 0.6101 - val_root_mean_squared_error: 0.7735
Epoch 200/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6227 - root_mean_squared_error: 0.7818 - val_loss: 0.7353 - val_root_mean_squared_error: 0.8502
Epoch 201/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6212 - root_mean_squared_error: 0.7807 - val_loss: 0.6247 - val_root_mean_squared_error: 0.7831
Epoch 202/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6169 - root_mean_squared_error: 0.7776 - val_loss: 0.5934 - val_root_mean_squared_error: 0.7628
Epoch 203/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6207 - root_mean_squared_error: 0.7801 - val_loss: 0.6378 - val_root_mean_squared_error: 0.7911
Epoch 204/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6153 - root_mean_squared_error: 0.7769 - val_loss: 0.6078 - val_root_mean_squared_error: 0.7718
Epoch 205/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6187 - root_mean_squared_error: 0.7791 - val_loss: 0.6378 - val_root_mean_squared_error: 0.7915
Epoch 206/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6247 - root_mean_squared_error: 0.7828 - val_loss: 0.5904 - val_root_mean_squared_error: 0.7600
Epoch 207/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6101 - root_mean_squared_error: 0.7735 - val_loss: 0.6168 - val_root_mean_squared_error: 0.7776
Epoch 208/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6116 - root_mean_squared_error: 0.7745 - val_loss: 0.6264 - val_root_mean_squared_error: 0.7838
Epoch 209/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6373 - root_mean_squared_error: 0.7911 - val_loss: 0.6316 - val_root_mean_squared_error: 0.7881
Epoch 210/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6197 - root_mean_squared_error: 0.7799 - val_loss: 0.6086 - val_root_mean_squared_error: 0.7728
Epoch 211/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6246 - root_mean_squared_error: 0.7829 - val_loss: 0.6305 - val_root_mean_squared_error: 0.7862
Epoch 212/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6198 - root_mean_squared_error: 0.7799 - val_loss: 0.5972 - val_root_mean_squared_error: 0.7660
Epoch 213/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6253 - root_mean_squared_error: 0.7832 - val_loss: 0.6295 - val_root_mean_squared_error: 0.7863
Epoch 214/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6248 - root_mean_squared_error: 0.7828 - val_loss: 0.6046 - val_root_mean_squared_error: 0.7697
Epoch 215/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6279 - root_mean_squared_error: 0.7850 - val_loss: 0.6312 - val_root_mean_squared_error: 0.7873
Epoch 216/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6199 - root_mean_squared_error: 0.7798 - val_loss: 0.6221 - val_root_mean_squared_error: 0.7804
Epoch 217/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6253 - root_mean_squared_error: 0.7835 - val_loss: 0.6391 - val_root_mean_squared_error: 0.7924
Epoch 218/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6177 - root_mean_squared_error: 0.7781 - val_loss: 0.6322 - val_root_mean_squared_error: 0.7874
Epoch 219/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6105 - root_mean_squared_error: 0.7735 - val_loss: 0.6212 - val_root_mean_squared_error: 0.7804
Epoch 220/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6061 - root_mean_squared_error: 0.7705 - val_loss: 0.6046 - val_root_mean_squared_error: 0.7700
Epoch 221/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6168 - root_mean_squared_error: 0.7777 - val_loss: 0.5958 - val_root_mean_squared_error: 0.7633
Epoch 222/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6289 - root_mean_squared_error: 0.7856 - val_loss: 0.6241 - val_root_mean_squared_error: 0.7831
Epoch 223/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6157 - root_mean_squared_error: 0.7770 - val_loss: 0.6108 - val_root_mean_squared_error: 0.7733
Epoch 224/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6105 - root_mean_squared_error: 0.7736 - val_loss: 0.6074 - val_root_mean_squared_error: 0.7724
Epoch 225/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6131 - root_mean_squared_error: 0.7750 - val_loss: 0.6112 - val_root_mean_squared_error: 0.7746
Epoch 226/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6076 - root_mean_squared_error: 0.7717 - val_loss: 0.6250 - val_root_mean_squared_error: 0.7822
Epoch 227/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6125 - root_mean_squared_error: 0.7749 - val_loss: 0.6374 - val_root_mean_squared_error: 0.7910
Epoch 228/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6077 - root_mean_squared_error: 0.7718 - val_loss: 0.5987 - val_root_mean_squared_error: 0.7666
Epoch 229/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6205 - root_mean_squared_error: 0.7800 - val_loss: 0.6277 - val_root_mean_squared_error: 0.7837
Epoch 230/500
17/17 [==============================] - 0s 4ms/step - loss: 0.6213 - root_mean_squared_error: 0.7808 - val_loss: 0.6223 - val_root_mean_squared_error: 0.7819
Epoch 231/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6173 - root_mean_squared_error: 0.7782 - val_loss: 0.6002 - val_root_mean_squared_error: 0.7674
Epoch 232/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6235 - root_mean_squared_error: 0.7822 - val_loss: 0.6151 - val_root_mean_squared_error: 0.7770
Epoch 233/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6209 - root_mean_squared_error: 0.7804 - val_loss: 0.5996 - val_root_mean_squared_error: 0.7653
Epoch 234/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6081 - root_mean_squared_error: 0.7722 - val_loss: 0.6127 - val_root_mean_squared_error: 0.7747
Epoch 235/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6120 - root_mean_squared_error: 0.7745 - val_loss: 0.6042 - val_root_mean_squared_error: 0.7706
Epoch 236/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6153 - root_mean_squared_error: 0.7766 - val_loss: 0.6254 - val_root_mean_squared_error: 0.7840
Epoch 237/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6165 - root_mean_squared_error: 0.7772 - val_loss: 0.6341 - val_root_mean_squared_error: 0.7886
Epoch 238/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6213 - root_mean_squared_error: 0.7808 - val_loss: 0.6306 - val_root_mean_squared_error: 0.7866
Epoch 239/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6170 - root_mean_squared_error: 0.7782 - val_loss: 0.6409 - val_root_mean_squared_error: 0.7934
Epoch 240/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6135 - root_mean_squared_error: 0.7751 - val_loss: 0.5996 - val_root_mean_squared_error: 0.7664
Epoch 241/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6036 - root_mean_squared_error: 0.7692 - val_loss: 0.6098 - val_root_mean_squared_error: 0.7742
Epoch 242/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6247 - root_mean_squared_error: 0.7826 - val_loss: 0.6062 - val_root_mean_squared_error: 0.7711
Epoch 243/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6257 - root_mean_squared_error: 0.7833 - val_loss: 0.5799 - val_root_mean_squared_error: 0.7543
Epoch 244/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6157 - root_mean_squared_error: 0.7767 - val_loss: 0.5978 - val_root_mean_squared_error: 0.7652
Epoch 245/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6229 - root_mean_squared_error: 0.7814 - val_loss: 0.6206 - val_root_mean_squared_error: 0.7795
Epoch 246/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6213 - root_mean_squared_error: 0.7806 - val_loss: 0.6424 - val_root_mean_squared_error: 0.7939
Epoch 247/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6154 - root_mean_squared_error: 0.7762 - val_loss: 0.6134 - val_root_mean_squared_error: 0.7756
Epoch 248/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6047 - root_mean_squared_error: 0.7695 - val_loss: 0.6033 - val_root_mean_squared_error: 0.7682
Epoch 249/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6080 - root_mean_squared_error: 0.7724 - val_loss: 0.6033 - val_root_mean_squared_error: 0.7688
Epoch 250/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6105 - root_mean_squared_error: 0.7737 - val_loss: 0.6075 - val_root_mean_squared_error: 0.7715
Epoch 251/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6276 - root_mean_squared_error: 0.7842 - val_loss: 0.6114 - val_root_mean_squared_error: 0.7748
Epoch 252/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6194 - root_mean_squared_error: 0.7796 - val_loss: 0.6195 - val_root_mean_squared_error: 0.7798
Epoch 253/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6139 - root_mean_squared_error: 0.7754 - val_loss: 0.6186 - val_root_mean_squared_error: 0.7795
Epoch 254/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6096 - root_mean_squared_error: 0.7731 - val_loss: 0.5914 - val_root_mean_squared_error: 0.7611
Epoch 255/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6068 - root_mean_squared_error: 0.7707 - val_loss: 0.6063 - val_root_mean_squared_error: 0.7713
Epoch 256/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6165 - root_mean_squared_error: 0.7772 - val_loss: 0.5930 - val_root_mean_squared_error: 0.7618
Epoch 257/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6368 - root_mean_squared_error: 0.7902 - val_loss: 0.5962 - val_root_mean_squared_error: 0.7638
Epoch 258/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6232 - root_mean_squared_error: 0.7815 - val_loss: 0.6078 - val_root_mean_squared_error: 0.7722
Epoch 259/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6165 - root_mean_squared_error: 0.7769 - val_loss: 0.6092 - val_root_mean_squared_error: 0.7718
Epoch 260/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6120 - root_mean_squared_error: 0.7744 - val_loss: 0.5899 - val_root_mean_squared_error: 0.7592
Epoch 261/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6047 - root_mean_squared_error: 0.7695 - val_loss: 0.6043 - val_root_mean_squared_error: 0.7693
Epoch 262/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6012 - root_mean_squared_error: 0.7670 - val_loss: 0.6347 - val_root_mean_squared_error: 0.7892
Epoch 263/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6049 - root_mean_squared_error: 0.7697 - val_loss: 0.6219 - val_root_mean_squared_error: 0.7809
Epoch 264/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6113 - root_mean_squared_error: 0.7739 - val_loss: 0.5997 - val_root_mean_squared_error: 0.7664
Epoch 265/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6138 - root_mean_squared_error: 0.7753 - val_loss: 0.6046 - val_root_mean_squared_error: 0.7696
Epoch 266/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6269 - root_mean_squared_error: 0.7839 - val_loss: 0.5993 - val_root_mean_squared_error: 0.7661
Epoch 267/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6224 - root_mean_squared_error: 0.7816 - val_loss: 0.5998 - val_root_mean_squared_error: 0.7669
Epoch 268/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6144 - root_mean_squared_error: 0.7758 - val_loss: 0.6241 - val_root_mean_squared_error: 0.7817
Epoch 269/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6140 - root_mean_squared_error: 0.7760 - val_loss: 0.5908 - val_root_mean_squared_error: 0.7598
Epoch 270/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6019 - root_mean_squared_error: 0.7677 - val_loss: 0.6041 - val_root_mean_squared_error: 0.7692
Epoch 271/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6206 - root_mean_squared_error: 0.7796 - val_loss: 0.6285 - val_root_mean_squared_error: 0.7853
Epoch 272/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6158 - root_mean_squared_error: 0.7767 - val_loss: 0.6178 - val_root_mean_squared_error: 0.7786
Epoch 273/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6175 - root_mean_squared_error: 0.7780 - val_loss: 0.5989 - val_root_mean_squared_error: 0.7656
Epoch 274/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6122 - root_mean_squared_error: 0.7747 - val_loss: 0.6011 - val_root_mean_squared_error: 0.7675
Epoch 275/500
17/17 [==============================] - 0s 6ms/step - loss: 0.5994 - root_mean_squared_error: 0.7659 - val_loss: 0.5920 - val_root_mean_squared_error: 0.7604
Epoch 276/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6080 - root_mean_squared_error: 0.7716 - val_loss: 0.5994 - val_root_mean_squared_error: 0.7664
Epoch 277/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6136 - root_mean_squared_error: 0.7756 - val_loss: 0.6221 - val_root_mean_squared_error: 0.7810
Epoch 278/500
17/17 [==============================] - 0s 5ms/step - loss: 0.5993 - root_mean_squared_error: 0.7657 - val_loss: 0.6337 - val_root_mean_squared_error: 0.7879
Epoch 279/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6166 - root_mean_squared_error: 0.7774 - val_loss: 0.6155 - val_root_mean_squared_error: 0.7772
Epoch 280/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6102 - root_mean_squared_error: 0.7731 - val_loss: 0.5922 - val_root_mean_squared_error: 0.7608
Epoch 281/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6052 - root_mean_squared_error: 0.7697 - val_loss: 0.6324 - val_root_mean_squared_error: 0.7866
Epoch 282/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6063 - root_mean_squared_error: 0.7706 - val_loss: 0.5976 - val_root_mean_squared_error: 0.7646
Epoch 283/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6174 - root_mean_squared_error: 0.7778 - val_loss: 0.5887 - val_root_mean_squared_error: 0.7598
Epoch 284/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6155 - root_mean_squared_error: 0.7767 - val_loss: 0.6318 - val_root_mean_squared_error: 0.7868
Epoch 285/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6016 - root_mean_squared_error: 0.7677 - val_loss: 0.5907 - val_root_mean_squared_error: 0.7594
Epoch 286/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6200 - root_mean_squared_error: 0.7797 - val_loss: 0.6051 - val_root_mean_squared_error: 0.7690
Epoch 287/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6135 - root_mean_squared_error: 0.7748 - val_loss: 0.5940 - val_root_mean_squared_error: 0.7623
Epoch 288/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6083 - root_mean_squared_error: 0.7714 - val_loss: 0.6090 - val_root_mean_squared_error: 0.7719
Epoch 289/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6109 - root_mean_squared_error: 0.7736 - val_loss: 0.6104 - val_root_mean_squared_error: 0.7723
Epoch 290/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6275 - root_mean_squared_error: 0.7846 - val_loss: 0.6666 - val_root_mean_squared_error: 0.8087
Epoch 291/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6098 - root_mean_squared_error: 0.7729 - val_loss: 0.6235 - val_root_mean_squared_error: 0.7814
Epoch 292/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6028 - root_mean_squared_error: 0.7688 - val_loss: 0.5886 - val_root_mean_squared_error: 0.7594
Epoch 293/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6081 - root_mean_squared_error: 0.7716 - val_loss: 0.6048 - val_root_mean_squared_error: 0.7693
Epoch 294/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6062 - root_mean_squared_error: 0.7705 - val_loss: 0.6153 - val_root_mean_squared_error: 0.7771
Epoch 295/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6168 - root_mean_squared_error: 0.7774 - val_loss: 0.5989 - val_root_mean_squared_error: 0.7652
Epoch 296/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6154 - root_mean_squared_error: 0.7761 - val_loss: 0.5978 - val_root_mean_squared_error: 0.7648
Epoch 297/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6088 - root_mean_squared_error: 0.7724 - val_loss: 0.6024 - val_root_mean_squared_error: 0.7680
Epoch 298/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6101 - root_mean_squared_error: 0.7729 - val_loss: 0.6099 - val_root_mean_squared_error: 0.7725
Epoch 299/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6122 - root_mean_squared_error: 0.7746 - val_loss: 0.6030 - val_root_mean_squared_error: 0.7687
Epoch 300/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6216 - root_mean_squared_error: 0.7803 - val_loss: 0.5941 - val_root_mean_squared_error: 0.7620
Epoch 301/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6190 - root_mean_squared_error: 0.7788 - val_loss: 0.6175 - val_root_mean_squared_error: 0.7776
Epoch 302/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6148 - root_mean_squared_error: 0.7761 - val_loss: 0.6090 - val_root_mean_squared_error: 0.7726
Epoch 303/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6283 - root_mean_squared_error: 0.7849 - val_loss: 0.5996 - val_root_mean_squared_error: 0.7657
Epoch 304/500
17/17 [==============================] - 0s 4ms/step - loss: 0.6166 - root_mean_squared_error: 0.7772 - val_loss: 0.5954 - val_root_mean_squared_error: 0.7636
Epoch 305/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6096 - root_mean_squared_error: 0.7728 - val_loss: 0.5912 - val_root_mean_squared_error: 0.7603
Epoch 306/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6098 - root_mean_squared_error: 0.7728 - val_loss: 0.6311 - val_root_mean_squared_error: 0.7869
Epoch 307/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6127 - root_mean_squared_error: 0.7748 - val_loss: 0.6397 - val_root_mean_squared_error: 0.7916
Epoch 308/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6087 - root_mean_squared_error: 0.7717 - val_loss: 0.6082 - val_root_mean_squared_error: 0.7716
Epoch 309/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6134 - root_mean_squared_error: 0.7751 - val_loss: 0.5923 - val_root_mean_squared_error: 0.7616
Epoch 310/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6106 - root_mean_squared_error: 0.7734 - val_loss: 0.6237 - val_root_mean_squared_error: 0.7814
Epoch 311/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6043 - root_mean_squared_error: 0.7690 - val_loss: 0.5922 - val_root_mean_squared_error: 0.7612
Epoch 312/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6003 - root_mean_squared_error: 0.7665 - val_loss: 0.5869 - val_root_mean_squared_error: 0.7575
Epoch 313/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6029 - root_mean_squared_error: 0.7682 - val_loss: 0.5917 - val_root_mean_squared_error: 0.7611
Epoch 314/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6085 - root_mean_squared_error: 0.7718 - val_loss: 0.5986 - val_root_mean_squared_error: 0.7644
Epoch 315/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6064 - root_mean_squared_error: 0.7709 - val_loss: 0.6161 - val_root_mean_squared_error: 0.7764
Epoch 316/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6082 - root_mean_squared_error: 0.7718 - val_loss: 0.6079 - val_root_mean_squared_error: 0.7723
Epoch 317/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6226 - root_mean_squared_error: 0.7815 - val_loss: 0.5987 - val_root_mean_squared_error: 0.7647
Epoch 318/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6058 - root_mean_squared_error: 0.7702 - val_loss: 0.6072 - val_root_mean_squared_error: 0.7710
Epoch 319/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6062 - root_mean_squared_error: 0.7699 - val_loss: 0.5939 - val_root_mean_squared_error: 0.7624
Epoch 320/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6052 - root_mean_squared_error: 0.7701 - val_loss: 0.6016 - val_root_mean_squared_error: 0.7676
Epoch 321/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6164 - root_mean_squared_error: 0.7768 - val_loss: 0.5861 - val_root_mean_squared_error: 0.7577
Epoch 322/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6086 - root_mean_squared_error: 0.7719 - val_loss: 0.5942 - val_root_mean_squared_error: 0.7621
Epoch 323/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6120 - root_mean_squared_error: 0.7740 - val_loss: 0.6025 - val_root_mean_squared_error: 0.7682
Epoch 324/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6052 - root_mean_squared_error: 0.7693 - val_loss: 0.5907 - val_root_mean_squared_error: 0.7599
Epoch 325/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6002 - root_mean_squared_error: 0.7661 - val_loss: 0.5937 - val_root_mean_squared_error: 0.7623
Epoch 326/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6109 - root_mean_squared_error: 0.7734 - val_loss: 0.5910 - val_root_mean_squared_error: 0.7603
Epoch 327/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6148 - root_mean_squared_error: 0.7759 - val_loss: 0.5944 - val_root_mean_squared_error: 0.7631
Epoch 328/500
17/17 [==============================] - 0s 5ms/step - loss: 0.5991 - root_mean_squared_error: 0.7656 - val_loss: 0.5874 - val_root_mean_squared_error: 0.7573
Epoch 329/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6065 - root_mean_squared_error: 0.7703 - val_loss: 0.5988 - val_root_mean_squared_error: 0.7650
Epoch 330/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6086 - root_mean_squared_error: 0.7722 - val_loss: 0.6035 - val_root_mean_squared_error: 0.7685
Epoch 331/500
17/17 [==============================] - 0s 5ms/step - loss: 0.5957 - root_mean_squared_error: 0.7633 - val_loss: 0.5996 - val_root_mean_squared_error: 0.7656
Epoch 332/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6064 - root_mean_squared_error: 0.7706 - val_loss: 0.5948 - val_root_mean_squared_error: 0.7623
Epoch 333/500
17/17 [==============================] - 0s 5ms/step - loss: 0.5965 - root_mean_squared_error: 0.7641 - val_loss: 0.6122 - val_root_mean_squared_error: 0.7738
Epoch 334/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6219 - root_mean_squared_error: 0.7804 - val_loss: 0.6066 - val_root_mean_squared_error: 0.7698
Epoch 335/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6171 - root_mean_squared_error: 0.7773 - val_loss: 0.5984 - val_root_mean_squared_error: 0.7649
Epoch 336/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6154 - root_mean_squared_error: 0.7762 - val_loss: 0.5860 - val_root_mean_squared_error: 0.7564
Epoch 337/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6107 - root_mean_squared_error: 0.7727 - val_loss: 0.5878 - val_root_mean_squared_error: 0.7582
Epoch 338/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6077 - root_mean_squared_error: 0.7713 - val_loss: 0.5994 - val_root_mean_squared_error: 0.7659
Epoch 339/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6067 - root_mean_squared_error: 0.7708 - val_loss: 0.5888 - val_root_mean_squared_error: 0.7586
Epoch 340/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6048 - root_mean_squared_error: 0.7695 - val_loss: 0.6038 - val_root_mean_squared_error: 0.7690
Epoch 341/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6026 - root_mean_squared_error: 0.7679 - val_loss: 0.5831 - val_root_mean_squared_error: 0.7552
Epoch 342/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6044 - root_mean_squared_error: 0.7691 - val_loss: 0.6021 - val_root_mean_squared_error: 0.7670
Epoch 343/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6031 - root_mean_squared_error: 0.7679 - val_loss: 0.5968 - val_root_mean_squared_error: 0.7644
Epoch 344/500
17/17 [==============================] - 0s 5ms/step - loss: 0.5977 - root_mean_squared_error: 0.7648 - val_loss: 0.6036 - val_root_mean_squared_error: 0.7685
Epoch 345/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6040 - root_mean_squared_error: 0.7694 - val_loss: 0.6182 - val_root_mean_squared_error: 0.7781
Epoch 346/500
17/17 [==============================] - 0s 11ms/step - loss: 0.6080 - root_mean_squared_error: 0.7712 - val_loss: 0.5890 - val_root_mean_squared_error: 0.7592
Epoch 347/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6151 - root_mean_squared_error: 0.7759 - val_loss: 0.5863 - val_root_mean_squared_error: 0.7570
Epoch 348/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6132 - root_mean_squared_error: 0.7750 - val_loss: 0.6142 - val_root_mean_squared_error: 0.7754
Epoch 349/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6134 - root_mean_squared_error: 0.7746 - val_loss: 0.5942 - val_root_mean_squared_error: 0.7627
Epoch 350/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6024 - root_mean_squared_error: 0.7677 - val_loss: 0.6207 - val_root_mean_squared_error: 0.7800
Epoch 351/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6134 - root_mean_squared_error: 0.7750 - val_loss: 0.6185 - val_root_mean_squared_error: 0.7776
Epoch 352/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6155 - root_mean_squared_error: 0.7760 - val_loss: 0.6046 - val_root_mean_squared_error: 0.7688
Epoch 353/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6043 - root_mean_squared_error: 0.7692 - val_loss: 0.6062 - val_root_mean_squared_error: 0.7704
Epoch 354/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6172 - root_mean_squared_error: 0.7777 - val_loss: 0.5899 - val_root_mean_squared_error: 0.7594
Epoch 355/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6058 - root_mean_squared_error: 0.7701 - val_loss: 0.6132 - val_root_mean_squared_error: 0.7752
Epoch 356/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6136 - root_mean_squared_error: 0.7750 - val_loss: 0.6192 - val_root_mean_squared_error: 0.7785
Epoch 357/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6152 - root_mean_squared_error: 0.7759 - val_loss: 0.5922 - val_root_mean_squared_error: 0.7617
Epoch 358/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6070 - root_mean_squared_error: 0.7705 - val_loss: 0.6045 - val_root_mean_squared_error: 0.7692
Epoch 359/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6041 - root_mean_squared_error: 0.7690 - val_loss: 0.5946 - val_root_mean_squared_error: 0.7631
Epoch 360/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6113 - root_mean_squared_error: 0.7731 - val_loss: 0.6045 - val_root_mean_squared_error: 0.7699
Epoch 361/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6024 - root_mean_squared_error: 0.7678 - val_loss: 0.5969 - val_root_mean_squared_error: 0.7645
Epoch 362/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6175 - root_mean_squared_error: 0.7774 - val_loss: 0.5986 - val_root_mean_squared_error: 0.7653
Epoch 363/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6074 - root_mean_squared_error: 0.7710 - val_loss: 0.6091 - val_root_mean_squared_error: 0.7724
Epoch 364/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6001 - root_mean_squared_error: 0.7661 - val_loss: 0.5991 - val_root_mean_squared_error: 0.7659
Epoch 365/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6129 - root_mean_squared_error: 0.7744 - val_loss: 0.5989 - val_root_mean_squared_error: 0.7662
Epoch 366/500
17/17 [==============================] - 0s 10ms/step - loss: 0.5975 - root_mean_squared_error: 0.7645 - val_loss: 0.5875 - val_root_mean_squared_error: 0.7583
Epoch 367/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6121 - root_mean_squared_error: 0.7740 - val_loss: 0.5999 - val_root_mean_squared_error: 0.7656
Epoch 368/500
17/17 [==============================] - 0s 6ms/step - loss: 0.5932 - root_mean_squared_error: 0.7619 - val_loss: 0.6004 - val_root_mean_squared_error: 0.7661
Epoch 369/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6051 - root_mean_squared_error: 0.7693 - val_loss: 0.6114 - val_root_mean_squared_error: 0.7739
Epoch 370/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6045 - root_mean_squared_error: 0.7692 - val_loss: 0.5869 - val_root_mean_squared_error: 0.7574
Epoch 371/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6100 - root_mean_squared_error: 0.7729 - val_loss: 0.6055 - val_root_mean_squared_error: 0.7705
Epoch 372/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6042 - root_mean_squared_error: 0.7687 - val_loss: 0.6071 - val_root_mean_squared_error: 0.7706
Epoch 373/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6244 - root_mean_squared_error: 0.7817 - val_loss: 0.6185 - val_root_mean_squared_error: 0.7784
Epoch 374/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6043 - root_mean_squared_error: 0.7687 - val_loss: 0.6052 - val_root_mean_squared_error: 0.7696
Epoch 375/500
17/17 [==============================] - 0s 5ms/step - loss: 0.6146 - root_mean_squared_error: 0.7753 - val_loss: 0.5903 - val_root_mean_squared_error: 0.7599
Epoch 376/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6063 - root_mean_squared_error: 0.7704 - val_loss: 0.6101 - val_root_mean_squared_error: 0.7726
Epoch 377/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6000 - root_mean_squared_error: 0.7656 - val_loss: 0.5902 - val_root_mean_squared_error: 0.7594
Epoch 378/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6065 - root_mean_squared_error: 0.7699 - val_loss: 0.6050 - val_root_mean_squared_error: 0.7694
Epoch 379/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6123 - root_mean_squared_error: 0.7738 - val_loss: 0.5953 - val_root_mean_squared_error: 0.7626
Epoch 380/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6113 - root_mean_squared_error: 0.7736 - val_loss: 0.5871 - val_root_mean_squared_error: 0.7576
Epoch 381/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6102 - root_mean_squared_error: 0.7727 - val_loss: 0.6015 - val_root_mean_squared_error: 0.7671
Epoch 382/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6033 - root_mean_squared_error: 0.7677 - val_loss: 0.5908 - val_root_mean_squared_error: 0.7591
Epoch 383/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6028 - root_mean_squared_error: 0.7679 - val_loss: 0.5998 - val_root_mean_squared_error: 0.7647
Epoch 384/500
17/17 [==============================] - 0s 11ms/step - loss: 0.6015 - root_mean_squared_error: 0.7669 - val_loss: 0.5913 - val_root_mean_squared_error: 0.7606
Epoch 385/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6038 - root_mean_squared_error: 0.7683 - val_loss: 0.6006 - val_root_mean_squared_error: 0.7659
Epoch 386/500
17/17 [==============================] - 0s 12ms/step - loss: 0.5979 - root_mean_squared_error: 0.7644 - val_loss: 0.6163 - val_root_mean_squared_error: 0.7766
Epoch 387/500
17/17 [==============================] - 0s 12ms/step - loss: 0.6100 - root_mean_squared_error: 0.7726 - val_loss: 0.5991 - val_root_mean_squared_error: 0.7659
Epoch 388/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6212 - root_mean_squared_error: 0.7796 - val_loss: 0.5870 - val_root_mean_squared_error: 0.7571
Epoch 389/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6050 - root_mean_squared_error: 0.7696 - val_loss: 0.5926 - val_root_mean_squared_error: 0.7610
Epoch 390/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6120 - root_mean_squared_error: 0.7739 - val_loss: 0.6128 - val_root_mean_squared_error: 0.7744
Epoch 391/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6053 - root_mean_squared_error: 0.7687 - val_loss: 0.6007 - val_root_mean_squared_error: 0.7667
Epoch 392/500
17/17 [==============================] - 0s 9ms/step - loss: 0.5961 - root_mean_squared_error: 0.7633 - val_loss: 0.6008 - val_root_mean_squared_error: 0.7667
Epoch 393/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6076 - root_mean_squared_error: 0.7708 - val_loss: 0.5929 - val_root_mean_squared_error: 0.7615
Epoch 394/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6060 - root_mean_squared_error: 0.7694 - val_loss: 0.6029 - val_root_mean_squared_error: 0.7675
Epoch 395/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6035 - root_mean_squared_error: 0.7679 - val_loss: 0.6283 - val_root_mean_squared_error: 0.7839
Epoch 396/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6016 - root_mean_squared_error: 0.7668 - val_loss: 0.5869 - val_root_mean_squared_error: 0.7577
Epoch 397/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6083 - root_mean_squared_error: 0.7712 - val_loss: 0.5850 - val_root_mean_squared_error: 0.7567
Epoch 398/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6091 - root_mean_squared_error: 0.7718 - val_loss: 0.5882 - val_root_mean_squared_error: 0.7587
Epoch 399/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6072 - root_mean_squared_error: 0.7707 - val_loss: 0.5843 - val_root_mean_squared_error: 0.7560
Epoch 400/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6072 - root_mean_squared_error: 0.7705 - val_loss: 0.6191 - val_root_mean_squared_error: 0.7774
Epoch 401/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5952 - root_mean_squared_error: 0.7625 - val_loss: 0.5882 - val_root_mean_squared_error: 0.7581
Epoch 402/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6063 - root_mean_squared_error: 0.7701 - val_loss: 0.5965 - val_root_mean_squared_error: 0.7636
Epoch 403/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6008 - root_mean_squared_error: 0.7663 - val_loss: 0.5913 - val_root_mean_squared_error: 0.7592
Epoch 404/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6052 - root_mean_squared_error: 0.7693 - val_loss: 0.6093 - val_root_mean_squared_error: 0.7711
Epoch 405/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6039 - root_mean_squared_error: 0.7677 - val_loss: 0.5825 - val_root_mean_squared_error: 0.7542
Epoch 406/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5997 - root_mean_squared_error: 0.7657 - val_loss: 0.5822 - val_root_mean_squared_error: 0.7537
Epoch 407/500
17/17 [==============================] - 0s 9ms/step - loss: 0.5998 - root_mean_squared_error: 0.7659 - val_loss: 0.6063 - val_root_mean_squared_error: 0.7698
Epoch 408/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5981 - root_mean_squared_error: 0.7645 - val_loss: 0.6143 - val_root_mean_squared_error: 0.7750
Epoch 409/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6082 - root_mean_squared_error: 0.7713 - val_loss: 0.5917 - val_root_mean_squared_error: 0.7606
Epoch 410/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6104 - root_mean_squared_error: 0.7722 - val_loss: 0.5876 - val_root_mean_squared_error: 0.7581
Epoch 411/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6106 - root_mean_squared_error: 0.7729 - val_loss: 0.5992 - val_root_mean_squared_error: 0.7649
Epoch 412/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6068 - root_mean_squared_error: 0.7705 - val_loss: 0.5894 - val_root_mean_squared_error: 0.7589
Epoch 413/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6046 - root_mean_squared_error: 0.7691 - val_loss: 0.5958 - val_root_mean_squared_error: 0.7633
Epoch 414/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6090 - root_mean_squared_error: 0.7714 - val_loss: 0.6172 - val_root_mean_squared_error: 0.7771
Epoch 415/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6096 - root_mean_squared_error: 0.7718 - val_loss: 0.6002 - val_root_mean_squared_error: 0.7656
Epoch 416/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6139 - root_mean_squared_error: 0.7747 - val_loss: 0.5892 - val_root_mean_squared_error: 0.7581
Epoch 417/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6037 - root_mean_squared_error: 0.7678 - val_loss: 0.5950 - val_root_mean_squared_error: 0.7618
Epoch 418/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6055 - root_mean_squared_error: 0.7695 - val_loss: 0.6210 - val_root_mean_squared_error: 0.7793
Epoch 419/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6088 - root_mean_squared_error: 0.7719 - val_loss: 0.6201 - val_root_mean_squared_error: 0.7789
Epoch 420/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6122 - root_mean_squared_error: 0.7736 - val_loss: 0.5955 - val_root_mean_squared_error: 0.7633
Epoch 421/500
17/17 [==============================] - 0s 7ms/step - loss: 0.5985 - root_mean_squared_error: 0.7650 - val_loss: 0.5795 - val_root_mean_squared_error: 0.7526
Epoch 422/500
17/17 [==============================] - 0s 9ms/step - loss: 0.5964 - root_mean_squared_error: 0.7634 - val_loss: 0.5950 - val_root_mean_squared_error: 0.7614
Epoch 423/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6006 - root_mean_squared_error: 0.7660 - val_loss: 0.6080 - val_root_mean_squared_error: 0.7713
Epoch 424/500
17/17 [==============================] - 0s 10ms/step - loss: 0.6047 - root_mean_squared_error: 0.7684 - val_loss: 0.5970 - val_root_mean_squared_error: 0.7637
Epoch 425/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6040 - root_mean_squared_error: 0.7682 - val_loss: 0.5939 - val_root_mean_squared_error: 0.7610
Epoch 426/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6085 - root_mean_squared_error: 0.7715 - val_loss: 0.5909 - val_root_mean_squared_error: 0.7600
Epoch 427/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6118 - root_mean_squared_error: 0.7733 - val_loss: 0.6040 - val_root_mean_squared_error: 0.7681
Epoch 428/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5989 - root_mean_squared_error: 0.7652 - val_loss: 0.6534 - val_root_mean_squared_error: 0.7998
Epoch 429/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5989 - root_mean_squared_error: 0.7648 - val_loss: 0.6095 - val_root_mean_squared_error: 0.7719
Epoch 430/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6043 - root_mean_squared_error: 0.7684 - val_loss: 0.5871 - val_root_mean_squared_error: 0.7575
Epoch 431/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6072 - root_mean_squared_error: 0.7703 - val_loss: 0.5872 - val_root_mean_squared_error: 0.7574
Epoch 432/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6067 - root_mean_squared_error: 0.7700 - val_loss: 0.6136 - val_root_mean_squared_error: 0.7753
Epoch 433/500
17/17 [==============================] - 0s 7ms/step - loss: 0.5983 - root_mean_squared_error: 0.7645 - val_loss: 0.6064 - val_root_mean_squared_error: 0.7698
Epoch 434/500
17/17 [==============================] - 0s 7ms/step - loss: 0.5958 - root_mean_squared_error: 0.7629 - val_loss: 0.6233 - val_root_mean_squared_error: 0.7801
Epoch 435/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6059 - root_mean_squared_error: 0.7694 - val_loss: 0.5900 - val_root_mean_squared_error: 0.7600
Epoch 436/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6072 - root_mean_squared_error: 0.7700 - val_loss: 0.6020 - val_root_mean_squared_error: 0.7675
Epoch 437/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6092 - root_mean_squared_error: 0.7717 - val_loss: 0.6048 - val_root_mean_squared_error: 0.7684
Epoch 438/500
17/17 [==============================] - 0s 6ms/step - loss: 0.5939 - root_mean_squared_error: 0.7620 - val_loss: 0.6025 - val_root_mean_squared_error: 0.7672
Epoch 439/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6044 - root_mean_squared_error: 0.7686 - val_loss: 0.6246 - val_root_mean_squared_error: 0.7820
Epoch 440/500
17/17 [==============================] - 0s 6ms/step - loss: 0.5971 - root_mean_squared_error: 0.7635 - val_loss: 0.6086 - val_root_mean_squared_error: 0.7702
Epoch 441/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6060 - root_mean_squared_error: 0.7697 - val_loss: 0.6005 - val_root_mean_squared_error: 0.7657
Epoch 442/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6100 - root_mean_squared_error: 0.7719 - val_loss: 0.6247 - val_root_mean_squared_error: 0.7813
Epoch 443/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6044 - root_mean_squared_error: 0.7684 - val_loss: 0.5913 - val_root_mean_squared_error: 0.7600
Epoch 444/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5937 - root_mean_squared_error: 0.7612 - val_loss: 0.6058 - val_root_mean_squared_error: 0.7694
Epoch 445/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6034 - root_mean_squared_error: 0.7679 - val_loss: 0.6004 - val_root_mean_squared_error: 0.7657
Epoch 446/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6131 - root_mean_squared_error: 0.7739 - val_loss: 0.6041 - val_root_mean_squared_error: 0.7682
Epoch 447/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5954 - root_mean_squared_error: 0.7625 - val_loss: 0.6149 - val_root_mean_squared_error: 0.7759
Epoch 448/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6009 - root_mean_squared_error: 0.7661 - val_loss: 0.5957 - val_root_mean_squared_error: 0.7635
Epoch 449/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6042 - root_mean_squared_error: 0.7682 - val_loss: 0.6324 - val_root_mean_squared_error: 0.7873
Epoch 450/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6073 - root_mean_squared_error: 0.7702 - val_loss: 0.5916 - val_root_mean_squared_error: 0.7603
Epoch 451/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6114 - root_mean_squared_error: 0.7729 - val_loss: 0.6116 - val_root_mean_squared_error: 0.7737
Epoch 452/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6048 - root_mean_squared_error: 0.7687 - val_loss: 0.6010 - val_root_mean_squared_error: 0.7659
Epoch 453/500
17/17 [==============================] - 0s 9ms/step - loss: 0.5921 - root_mean_squared_error: 0.7605 - val_loss: 0.5952 - val_root_mean_squared_error: 0.7622
Epoch 454/500
17/17 [==============================] - 0s 7ms/step - loss: 0.5976 - root_mean_squared_error: 0.7644 - val_loss: 0.6178 - val_root_mean_squared_error: 0.7774
Epoch 455/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6004 - root_mean_squared_error: 0.7654 - val_loss: 0.6043 - val_root_mean_squared_error: 0.7689
Epoch 456/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5987 - root_mean_squared_error: 0.7647 - val_loss: 0.6098 - val_root_mean_squared_error: 0.7721
Epoch 457/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6122 - root_mean_squared_error: 0.7735 - val_loss: 0.5855 - val_root_mean_squared_error: 0.7566
Epoch 458/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6049 - root_mean_squared_error: 0.7686 - val_loss: 0.5773 - val_root_mean_squared_error: 0.7509
Epoch 459/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6017 - root_mean_squared_error: 0.7669 - val_loss: 0.6029 - val_root_mean_squared_error: 0.7666
Epoch 460/500
17/17 [==============================] - 0s 9ms/step - loss: 0.5931 - root_mean_squared_error: 0.7608 - val_loss: 0.6052 - val_root_mean_squared_error: 0.7691
Epoch 461/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5988 - root_mean_squared_error: 0.7649 - val_loss: 0.6223 - val_root_mean_squared_error: 0.7800
Epoch 462/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5978 - root_mean_squared_error: 0.7638 - val_loss: 0.6180 - val_root_mean_squared_error: 0.7764
Epoch 463/500
17/17 [==============================] - 0s 6ms/step - loss: 0.6042 - root_mean_squared_error: 0.7688 - val_loss: 0.5988 - val_root_mean_squared_error: 0.7650
Epoch 464/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6044 - root_mean_squared_error: 0.7683 - val_loss: 0.5823 - val_root_mean_squared_error: 0.7539
Epoch 465/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6023 - root_mean_squared_error: 0.7671 - val_loss: 0.5826 - val_root_mean_squared_error: 0.7546
Epoch 466/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5926 - root_mean_squared_error: 0.7606 - val_loss: 0.5878 - val_root_mean_squared_error: 0.7575
Epoch 467/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6080 - root_mean_squared_error: 0.7711 - val_loss: 0.6096 - val_root_mean_squared_error: 0.7718
Epoch 468/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6041 - root_mean_squared_error: 0.7685 - val_loss: 0.5976 - val_root_mean_squared_error: 0.7632
Epoch 469/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6072 - root_mean_squared_error: 0.7702 - val_loss: 0.6010 - val_root_mean_squared_error: 0.7675
Epoch 470/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5950 - root_mean_squared_error: 0.7624 - val_loss: 0.5921 - val_root_mean_squared_error: 0.7601
Epoch 471/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6024 - root_mean_squared_error: 0.7667 - val_loss: 0.5940 - val_root_mean_squared_error: 0.7617
Epoch 472/500
17/17 [==============================] - 0s 7ms/step - loss: 0.5961 - root_mean_squared_error: 0.7631 - val_loss: 0.6270 - val_root_mean_squared_error: 0.7826
Epoch 473/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6000 - root_mean_squared_error: 0.7654 - val_loss: 0.6121 - val_root_mean_squared_error: 0.7736
Epoch 474/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6100 - root_mean_squared_error: 0.7721 - val_loss: 0.5844 - val_root_mean_squared_error: 0.7555
Epoch 475/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6286 - root_mean_squared_error: 0.7840 - val_loss: 0.6162 - val_root_mean_squared_error: 0.7764
Epoch 476/500
17/17 [==============================] - 0s 7ms/step - loss: 0.5926 - root_mean_squared_error: 0.7606 - val_loss: 0.5961 - val_root_mean_squared_error: 0.7627
Epoch 477/500
17/17 [==============================] - 0s 9ms/step - loss: 0.5964 - root_mean_squared_error: 0.7629 - val_loss: 0.5903 - val_root_mean_squared_error: 0.7593
Epoch 478/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6020 - root_mean_squared_error: 0.7671 - val_loss: 0.6048 - val_root_mean_squared_error: 0.7693
Epoch 479/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6012 - root_mean_squared_error: 0.7662 - val_loss: 0.5906 - val_root_mean_squared_error: 0.7589
Epoch 480/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6030 - root_mean_squared_error: 0.7675 - val_loss: 0.6006 - val_root_mean_squared_error: 0.7650
Epoch 481/500
17/17 [==============================] - 0s 7ms/step - loss: 0.5926 - root_mean_squared_error: 0.7605 - val_loss: 0.5816 - val_root_mean_squared_error: 0.7522
Epoch 482/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6048 - root_mean_squared_error: 0.7687 - val_loss: 0.6075 - val_root_mean_squared_error: 0.7697
Epoch 483/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5972 - root_mean_squared_error: 0.7635 - val_loss: 0.6018 - val_root_mean_squared_error: 0.7668
Epoch 484/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6108 - root_mean_squared_error: 0.7725 - val_loss: 0.6029 - val_root_mean_squared_error: 0.7673
Epoch 485/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6230 - root_mean_squared_error: 0.7805 - val_loss: 0.5999 - val_root_mean_squared_error: 0.7650
Epoch 486/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6051 - root_mean_squared_error: 0.7686 - val_loss: 0.5855 - val_root_mean_squared_error: 0.7551
Epoch 487/500
17/17 [==============================] - 0s 6ms/step - loss: 0.5953 - root_mean_squared_error: 0.7624 - val_loss: 0.5923 - val_root_mean_squared_error: 0.7603
Epoch 488/500
17/17 [==============================] - 0s 7ms/step - loss: 0.5972 - root_mean_squared_error: 0.7635 - val_loss: 0.5944 - val_root_mean_squared_error: 0.7612
Epoch 489/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6069 - root_mean_squared_error: 0.7701 - val_loss: 0.6224 - val_root_mean_squared_error: 0.7797
Epoch 490/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6077 - root_mean_squared_error: 0.7704 - val_loss: 0.6095 - val_root_mean_squared_error: 0.7717
Epoch 491/500
17/17 [==============================] - 0s 7ms/step - loss: 0.5896 - root_mean_squared_error: 0.7585 - val_loss: 0.6151 - val_root_mean_squared_error: 0.7752
Epoch 492/500
17/17 [==============================] - 0s 8ms/step - loss: 0.6007 - root_mean_squared_error: 0.7663 - val_loss: 0.5791 - val_root_mean_squared_error: 0.7517
Epoch 493/500
17/17 [==============================] - 0s 8ms/step - loss: 0.5930 - root_mean_squared_error: 0.7606 - val_loss: 0.6020 - val_root_mean_squared_error: 0.7668
Epoch 494/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6027 - root_mean_squared_error: 0.7669 - val_loss: 0.5847 - val_root_mean_squared_error: 0.7564
Epoch 495/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6002 - root_mean_squared_error: 0.7659 - val_loss: 0.6294 - val_root_mean_squared_error: 0.7846
Epoch 496/500
17/17 [==============================] - 0s 9ms/step - loss: 0.6028 - root_mean_squared_error: 0.7673 - val_loss: 0.5916 - val_root_mean_squared_error: 0.7601
Epoch 497/500
17/17 [==============================] - 0s 7ms/step - loss: 0.5973 - root_mean_squared_error: 0.7636 - val_loss: 0.6069 - val_root_mean_squared_error: 0.7709
Epoch 498/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6015 - root_mean_squared_error: 0.7665 - val_loss: 0.6210 - val_root_mean_squared_error: 0.7799
Epoch 499/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6053 - root_mean_squared_error: 0.7691 - val_loss: 0.6070 - val_root_mean_squared_error: 0.7693
Epoch 500/500
17/17 [==============================] - 0s 7ms/step - loss: 0.6001 - root_mean_squared_error: 0.7655 - val_loss: 0.5977 - val_root_mean_squared_error: 0.7642
Model training finished.
Train RMSE: 0.765
Evaluating model performance...
Test RMSE: 0.766
Predictions mean: 5.29, min: 4.95, max: 5.62, range: 0.67 - Actual: 6.0
Predictions mean: 5.26, min: 4.89, max: 5.82, range: 0.92 - Actual: 4.0
Predictions mean: 6.46, min: 5.91, max: 6.6, range: 0.69 - Actual: 7.0
Predictions mean: 6.12, min: 5.58, max: 6.33, range: 0.75 - Actual: 6.0
Predictions mean: 5.53, min: 5.08, max: 6.01, range: 0.93 - Actual: 6.0
Predictions mean: 5.62, min: 5.16, max: 6.09, range: 0.93 - Actual: 5.0
Predictions mean: 5.73, min: 5.25, max: 6.15, range: 0.9 - Actual: 5.0
Predictions mean: 5.81, min: 5.45, max: 6.09, range: 0.64 - Actual: 4.0
Predictions mean: 6.57, min: 6.17, max: 6.67, range: 0.5 - Actual: 6.0
Predictions mean: 5.89, min: 5.53, max: 6.12, range: 0.59 - Actual: 5.0
</pre></div>
</div>
</div>
</div>
<p id="id3"><dl class="citation">
<dt class="label" id="id26"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>)</span></dt>
<dd><p>Laurent Valentin Jospin, Wray L. Buntine, Farid Boussa\&quot;ıd, Hamid Laga, and Mohammed Bennamoun. Hands-on bayesian neural networks - a tutorial for deep learning users. <em>CoRR</em>, 2020. URL: <a class="reference external" href="https://arxiv.org/abs/2007.06823">https://arxiv.org/abs/2007.06823</a>, <a class="reference external" href="https://arxiv.org/abs/2007.06823">arXiv:2007.06823</a>.</p>
</dd>
</dl>
</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./02_probML"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="02_GPforML/10_advanced/03_DeepGP.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">7.10.3. </span>Gaussian Processes on latent representations</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../03_appl/01_BO.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">9. </span>Bayesian Optimization</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By C. Bogoclu, N. Friedlich & R. Vosshall<br/>
        
          <div class="extra_footer">
            Content on this site is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">a CC BY-NC-NB 4.0 licence</a>.
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>