
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>7.10.3. Gaussian Processes on latent representations &#8212; Introduction to Probabilistic Machine Learning</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/additional.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://probabilistic-ml.github.io/lecture-notes/welcome.html/02_probML/02_GPforML/10_advanced/03_DeepGP.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="8. Overview of Further Probabilistic Models" href="../../03_overview.html" />
    <link rel="prev" title="7.10.2. Non-stationary Gaussian Processes" href="02_NonstationaryGP.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Probabilistic Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../welcome.html">
   Welcome
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Preface
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../00_preface/01_preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../00_preface/02_python.html">
   Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../00_preface/03_notation.html">
   Notation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Fundamentals
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../01_fund/01_fundprob.html">
   1. Fundamentals of Probability Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../01_fund/01_fundprob/01_probabilityspaces.html">
     1.1. Probability Spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../01_fund/01_fundprob/02_randomvariables.html">
     1.2. Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../01_fund/01_fundprob/03_independence.html">
     1.3. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../01_fund/01_fundprob/04_impprobdistr.html">
     1.4. Important Probability Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../01_fund/01_fundprob/05_essthms.html">
     1.5. Essential Theorems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../01_fund/02_stat.html">
   2. Bayesian vs. Frequentists View
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../01_fund/03_bayes.html">
   3. Bayesian Inference, MAP &amp; MLE
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../01_fund/03_bayes/01_cointoss.html">
     3.1. Coin Toss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../01_fund/03_bayes/02_bayesianinference.html">
     3.2. Bayesian Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../01_fund/03_bayes/03_MLEandMAP.html">
     3.3. MAP and MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../01_fund/03_bayes/04_linregr.html">
     3.4. Linear Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../01_fund/04_opt.html">
   4. Optimization Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../01_fund/05_MLworkflow.html">
   5. Machine Learning Workflow
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probabilistic Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../01_motivation.html">
   6. Motivation of Probabilistic Models
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../02_GPforML.html">
   7. Gaussian Processes for Machine Learning
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../01_kerneltrick.html">
     7.1. The Kernel Trick: Implicit embeddings from inner products
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_GP.html">
     7.2. Gaussian Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_GPregression.html">
     7.3. Gaussian Process Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_kernels.html">
     7.4. Kernel Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_hyperparamimpact.html">
     7.5. Impact of Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06_hyperparamselect.html">
     7.6. Selection of Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07_multiout.html">
     7.7. Extension to Multiple Outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08_GPclassification.html">
     7.8. Gaussian Process Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09_examples.html">
     7.9. Examples
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../10_advanced.html">
     7.10. Advanced Methods
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="01_SparseGP.html">
       7.10.1. Scalable Gaussian Processes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="02_NonstationaryGP.html">
       7.10.2. Non-stationary Gaussian Processes
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       7.10.3. Gaussian Processes on latent representations
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_overview.html">
   8. Overview of Further Probabilistic Models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../03_appl/01_BO.html">
   9. Bayesian Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../03_appl/uncertainty.html">
   10. Design Uncertainty Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../03_appl/03_RL.html">
   11. Efficient Reinforcement Learning
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org/"><img alt="Jupyter Book" src="https://jupyterbook.org/badge.svg" width="100"></a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/02_probML/02_GPforML/10_advanced/03_DeepGP.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Probabilistic-ML/lecture-notes"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="gaussian-processes-on-latent-representations">
<h1><span class="section-number">7.10.3. </span>Gaussian Processes on latent representations<a class="headerlink" href="#gaussian-processes-on-latent-representations" title="Permalink to this headline">¶</a></h1>
<p>Although the representative power of a Gaussian process is quite high due to the use of kernels, a single kernel measure may not be sufficient to represent very complicated relationships. Although kernel engineering, i.e. combining multiple kernels, may provide some improvement of the representative power, this may still be insufficient. The kernel evaluation is bound to the original <span class="math notranslate nohighlight">\(d\)</span>-dimensional space <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>. However, the Euclidean distance as used in stationary kernels may not be the best way of measuring similarity between the samples <span class="math notranslate nohighlight">\(x_i \in \mathbb{R}^d\)</span>, on which the kernel approximation relies. Thus, a transformation <span class="math notranslate nohighlight">\(f_t: \mathbb{R}^d \rightarrow \mathbb{R}^q\)</span> to a latent space <span class="math notranslate nohighlight">\(\mathbb{R}^q\)</span> can be deployed to improve the effectivenes of the Eulidean distance on the new latent samples <span class="math notranslate nohighlight">\(u_i = f_t(x_i)\)</span>.</p>
<p>Both <span id="id1">[<a class="reference internal" href="#id27">2</a>]</span> and <span id="id2">[<a class="reference internal" href="#id26">5</a>]</span> propose to use deep <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span>, where multiple <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span> are stacked and the outputs of the previous layer <span class="math notranslate nohighlight">\(\mathcal{GP}_{i-1}\)</span> are used as the inputs of the current layer <span class="math notranslate nohighlight">\(\mathcal{GP}_{i}\)</span>. In other words, <span class="math notranslate nohighlight">\(l\)</span> number of <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span>s are stacked, where the first layers <span class="math notranslate nohighlight">\(\mathcal{GP}_{1, \dots, l-1}\)</span> correspond to the transformation function <span class="math notranslate nohighlight">\(f_t(\cdot)\)</span> and the posterior of the last layer <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span> corresponds to the predicted posterior. Both publications differ in the way the training and posterior prediction are formulated. In <span id="id3">[<a class="reference internal" href="#id27">2</a>]</span>, a variational posterior is used. This assumes an independence of the outputs of each layer. In <span id="id4">[<a class="reference internal" href="#id26">5</a>]</span>, a doubly stochastic variational inference is performed instead, where the assumption of independence is dropped.</p>
<p>Besides stacking <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span>s, various neural network architectures are also proposed for the transformation <span class="math notranslate nohighlight">\(f_t\)</span>. Most importantly, exact <span id="id5">[<a class="reference internal" href="#id28">6</a>]</span> and approximate <span id="id6">[<a class="reference internal" href="#id29">7</a>]</span> deep kernel learning were proposed, where a deep neural network (DNN) with reducing number of neurons were used as <span class="math notranslate nohighlight">\(f_t(\dot)\)</span> to reduce the dimensionality. This approach is especially useful, if the original representation contains redundant features such as in images.</p>
<p>Moreover, using variational autoencoders with exact <span id="id7">[<a class="reference internal" href="#id30">1</a>]</span> and sparse <span id="id8">[<a class="reference internal" href="#id31">3</a>]</span> <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span> were also proposed. Since variational autoencoder seek to learn independent Gaussians as latent variables <span id="id9">[<a class="reference internal" href="#id32">4</a>]</span>, using them in a <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span> context becomes more straightforward while providing the advantages of probabilistic treatment.  Finally, <span id="id10">[]</span> derive an exact equivalence between <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span> and DNN, followed by a proposal to use <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span> prior on DNN, yielding neural network Gaussian Processes. As such, <span class="math notranslate nohighlight">\(f_t(\cdot)\)</span> consists of all latent layers of the DNN before the output layer.</p>
<p id="id11"><dl class="citation">
<dt class="label" id="id30"><span class="brackets"><a class="fn-backref" href="#id7">1</a></span></dt>
<dd><p>Francesco Paolo Casale, Adrian V. Dalca, Luca Saglietti, Jennifer Listgarten, and Nicoló Fusi. Gaussian process prior variational autoencoders. In <em>NeurIPS</em>. 2018.</p>
</dd>
<dt class="label" id="id27"><span class="brackets">2</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id3">2</a>)</span></dt>
<dd><p>Andreas Damianou and Neil D. Lawrence. Deep Gaussian processes. In Carlos M. Carvalho and Pradeep Ravikumar, editors, <em>Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics</em>, volume 31 of Proceedings of Machine Learning Research, 207–215. Scottsdale, Arizona, USA, 29 Apr–01 May 2013. PMLR. URL: <a class="reference external" href="https://proceedings.mlr.press/v31/damianou13a.html">https://proceedings.mlr.press/v31/damianou13a.html</a>.</p>
</dd>
<dt class="label" id="id31"><span class="brackets"><a class="fn-backref" href="#id8">3</a></span></dt>
<dd><p>Metod Jazbec, Matt Ashman, Vincent Fortuin, Michael Pearce, Stephan Mandt, and Gunnar Rätsch. Scalable gaussian process variational autoencoders. In Arindam Banerjee and Kenji Fukumizu, editors, <em>Proceedings of The 24th International Conference on Artificial Intelligence and Statistics</em>, volume 130 of Proceedings of Machine Learning Research, 3511–3519. PMLR, 13–15 Apr 2021. URL: <a class="reference external" href="https://proceedings.mlr.press/v130/jazbec21a.html">https://proceedings.mlr.press/v130/jazbec21a.html</a>.</p>
</dd>
<dt class="label" id="id32"><span class="brackets"><a class="fn-backref" href="#id9">4</a></span></dt>
<dd><p>Diederik P Kingma and Max Welling. Auto-encoding variational bayes. 2014. <a class="reference external" href="https://arxiv.org/abs/1312.6114">arXiv:1312.6114</a>.</p>
</dd>
<dt class="label" id="id26"><span class="brackets">5</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>Hugh Salimbeni and Marc Deisenroth. Doubly stochastic variational inference for deep gaussian processes. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, <em>Advances in Neural Information Processing Systems</em>, volume 30. Curran Associates, Inc., 2017. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper/2017/file/8208974663db80265e9bfe7b222dcb18-Paper.pdf">https://proceedings.neurips.cc/paper/2017/file/8208974663db80265e9bfe7b222dcb18-Paper.pdf</a>.</p>
</dd>
<dt class="label" id="id28"><span class="brackets"><a class="fn-backref" href="#id5">6</a></span></dt>
<dd><p>Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P. Xing. Deep kernel learning. In Arthur Gretton and Christian C. Robert, editors, <em>Proceedings of the 19th International Conference on Artificial Intelligence and Statistics</em>, volume 51 of Proceedings of Machine Learning Research, 370–378. Cadiz, Spain, 09–11 May 2016. PMLR. URL: <a class="reference external" href="https://proceedings.mlr.press/v51/wilson16.html">https://proceedings.mlr.press/v51/wilson16.html</a>.</p>
</dd>
<dt class="label" id="id29"><span class="brackets"><a class="fn-backref" href="#id6">7</a></span></dt>
<dd><p>Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P. Xing. Stochastic variational deep kernel learning. In <em>NIPS</em>. 2016.</p>
</dd>
</dl>
</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./02_probML/02_GPforML/10_advanced"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="02_NonstationaryGP.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">7.10.2. </span>Non-stationary Gaussian Processes</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../03_overview.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8. </span>Overview of Further Probabilistic Models</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By C. Bogoclu, N. Friedlich & R. Vosshall<br/>
        
          <div class="extra_footer">
            Content on this site is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">a CC BY-NC-NB 4.0 licence</a>.
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>