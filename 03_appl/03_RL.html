
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>11. Efficient Reinforcement Learning &#8212; Introduction to Probabilistic Machine Learning</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/additional.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://probabilistic-ml.github.io/lecture-notes/welcome.html/03_appl/03_RL.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="10. Design Uncertainty Analysis" href="uncertainty.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Probabilistic Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../welcome.html">
   Welcome
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Preface
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_preface/01_preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_preface/02_python.html">
   Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_preface/03_notation.html">
   Notation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Fundamentals
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01_fund/01_fundprob.html">
   1. Fundamentals of Probability Theory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/01_fundprob/01_probabilityspaces.html">
     1.1. Probability Spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/01_fundprob/02_randomvariables.html">
     1.2. Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/01_fundprob/03_independence.html">
     1.3. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/01_fundprob/04_impprobdistr.html">
     1.4. Important Probability Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/01_fundprob/05_essthms.html">
     1.5. Essential Theorems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_fund/02_stat.html">
   2. Bayesian vs. Frequentists View
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01_fund/03_bayes.html">
   3. Bayesian Inference, MAP &amp; MLE
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/03_bayes/01_cointoss.html">
     3.1. Coin Toss
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/03_bayes/02_bayesianinference.html">
     3.2. Bayesian Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/03_bayes/03_MLEandMAP.html">
     3.3. MAP and MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01_fund/03_bayes/04_linregr.html">
     3.4. Linear Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_fund/04_opt.html">
   4. Optimization Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_fund/05_MLworkflow.html">
   5. Machine Learning Workflow
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probabilistic Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../02_probML/01_motivation.html">
   6. Motivation of Probabilistic Models
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02_probML/02_GPforML.html">
   7. Gaussian Processes for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_probML/02_GPforML/01_kerneltrick.html">
     7.1. The Kernel Trick: Implicit embeddings from inner products
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_probML/02_GPforML/02_GP.html">
     7.2. Gaussian Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_probML/02_GPforML/03_GPregression.html">
     7.3. Gaussian Process Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_probML/02_GPforML/04_kernels.html">
     7.4. Kernel Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_probML/02_GPforML/05_hyperparamimpact.html">
     7.5. Impact of Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_probML/02_GPforML/06_hyperparamselect.html">
     7.6. Selection of Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_probML/02_GPforML/07_multiout.html">
     7.7. Extension to Multiple Outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_probML/02_GPforML/08_GPclassification.html">
     7.8. Gaussian Process Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_probML/02_GPforML/09_examples.html">
     7.9. Examples
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../02_probML/02_GPforML/10_advanced.html">
     7.10. Advanced Methods
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../02_probML/02_GPforML/10_advanced/01_SparseGP.html">
       7.10.1. Scalable Gaussian Processes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../02_probML/02_GPforML/10_advanced/02_NonstationaryGP.html">
       7.10.2. Non-stationary Gaussian Processes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../02_probML/02_GPforML/10_advanced/03_DeepGP.html">
       7.10.3. Gaussian Processes on latent representations
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_probML/03_overview.html">
   8. Overview of Further Probabilistic Models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_BO.html">
   9. Bayesian Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="uncertainty.html">
   10. Design Uncertainty Analysis
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   11. Efficient Reinforcement Learning
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org/"><img alt="Jupyter Book" src="https://jupyterbook.org/badge.svg" width="100"></a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/03_appl/03_RL.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Probabilistic-ML/lecture-notes"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-definition">
   11.1. Problem definition
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dynamic-model-and-environment">
     11.1.1. Dynamic model and environment
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimization">
     11.1.2. Optimization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reinforcement-learning">
     11.1.3. Reinforcement learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probabilistic-inference-for-optimal-control">
   11.2. Probabilistic Inference for Optimal Control
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="efficient-reinforcement-learning">
<h1><span class="section-number">11. </span>Efficient Reinforcement Learning<a class="headerlink" href="#efficient-reinforcement-learning" title="Permalink to this headline">¶</a></h1>
<p>So far, supervised learning (SML) tasks were considered, where an algorithm was expected to learn the relationship <span class="math notranslate nohighlight">\(f: \mathbb{R}^{n_i} : \mathbb{R}^{n_o}\)</span> using a labeled dataset <span class="math notranslate nohighlight">\(\mathbb{D} := \{ (x_j, y_j), j\in [1,  m]\}\)</span> with <span class="math notranslate nohighlight">\(m\)</span> samples, where each sample consists of a tuple of input features <span class="math notranslate nohighlight">\( x_j \in \mathbb{R}^{n_i}\)</span>  and the corresponding labels <span class="math notranslate nohighlight">\( y_j \in \mathbb{R}^{n_o}\)</span>. Although SML is useful for many engineering tasks (e.g. design optimization, model validation and calibration, reliability analysis), it in itself does not provide a solution to problems, where some system parameters are controlled to achieve the desired system behaviour. Such problems are often investigated using the optimal control theory in engineering applications.</p>
<p>Whether the aim is to obtain the optimal trajectory for a satellite to maximize the fuel efficiency or to obtain the optimal pressure and flow rate of a medicinal ventilator, the description of the task does not coincide with SML. In contrast, reinforcement learning (RL) seeks to directly solve such problems. As such, there are many intersections regarding the optimal control theory and RL.</p>
<div class="section" id="problem-definition">
<h2><span class="section-number">11.1. </span>Problem definition<a class="headerlink" href="#problem-definition" title="Permalink to this headline">¶</a></h2>
<p>In optimal control problems, the aim is to find the optimal sequence of <em>control</em> values with respect to objective and constraint functions, one or more of which are formulated over a dynamic system. In RL, the aim is to find the sequence of <em>action</em> values that maximize the <em>expected reward</em>, where reward is a dynamic function as part of the <em>environment</em>.</p>
<p>Although the definitions look different since the used terminologies stem from different domains, there are many overlaps between the kind of tasks solved in these domains. Let us define individual terms to discuss this further.</p>
<div class="section" id="dynamic-model-and-environment">
<h3><span class="section-number">11.1.1. </span>Dynamic model and environment<a class="headerlink" href="#dynamic-model-and-environment" title="Permalink to this headline">¶</a></h3>
<p>In this work, a dynamic model refers to a time dependent model of following type:</p>
<div class="math notranslate nohighlight">
\[ s_{t+dt} = f(s_{t}, u_{t})  \]</div>
<p>where <span class="math notranslate nohighlight">\(s_t \in \mathbb{R}^{n_s}\)</span> are the <em>state</em> variables at time <span class="math notranslate nohighlight">\(t \in \mathbb{R}\)</span> and <span class="math notranslate nohighlight">\(u_t \in \mathbb{R}^{n_u}\)</span> are the <em>control</em> variables and <span class="math notranslate nohighlight">\(f: \mathbb{R}^{n_a + n_s} \rightarrow \mathbb{R}^{n_s}\)</span> is the <em>transition</em> function. Often, <span class="math notranslate nohighlight">\(f\)</span> is the first derivative of the solution of a set of differential equations with respect to time.</p>
<p>One approach to evaluate such systems is to discretize the time dimension. Besides being helpful regarding the optimization problem (see e.g. <a class="reference external" href="https://engineering.lehigh.edu/sites/engineering.lehigh.edu/files/_DEPARTMENTS/ise/pdf/tech-papers/09/09t_005.pdf">First-discretize-then-optimize</a>), it also simplifies the notation. The time discretized model can be denoted as</p>
<div class="math notranslate nohighlight">
\[ s_{t+1} = f(s_{t}, u_{t})  \]</div>
<p>where <span class="math notranslate nohighlight">\(t \in \mathbb{N}\)</span> now represents index of the discretization step, i.e. the actual time can be computed
as <span class="math notranslate nohighlight">\(t \cdot \Delta t\)</span> for an equidistant discretization with step size <span class="math notranslate nohighlight">\(\Delta t \in \mathbb{R}\)</span>.</p>
<p>Thus, given an initial configuration <span class="math notranslate nohighlight">\(s_0\)</span> and the transition function <span class="math notranslate nohighlight">\(f\)</span>, the state of the system at any point <span class="math notranslate nohighlight">\(t\)</span> in
time can be computed as</p>
<div class="math notranslate nohighlight">
\[ s_t = f(\dots f(f(s_0, u_0), u_1)\dots, u_{t-1})  \]</div>
<p>and a trajectory <span class="math notranslate nohighlight">\(\mathbb{T}\)</span> of the system, i.e. its evolution in time, can be constructed from tuples of state action pairs</p>
<div class="math notranslate nohighlight">
\[ \mathbb{T} := \left\{(s_t, u_t); t \in [0, n_t] \right\}\]</div>
<p>where <span class="math notranslate nohighlight">\(n_t \in \mathbb{N}\)</span> is the number of discretization steps.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The trajectory <span class="math notranslate nohighlight">\(\mathbb{T}\)</span> as formulated above will always have one state more than the actions leading to that state. For ease of notation, we assume that the last action is set to <span class="math notranslate nohighlight">\(a_n = 0\)</span> in the following.</p>
</div>
</div>
<div class="section" id="optimization">
<h3><span class="section-number">11.1.2. </span>Optimization<a class="headerlink" href="#optimization" title="Permalink to this headline">¶</a></h3>
<p>In the context of optimal control, there are various kinds of optimization problems considering the kind of dynamic model described above.
Here, we will investigate closed-loop control problems \cite{AnyControlTheoryBook} without constraints.
In such problems, the aim is to reach and maintain a target state <span class="math notranslate nohighlight">\(s^*\)</span>. Moreover, the expected result is not an optimal trajectory <span class="math notranslate nohighlight">\(\mathbb{T}^*\)</span> but a controller <span class="math notranslate nohighlight">\(\pi: \mathbb{R}^{n_s} \rightarrow \mathbb{R}^{n_u}\)</span>. The actual problem has an infinite horizon, although a finite one <span class="math notranslate nohighlight">\(t_f\)</span> has to be chosen for evaluation due to practical reasons.
Thus, a possible objective for this kind of problems can be given as</p>
<div class="math notranslate nohighlight">
\[ \mathrm{arg} \min_{\pi} \sum_{t=0}^{n_t}\left(s_t - s^*\right)^2 \]</div>
<p>where expectation is computed along the time dimension. Notice that any other error metric could also be used instead of the
squared error. As such, the optimal controller <span class="math notranslate nohighlight">\(\pi^*\)</span> is the one, that minimizes the chosen error metric.</p>
</div>
<div class="section" id="reinforcement-learning">
<h3><span class="section-number">11.1.3. </span>Reinforcement learning<a class="headerlink" href="#reinforcement-learning" title="Permalink to this headline">¶</a></h3>
<p>In RL literature, the dynamic model is part of the <em>environment</em> which represents the interaction space for an <em>agent</em> <span class="math notranslate nohighlight">\(\pi\)</span>. For our purposes, <em>agent</em> has the same function as the <em>controller</em> before.
Besides the dynamic model, environment may also define sources of noise as well as a reward function <span class="math notranslate nohighlight">\(r: \mathbb{R}^{n_s + n_u} \rightarrow \mathbb{R}\)</span> equivalent to an optimization objective. Thus, RL seeks to solve the following optimization problem</p>
<div class="math notranslate nohighlight">
\[ \mathrm{arg}\max_{\pi} \sum_{t=0}^{n_t} r\left(s_t, u_t\right) \]</div>
<p>As such, the optimal agent <span class="math notranslate nohighlight">\(\pi^*\)</span> is the one, that maximizes the total return. Notice that this equation is equivalent to the optimization objective given before. Typically, the dataset <span class="math notranslate nohighlight">\(\mathbb{D}\)</span> in RL consists of multiple trajectories <span class="math notranslate nohighlight">\(\mathbb{T}_i\)</span> representing different trials.</p>
<p>Possibly the most important difference between SML and RL algorithms is the existence of the optimal actions. If these are available as examples, SML framework could be theoretically used to to learn to output them. Otherwise RL is used to obtain them by interacting with the environment and observing its response. Furthermore, existing good actions can also be used in RL (e.g. expert demonstrations \citepeg{OpenAI2018,OtherGuyWithFewShotRL}) In any case, recent research \citepeg{UpsideDownRL,RewardToRL) shows that such distinctions are not necessarily clear in all cases.</p>
<p>A more detailed description of reinforcement learning is beyond the scope of this book. See <a class="reference external" href="http://incompleteideas.net/book/RLbook2020.pdf">Reinforcement Learning by Sutton &amp; Barto</a> for further reference.</p>
</div>
</div>
<div class="section" id="probabilistic-inference-for-optimal-control">
<h2><span class="section-number">11.2. </span>Probabilistic Inference for Optimal Control<a class="headerlink" href="#probabilistic-inference-for-optimal-control" title="Permalink to this headline">¶</a></h2>
<p>Assume that the transition function <span class="math notranslate nohighlight">\(f\)</span> in the dynamic model is not known or too expensive to optimize.
As discussed earlier, SML algorithms can be used to acquire surrogate models, that are usually faster to evaluate at the cost of some accuracy loss.</p>
<p>Let us use a <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span> to approximate the unknown transition function <span class="math notranslate nohighlight">\(f\)</span>. Specifically, let us train a model <span class="math notranslate nohighlight">\(\tilde{f}: \mathbb{R}^{n_s + n_a} \rightarrow \mathbb{R}^{n_s}\)</span> to use
the current state <span class="math notranslate nohighlight">\(s_t\)</span> and action <span class="math notranslate nohighlight">\(u_t\)</span> as input and predict the state difference <span class="math notranslate nohighlight">\(\Delta^s_{t} \in \mathbb{R}^{n_s}\)</span> such that</p>
<div class="math notranslate nohighlight">
\[ s_{t + 1} = s_t + \Delta^s_{t} \]</div>
<p>We can take a trajectory <span class="math notranslate nohighlight">\(\mathbb{T}\)</span> and create tuples of input <span class="math notranslate nohighlight">\(x^T = [s_t^T, a_t^T]\)</span> and output <span class="math notranslate nohighlight">\(\Delta^s_t = s_{t+1} - s_t\)</span> features from each transition.
Using this data set, a <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span> model can be trained. The resulting one step (approximate) dynamics model can be given as</p>
<div class="amsmath math notranslate nohighlight" id="equation-34da62a2-3199-4f45-af3b-cb7dbf463e92">
<span class="eqno">(11.1)<a class="headerlink" href="#equation-34da62a2-3199-4f45-af3b-cb7dbf463e92" title="Permalink to this equation">¶</a></span>\[\begin{align}
p(s_{t + 1} | s_t, a_t) &amp;= \mathcal{N}(s_{t+1} | \mu_{t+1}, \Sigma_{t+1}) \\
\mu_{t+1} &amp;= s_t + \mu_{\Delta^s_{t}} \\
\Sigma_{t+1} &amp;= \Sigma^2_{\Delta^s_{t}} \\
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu_{\Delta^s_{t}} \in \mathbb{R}^{n_s}\)</span> and <span class="math notranslate nohighlight">\(\Sigma^2_{\Delta^s_{t}}  \in \mathbb{R}^{n_s}\)</span> are the posterior mean and the variance of the <span class="math notranslate nohighlight">\(\mathcal{GP}\)</span> (see <a class="reference external" href="https://probabilistic-ml.github.io/lecture-notes/02_probML/kernelmethods.html#gaussian-process">Gaussian Process</a>).</p>
<p>Now that we have a model of the dynamics, we could use control theory (or any other appropriate method) to find an optimal controller <span class="math notranslate nohighlight">\(\pi\)</span>.
Moreover, we could use Bayesian optimization to account for the model uncertainty, which could accelerate the optimization.
However, notice that the output of each step is the input to the next step.
Even if we assume the initial state <span class="math notranslate nohighlight">\(s_0\)</span> to be known, <span class="math notranslate nohighlight">\(s_1\)</span> is an uncertain variable, which will be part of the input when predicting <span class="math notranslate nohighlight">\(s_2\)</span>.
A better strategy would be to propagate the uncertainty for a more accurate estimate of <span class="math notranslate nohighlight">\(\Sigma_{t+1}\)</span>.</p>
<p>Propagating the uncertainty is not a trivial task <span id="id1">[<a class="reference internal" href="RL.html#id4">1</a>]</span>. Let us elaborate using an example.</p>
<p id="id2"><dl class="citation">
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>M.P. Deisenroth and C.E. Rasmussen. Pilco: a model-based and data-efficient approach to policy search. In <em>Proceedings of the 28th International Conference on Machine Learning, ICML 2011</em>, 465–472. Omnipress, 2011.</p>
</dd>
</dl>
</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./03_appl"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="uncertainty.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">10. </span>Design Uncertainty Analysis</p>
        </div>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By C. Bogoclu, N. Friedlich & R. Vosshall<br/>
        
          <div class="extra_footer">
            Content on this site is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">a CC BY-NC-NB 4.0 licence</a>.
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>